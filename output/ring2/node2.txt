[2022-11-02 16:28:57,786 {main.py:127}] <INFO> Namespace(datadir='./data', outdir='./output/ring2', epochs=200, batch_size=100, seed=569, data_init_seed=11, model_init_seed=13, l2_lambda=0.01, model_name='resnet50', dataset_name='cifar10', train_data_length=10000, group_channels=32, drop_rate=0.1, last_drop_rate=0.5, cuda=True, cuda_device_no=2, plot=False, scheduler='StepLR', step_size=410, gamma=0.9, sleep_factor=0.0, loglevel=<LogLevel.INFO: 20>, logfile=None, optimizer='PdmmISVR', nodename='node1', conf='./conf/node_list.json', host='./conf/hosts.json', lr=0.002, use_gcoef=False, piw=1.0, round_step=False, swap_timeout=10)
[2022-11-02 16:28:57,786 {main.py:193}] <INFO> {'nodes': {'node0': {'device': 'cuda', 'round': 10, 'edges': {'node2': 0, 'node1': 4}}, 'node1': {'device': 'cuda', 'round': 10, 'edges': {'node0': 1, 'node2': 5}}, 'node2': {'device': 'cuda', 'round': 10, 'edges': {'node1': 2, 'node0': 6}}}}
[2022-11-02 16:28:57,908 {dist_trainer.py:186}] <INFO> : <class 'model.resnet.ResNet'>
[2022-11-02 16:28:57,908 {dist_trainer.py:186}] <INFO> conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,908 {dist_trainer.py:183}] <INFO> bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-02 16:28:57,908 {dist_trainer.py:186}] <INFO> relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,908 {dist_trainer.py:186}] <INFO> maxpool: <class 'torch.nn.modules.pooling.MaxPool2d'>
[2022-11-02 16:28:57,908 {dist_trainer.py:186}] <INFO> dropout1: <class 'torch.nn.modules.dropout.Dropout2d'>
[2022-11-02 16:28:57,908 {dist_trainer.py:186}] <INFO> layer1: <class 'torch.nn.modules.container.Sequential'>
[2022-11-02 16:28:57,908 {dist_trainer.py:186}] <INFO> layer1.0: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,908 {dist_trainer.py:186}] <INFO> layer1.0.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,908 {dist_trainer.py:183}] <INFO> layer1.0.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-02 16:28:57,908 {dist_trainer.py:186}] <INFO> layer1.0.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,908 {dist_trainer.py:183}] <INFO> layer1.0.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-02 16:28:57,908 {dist_trainer.py:186}] <INFO> layer1.0.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,909 {dist_trainer.py:183}] <INFO> layer1.0.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer1.0.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer1.0.downsample: <class 'torch.nn.modules.container.Sequential'>
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer1.0.downsample.0: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,909 {dist_trainer.py:183}] <INFO> layer1.0.downsample.1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer1.1: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer1.1.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,909 {dist_trainer.py:183}] <INFO> layer1.1.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer1.1.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,909 {dist_trainer.py:183}] <INFO> layer1.1.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer1.1.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,909 {dist_trainer.py:183}] <INFO> layer1.1.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer1.1.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer1.2: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer1.2.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,909 {dist_trainer.py:183}] <INFO> layer1.2.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer1.2.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,909 {dist_trainer.py:183}] <INFO> layer1.2.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer1.2.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,909 {dist_trainer.py:183}] <INFO> layer1.2.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer1.2.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer1.3: <class 'torch.nn.modules.dropout.Dropout2d'>
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer2: <class 'torch.nn.modules.container.Sequential'>
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer2.0: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer2.0.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,909 {dist_trainer.py:183}] <INFO> layer2.0.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer2.0.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,909 {dist_trainer.py:183}] <INFO> layer2.0.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer2.0.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,909 {dist_trainer.py:183}] <INFO> layer2.0.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer2.0.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer2.0.downsample: <class 'torch.nn.modules.container.Sequential'>
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer2.0.downsample.0: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,909 {dist_trainer.py:183}] <INFO> layer2.0.downsample.1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer2.1: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer2.1.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,909 {dist_trainer.py:183}] <INFO> layer2.1.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer2.1.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,909 {dist_trainer.py:183}] <INFO> layer2.1.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer2.1.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,909 {dist_trainer.py:183}] <INFO> layer2.1.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer2.1.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer2.2: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer2.2.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,910 {dist_trainer.py:183}] <INFO> layer2.2.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer2.2.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,910 {dist_trainer.py:183}] <INFO> layer2.2.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer2.2.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,910 {dist_trainer.py:183}] <INFO> layer2.2.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer2.2.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer2.3: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer2.3.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,910 {dist_trainer.py:183}] <INFO> layer2.3.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer2.3.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,910 {dist_trainer.py:183}] <INFO> layer2.3.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer2.3.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,910 {dist_trainer.py:183}] <INFO> layer2.3.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer2.3.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer2.4: <class 'torch.nn.modules.dropout.Dropout2d'>
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer3: <class 'torch.nn.modules.container.Sequential'>
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer3.0: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer3.0.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,910 {dist_trainer.py:183}] <INFO> layer3.0.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer3.0.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,910 {dist_trainer.py:183}] <INFO> layer3.0.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer3.0.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,910 {dist_trainer.py:183}] <INFO> layer3.0.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer3.0.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer3.0.downsample: <class 'torch.nn.modules.container.Sequential'>
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer3.0.downsample.0: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,910 {dist_trainer.py:183}] <INFO> layer3.0.downsample.1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer3.1: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer3.1.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,910 {dist_trainer.py:183}] <INFO> layer3.1.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer3.1.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,910 {dist_trainer.py:183}] <INFO> layer3.1.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer3.1.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,910 {dist_trainer.py:183}] <INFO> layer3.1.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer3.1.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer3.2: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer3.2.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,910 {dist_trainer.py:183}] <INFO> layer3.2.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer3.2.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,911 {dist_trainer.py:183}] <INFO> layer3.2.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer3.2.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,911 {dist_trainer.py:183}] <INFO> layer3.2.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer3.2.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer3.3: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer3.3.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,911 {dist_trainer.py:183}] <INFO> layer3.3.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer3.3.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,911 {dist_trainer.py:183}] <INFO> layer3.3.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer3.3.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,911 {dist_trainer.py:183}] <INFO> layer3.3.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer3.3.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer3.4: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer3.4.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,911 {dist_trainer.py:183}] <INFO> layer3.4.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer3.4.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,911 {dist_trainer.py:183}] <INFO> layer3.4.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer3.4.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,911 {dist_trainer.py:183}] <INFO> layer3.4.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer3.4.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer3.5: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer3.5.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,911 {dist_trainer.py:183}] <INFO> layer3.5.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer3.5.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,911 {dist_trainer.py:183}] <INFO> layer3.5.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer3.5.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,911 {dist_trainer.py:183}] <INFO> layer3.5.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer3.5.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer3.6: <class 'torch.nn.modules.dropout.Dropout2d'>
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer4: <class 'torch.nn.modules.container.Sequential'>
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer4.0: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer4.0.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,911 {dist_trainer.py:183}] <INFO> layer4.0.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer4.0.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,911 {dist_trainer.py:183}] <INFO> layer4.0.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer4.0.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,911 {dist_trainer.py:183}] <INFO> layer4.0.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 64, channels: 2048, eps: 0.000010, affine: True
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer4.0.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer4.0.downsample: <class 'torch.nn.modules.container.Sequential'>
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer4.0.downsample.0: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,912 {dist_trainer.py:183}] <INFO> layer4.0.downsample.1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 64, channels: 2048, eps: 0.000010, affine: True
[2022-11-02 16:28:57,912 {dist_trainer.py:186}] <INFO> layer4.1: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,912 {dist_trainer.py:186}] <INFO> layer4.1.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,912 {dist_trainer.py:183}] <INFO> layer4.1.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 16:28:57,912 {dist_trainer.py:186}] <INFO> layer4.1.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,912 {dist_trainer.py:183}] <INFO> layer4.1.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 16:28:57,912 {dist_trainer.py:186}] <INFO> layer4.1.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,912 {dist_trainer.py:183}] <INFO> layer4.1.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 64, channels: 2048, eps: 0.000010, affine: True
[2022-11-02 16:28:57,912 {dist_trainer.py:186}] <INFO> layer4.1.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,912 {dist_trainer.py:186}] <INFO> layer4.2: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,912 {dist_trainer.py:186}] <INFO> layer4.2.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,912 {dist_trainer.py:183}] <INFO> layer4.2.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 16:28:57,912 {dist_trainer.py:186}] <INFO> layer4.2.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,912 {dist_trainer.py:183}] <INFO> layer4.2.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 16:28:57,912 {dist_trainer.py:186}] <INFO> layer4.2.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,912 {dist_trainer.py:183}] <INFO> layer4.2.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 64, channels: 2048, eps: 0.000010, affine: True
[2022-11-02 16:28:57,912 {dist_trainer.py:186}] <INFO> layer4.2.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,912 {dist_trainer.py:186}] <INFO> avgpool: <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>
[2022-11-02 16:28:57,912 {dist_trainer.py:186}] <INFO> dropout_fc: <class 'torch.nn.modules.dropout.Dropout'>
[2022-11-02 16:28:57,912 {dist_trainer.py:186}] <INFO> fc: <class 'torch.nn.modules.linear.Linear'>
[2022-11-02 16:28:57,912 {dist_trainer.py:192}] <INFO> parameter size: conv1.weight 37632B
[2022-11-02 16:28:57,912 {dist_trainer.py:192}] <INFO> parameter size: bn1.weight 256B
[2022-11-02 16:28:57,912 {dist_trainer.py:192}] <INFO> parameter size: bn1.bias 256B
[2022-11-02 16:28:57,912 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.conv1.weight 16384B
[2022-11-02 16:28:57,912 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.bn1.weight 256B
[2022-11-02 16:28:57,912 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.bn1.bias 256B
[2022-11-02 16:28:57,912 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.conv2.weight 147456B
[2022-11-02 16:28:57,912 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.bn2.weight 256B
[2022-11-02 16:28:57,913 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.bn2.bias 256B
[2022-11-02 16:28:57,913 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.conv3.weight 65536B
[2022-11-02 16:28:57,913 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.bn3.weight 1024B
[2022-11-02 16:28:57,913 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.bn3.bias 1024B
[2022-11-02 16:28:57,913 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.downsample.0.weight 65536B
[2022-11-02 16:28:57,913 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.downsample.1.weight 1024B
[2022-11-02 16:28:57,913 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.downsample.1.bias 1024B
[2022-11-02 16:28:57,913 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.conv1.weight 65536B
[2022-11-02 16:28:57,913 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.bn1.weight 256B
[2022-11-02 16:28:57,913 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.bn1.bias 256B
[2022-11-02 16:28:57,913 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.conv2.weight 147456B
[2022-11-02 16:28:57,913 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.bn2.weight 256B
[2022-11-02 16:28:57,913 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.bn2.bias 256B
[2022-11-02 16:28:57,913 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.conv3.weight 65536B
[2022-11-02 16:28:57,913 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.bn3.weight 1024B
[2022-11-02 16:28:57,913 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.bn3.bias 1024B
[2022-11-02 16:28:57,913 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.conv1.weight 65536B
[2022-11-02 16:28:57,913 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.bn1.weight 256B
[2022-11-02 16:28:57,913 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.bn1.bias 256B
[2022-11-02 16:28:57,913 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.conv2.weight 147456B
[2022-11-02 16:28:57,913 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.bn2.weight 256B
[2022-11-02 16:28:57,913 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.bn2.bias 256B
[2022-11-02 16:28:57,913 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.conv3.weight 65536B
[2022-11-02 16:28:57,913 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.bn3.weight 1024B
[2022-11-02 16:28:57,914 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.bn3.bias 1024B
[2022-11-02 16:28:57,914 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.conv1.weight 131072B
[2022-11-02 16:28:57,914 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.bn1.weight 512B
[2022-11-02 16:28:57,914 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.bn1.bias 512B
[2022-11-02 16:28:57,914 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.conv2.weight 589824B
[2022-11-02 16:28:57,914 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.bn2.weight 512B
[2022-11-02 16:28:57,914 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.bn2.bias 512B
[2022-11-02 16:28:57,914 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.conv3.weight 262144B
[2022-11-02 16:28:57,914 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.bn3.weight 2048B
[2022-11-02 16:28:57,914 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.bn3.bias 2048B
[2022-11-02 16:28:57,914 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.downsample.0.weight 524288B
[2022-11-02 16:28:57,914 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.downsample.1.weight 2048B
[2022-11-02 16:28:57,914 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.downsample.1.bias 2048B
[2022-11-02 16:28:57,914 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.conv1.weight 262144B
[2022-11-02 16:28:57,914 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.bn1.weight 512B
[2022-11-02 16:28:57,914 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.bn1.bias 512B
[2022-11-02 16:28:57,914 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.conv2.weight 589824B
[2022-11-02 16:28:57,914 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.bn2.weight 512B
[2022-11-02 16:28:57,914 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.bn2.bias 512B
[2022-11-02 16:28:57,914 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.conv3.weight 262144B
[2022-11-02 16:28:57,914 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.bn3.weight 2048B
[2022-11-02 16:28:57,914 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.bn3.bias 2048B
[2022-11-02 16:28:57,914 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.conv1.weight 262144B
[2022-11-02 16:28:57,914 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.bn1.weight 512B
[2022-11-02 16:28:57,915 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.bn1.bias 512B
[2022-11-02 16:28:57,915 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.conv2.weight 589824B
[2022-11-02 16:28:57,915 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.bn2.weight 512B
[2022-11-02 16:28:57,915 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.bn2.bias 512B
[2022-11-02 16:28:57,915 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.conv3.weight 262144B
[2022-11-02 16:28:57,915 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.bn3.weight 2048B
[2022-11-02 16:28:57,915 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.bn3.bias 2048B
[2022-11-02 16:28:57,915 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.conv1.weight 262144B
[2022-11-02 16:28:57,915 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.bn1.weight 512B
[2022-11-02 16:28:57,915 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.bn1.bias 512B
[2022-11-02 16:28:57,915 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.conv2.weight 589824B
[2022-11-02 16:28:57,915 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.bn2.weight 512B
[2022-11-02 16:28:57,915 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.bn2.bias 512B
[2022-11-02 16:28:57,915 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.conv3.weight 262144B
[2022-11-02 16:28:57,915 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.bn3.weight 2048B
[2022-11-02 16:28:57,915 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.bn3.bias 2048B
[2022-11-02 16:28:57,915 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.conv1.weight 524288B
[2022-11-02 16:28:57,915 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.bn1.weight 1024B
[2022-11-02 16:28:57,915 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.bn1.bias 1024B
[2022-11-02 16:28:57,915 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.conv2.weight 2359296B
[2022-11-02 16:28:57,915 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.bn2.weight 1024B
[2022-11-02 16:28:57,915 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.bn2.bias 1024B
[2022-11-02 16:28:57,915 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.conv3.weight 1048576B
[2022-11-02 16:28:57,915 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.bn3.weight 4096B
[2022-11-02 16:28:57,916 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.bn3.bias 4096B
[2022-11-02 16:28:57,916 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.downsample.0.weight 2097152B
[2022-11-02 16:28:57,916 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.downsample.1.weight 4096B
[2022-11-02 16:28:57,916 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.downsample.1.bias 4096B
[2022-11-02 16:28:57,916 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.conv1.weight 1048576B
[2022-11-02 16:28:57,916 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.bn1.weight 1024B
[2022-11-02 16:28:57,916 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.bn1.bias 1024B
[2022-11-02 16:28:57,916 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.conv2.weight 2359296B
[2022-11-02 16:28:57,916 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.bn2.weight 1024B
[2022-11-02 16:28:57,916 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.bn2.bias 1024B
[2022-11-02 16:28:57,916 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.conv3.weight 1048576B
[2022-11-02 16:28:57,916 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.bn3.weight 4096B
[2022-11-02 16:28:57,916 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.bn3.bias 4096B
[2022-11-02 16:28:57,916 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.conv1.weight 1048576B
[2022-11-02 16:28:57,916 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.bn1.weight 1024B
[2022-11-02 16:28:57,916 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.bn1.bias 1024B
[2022-11-02 16:28:57,916 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.conv2.weight 2359296B
[2022-11-02 16:28:57,916 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.bn2.weight 1024B
[2022-11-02 16:28:57,916 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.bn2.bias 1024B
[2022-11-02 16:28:57,916 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.conv3.weight 1048576B
[2022-11-02 16:28:57,916 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.bn3.weight 4096B
[2022-11-02 16:28:57,919 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.bn3.bias 4096B
[2022-11-02 16:28:57,919 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.conv1.weight 1048576B
[2022-11-02 16:28:57,919 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.bn1.weight 1024B
[2022-11-02 16:28:57,919 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.bn1.bias 1024B
[2022-11-02 16:28:57,919 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.conv2.weight 2359296B
[2022-11-02 16:28:57,919 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.bn2.weight 1024B
[2022-11-02 16:28:57,919 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.bn2.bias 1024B
[2022-11-02 16:28:57,919 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.conv3.weight 1048576B
[2022-11-02 16:28:57,919 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.bn3.weight 4096B
[2022-11-02 16:28:57,920 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.bn3.bias 4096B
[2022-11-02 16:28:57,920 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.conv1.weight 1048576B
[2022-11-02 16:28:57,920 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.bn1.weight 1024B
[2022-11-02 16:28:57,920 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.bn1.bias 1024B
[2022-11-02 16:28:57,920 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.conv2.weight 2359296B
[2022-11-02 16:28:57,920 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.bn2.weight 1024B
[2022-11-02 16:28:57,920 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.bn2.bias 1024B
[2022-11-02 16:28:57,920 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.conv3.weight 1048576B
[2022-11-02 16:28:57,920 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.bn3.weight 4096B
[2022-11-02 16:28:57,920 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.bn3.bias 4096B
[2022-11-02 16:28:57,920 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.conv1.weight 1048576B
[2022-11-02 16:28:57,920 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.bn1.weight 1024B
[2022-11-02 16:28:57,920 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.bn1.bias 1024B
[2022-11-02 16:28:57,920 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.conv2.weight 2359296B
[2022-11-02 16:28:57,920 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.bn2.weight 1024B
[2022-11-02 16:28:57,920 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.bn2.bias 1024B
[2022-11-02 16:28:57,920 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.conv3.weight 1048576B
[2022-11-02 16:28:57,920 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.bn3.weight 4096B
[2022-11-02 16:28:57,920 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.bn3.bias 4096B
[2022-11-02 16:28:57,920 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.conv1.weight 2097152B
[2022-11-02 16:28:57,920 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.bn1.weight 2048B
[2022-11-02 16:28:57,920 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.bn1.bias 2048B
[2022-11-02 16:28:57,920 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.conv2.weight 9437184B
[2022-11-02 16:28:57,921 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.bn2.weight 2048B
[2022-11-02 16:28:57,921 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.bn2.bias 2048B
[2022-11-02 16:28:57,921 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.conv3.weight 4194304B
[2022-11-02 16:28:57,921 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.bn3.weight 8192B
[2022-11-02 16:28:57,921 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.bn3.bias 8192B
[2022-11-02 16:28:57,921 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.downsample.0.weight 8388608B
[2022-11-02 16:28:57,921 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.downsample.1.weight 8192B
[2022-11-02 16:28:57,921 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.downsample.1.bias 8192B
[2022-11-02 16:28:57,921 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.conv1.weight 4194304B
[2022-11-02 16:28:57,921 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.bn1.weight 2048B
[2022-11-02 16:28:57,921 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.bn1.bias 2048B
[2022-11-02 16:28:57,921 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.conv2.weight 9437184B
[2022-11-02 16:28:57,921 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.bn2.weight 2048B
[2022-11-02 16:28:57,921 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.bn2.bias 2048B
[2022-11-02 16:28:57,921 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.conv3.weight 4194304B
[2022-11-02 16:28:57,921 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.bn3.weight 8192B
[2022-11-02 16:28:57,921 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.bn3.bias 8192B
[2022-11-02 16:28:57,921 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.conv1.weight 4194304B
[2022-11-02 16:28:57,921 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.bn1.weight 2048B
[2022-11-02 16:28:57,922 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.bn1.bias 2048B
[2022-11-02 16:28:57,922 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.conv2.weight 9437184B
[2022-11-02 16:28:57,922 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.bn2.weight 2048B
[2022-11-02 16:28:57,922 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.bn2.bias 2048B
[2022-11-02 16:28:57,922 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.conv3.weight 4194304B
[2022-11-02 16:28:57,922 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.bn3.weight 8192B
[2022-11-02 16:28:57,922 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.bn3.bias 8192B
[2022-11-02 16:28:57,922 {dist_trainer.py:192}] <INFO> parameter size: fc.weight 81920B
[2022-11-02 16:28:57,922 {dist_trainer.py:192}] <INFO> parameter size: fc.bias 40B
[2022-11-02 16:28:57,922 {dist_trainer.py:194}] <INFO> Model: resnet50 size: 89.754MiB
[2022-11-02 16:28:59,843 {dist_trainer.py:78}] <INFO> device: cuda:2 0/4, NVIDIA TITAN RTX
[2022-11-02 16:29:01,160 {dist_trainer.py:494}] <INFO> node0: [7,8,2,6,4,5,1,3]
[2022-11-02 16:29:01,160 {dist_trainer.py:494}] <INFO> node1: [4,5,1,3,0,9,7,8]
[2022-11-02 16:29:01,160 {dist_trainer.py:494}] <INFO> node2: [0,9,7,8,2,6,4,5]
[2022-11-02 16:29:01,160 {dist_trainer.py:497}] <INFO> class 0, [node1:0.472,node2:0.528]
[2022-11-02 16:29:01,160 {dist_trainer.py:497}] <INFO> class 1, [node0:0.505,node1:0.495]
[2022-11-02 16:29:01,160 {dist_trainer.py:497}] <INFO> class 2, [node0:0.535,node2:0.465]
[2022-11-02 16:29:01,160 {dist_trainer.py:497}] <INFO> class 3, [node0:0.502,node1:0.498]
[2022-11-02 16:29:01,160 {dist_trainer.py:497}] <INFO> class 4, [node0:0.325,node1:0.361,node2:0.314]
[2022-11-02 16:29:01,160 {dist_trainer.py:497}] <INFO> class 5, [node0:0.327,node1:0.343,node2:0.330]
[2022-11-02 16:29:01,160 {dist_trainer.py:497}] <INFO> class 6, [node0:0.497,node2:0.503]
[2022-11-02 16:29:01,160 {dist_trainer.py:497}] <INFO> class 7, [node0:0.340,node1:0.338,node2:0.322]
[2022-11-02 16:29:01,160 {dist_trainer.py:497}] <INFO> class 8, [node0:0.305,node1:0.352,node2:0.343]
[2022-11-02 16:29:01,161 {dist_trainer.py:497}] <INFO> class 9, [node1:0.475,node2:0.525]
[2022-11-02 16:29:01,162 {dist_trainer.py:527}] <INFO> train data node0: 1:2523,2:2675,3:2509,4:1624,5:1634,6:2484,7:1700,8:1524
[2022-11-02 16:29:01,162 {dist_trainer.py:527}] <INFO> train data node1: 0:2360,1:2477,3:2491,4:1806,5:1714,7:1690,8:1758,9:2375
[2022-11-02 16:29:01,163 {dist_trainer.py:527}] <INFO> train data node2: 0:2640,2:2325,4:1570,5:1652,6:2516,7:1610,8:1718,9:2625
[2022-11-02 16:29:14,062 {dist_trainer.py:531}] <INFO> split_load_datas(END)
[2022-11-02 16:29:14,063 {dist_trainer.py:114}] <INFO> datasets(END)
[2022-11-02 16:29:14,063 {dist_trainer.py:713}] <INFO> build_criterion(1)
[2022-11-02 16:29:14,064 {dist_trainer.py:721}] <INFO> build_criterion(2)
[2022-11-02 16:29:14,074 {contract.py:21}] <INFO> 0
[2022-11-02 16:29:14,075 {contract.py:21}] <INFO> 1
[2022-11-02 16:29:14,075 {contract.py:21}] <INFO> 2
[2022-11-02 16:29:14,075 {gateway.py:80}] <INFO> Gateway(1)
[2022-11-02 16:29:17,005 {distributed_c10d.py:228}] <INFO> Added key: store_based_barrier_key:1 to store for rank: 1
[2022-11-02 16:29:17,005 {distributed_c10d.py:262}] <INFO> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
[2022-11-02 16:29:17,006 {gateway.py:87}] <INFO> Gateway(2)
[2022-11-02 16:29:17,209 {gateway.py:25}] <INFO> ServerHandler(1)
[2022-11-02 16:29:17,246 {gateway.py:34}] <INFO> ServerHandler(2)
[2022-11-02 16:29:17,248 {contract.py:36}] <INFO> contract(1)
[2022-11-02 16:29:17,296 {gateway.py:62}] <INFO> <SRV> node1 : edge setup.
[2022-11-02 16:29:17,300 {contract.py:44}] <INFO> <CLI> node1 : edge setup.
[2022-11-02 16:29:17,496 {contract.py:59}] <INFO> contract(2)
[2022-11-02 16:29:17,497 {pdmm_isvr.py:22}] <INFO> Optimizer <class 'optimizer.pdmm_isvr.PdmmISVR'> params: {'lr': 0.002, 'round': 10, 'initial_lr': 0.002, 'piw': 1.0, 'use_gcoef': False}
[2022-11-02 16:29:17,497 {dist_trainer.py:725}] <INFO> build_optimizer()
[2022-11-02 16:29:17,497 {dist_trainer.py:736}] <INFO> Setup scheduler: <torch.optim.lr_scheduler.StepLR object at 0x7f3ae01b0310>
[2022-11-02 16:29:45,010 {dist_trainer.py:770}] <INFO> [   1/ 200] connecting edge count: 2
[2022-11-02 16:29:58,901 {dist_trainer.py:821}] <INFO> [   1/ 200] loss: (train=2.486, val=2.330, test=2.330, l2=14517.672), acc: (train=0.199, val=0.145, test=0.145), diff=0.00160024, proc(train=27.511sec, eval=11.665sec)
[2022-11-02 16:30:20,381 {dist_trainer.py:770}] <INFO> [   2/ 200] connecting edge count: 2
[2022-11-02 16:30:34,079 {dist_trainer.py:821}] <INFO> [   2/ 200] loss: (train=2.310, val=2.237, test=2.232, l2=15504.587), acc: (train=0.231, val=0.164, test=0.167), diff=0.00001402, proc(train=21.479sec, eval=11.376sec)
[2022-11-02 16:30:57,744 {dist_trainer.py:770}] <INFO> [   3/ 200] connecting edge count: 2
[2022-11-02 16:31:11,678 {dist_trainer.py:821}] <INFO> [   3/ 200] loss: (train=2.323, val=2.249, test=2.249, l2=15565.440), acc: (train=0.254, val=0.196, test=0.195), diff=0.00000634, proc(train=23.665sec, eval=11.602sec)
[2022-11-02 16:31:36,881 {dist_trainer.py:770}] <INFO> [   4/ 200] connecting edge count: 2
[2022-11-02 16:31:49,967 {dist_trainer.py:821}] <INFO> [   4/ 200] loss: (train=2.228, val=2.240, test=2.232, l2=15527.690), acc: (train=0.227, val=0.151, test=0.152), diff=0.00000076, proc(train=25.203sec, eval=11.342sec)
[2022-11-02 16:32:14,282 {dist_trainer.py:770}] <INFO> [   5/ 200] connecting edge count: 2
[2022-11-02 16:32:27,932 {dist_trainer.py:821}] <INFO> [   5/ 200] loss: (train=2.231, val=2.139, test=2.137, l2=15525.788), acc: (train=0.249, val=0.190, test=0.189), diff=0.00000049, proc(train=24.315sec, eval=11.645sec)
[2022-11-02 16:32:54,559 {dist_trainer.py:770}] <INFO> [   6/ 200] connecting edge count: 2
[2022-11-02 16:33:07,174 {dist_trainer.py:821}] <INFO> [   6/ 200] loss: (train=2.183, val=2.115, test=2.120, l2=15467.611), acc: (train=0.267, val=0.251, test=0.250), diff=0.00000025, proc(train=26.627sec, eval=11.331sec)
[2022-11-02 16:33:29,874 {dist_trainer.py:770}] <INFO> [   7/ 200] connecting edge count: 2
[2022-11-02 16:33:42,678 {dist_trainer.py:821}] <INFO> [   7/ 200] loss: (train=2.116, val=1.995, test=1.992, l2=15453.730), acc: (train=0.319, val=0.257, test=0.267), diff=0.00000037, proc(train=22.699sec, eval=11.588sec)
[2022-11-02 16:34:06,695 {dist_trainer.py:770}] <INFO> [   8/ 200] connecting edge count: 2
[2022-11-02 16:34:20,294 {dist_trainer.py:821}] <INFO> [   8/ 200] loss: (train=2.046, val=1.950, test=1.942, l2=15407.948), acc: (train=0.312, val=0.256, test=0.266), diff=0.00000076, proc(train=24.017sec, eval=11.614sec)
[2022-11-02 16:34:41,715 {dist_trainer.py:770}] <INFO> [   9/ 200] connecting edge count: 2
[2022-11-02 16:34:55,412 {dist_trainer.py:821}] <INFO> [   9/ 200] loss: (train=1.984, val=2.005, test=1.999, l2=15372.202), acc: (train=0.263, val=0.262, test=0.263), diff=0.00000061, proc(train=21.421sec, eval=11.351sec)
[2022-11-02 16:35:19,290 {dist_trainer.py:770}] <INFO> [  10/ 200] connecting edge count: 2
[2022-11-02 16:35:31,877 {dist_trainer.py:821}] <INFO> [  10/ 200] loss: (train=2.000, val=2.015, test=2.008, l2=15377.546), acc: (train=0.322, val=0.227, test=0.231), diff=0.00000064, proc(train=23.878sec, eval=11.688sec)
[2022-11-02 16:35:56,088 {dist_trainer.py:770}] <INFO> [  11/ 200] connecting edge count: 2
[2022-11-02 16:36:08,765 {dist_trainer.py:821}] <INFO> [  11/ 200] loss: (train=1.948, val=1.976, test=1.966, l2=15330.036), acc: (train=0.346, val=0.253, test=0.254), diff=0.00000046, proc(train=24.211sec, eval=11.465sec)
[2022-11-02 16:36:33,230 {dist_trainer.py:770}] <INFO> [  12/ 200] connecting edge count: 2
[2022-11-02 16:36:46,612 {dist_trainer.py:821}] <INFO> [  12/ 200] loss: (train=1.998, val=1.973, test=1.970, l2=15319.670), acc: (train=0.333, val=0.295, test=0.294), diff=0.00000049, proc(train=24.464sec, eval=11.786sec)
[2022-11-02 16:37:13,374 {dist_trainer.py:770}] <INFO> [  13/ 200] connecting edge count: 2
[2022-11-02 16:37:26,258 {dist_trainer.py:821}] <INFO> [  13/ 200] loss: (train=1.947, val=1.777, test=1.769, l2=15268.197), acc: (train=0.371, val=0.349, test=0.357), diff=0.00000040, proc(train=26.762sec, eval=11.565sec)
[2022-11-02 16:37:48,323 {dist_trainer.py:770}] <INFO> [  14/ 200] connecting edge count: 2
[2022-11-02 16:38:01,072 {dist_trainer.py:821}] <INFO> [  14/ 200] loss: (train=1.878, val=1.789, test=1.780, l2=15249.944), acc: (train=0.350, val=0.326, test=0.329), diff=0.00000081, proc(train=22.064sec, eval=11.484sec)
[2022-11-02 16:38:25,563 {dist_trainer.py:770}] <INFO> [  15/ 200] connecting edge count: 2
[2022-11-02 16:38:38,764 {dist_trainer.py:821}] <INFO> [  15/ 200] loss: (train=1.860, val=1.788, test=1.782, l2=15211.562), acc: (train=0.379, val=0.344, test=0.349), diff=0.00000099, proc(train=24.491sec, eval=11.755sec)
[2022-11-02 16:39:00,968 {dist_trainer.py:770}] <INFO> [  16/ 200] connecting edge count: 2
[2022-11-02 16:39:13,920 {dist_trainer.py:821}] <INFO> [  16/ 200] loss: (train=1.805, val=1.758, test=1.756, l2=15174.445), acc: (train=0.382, val=0.356, test=0.362), diff=0.00000069, proc(train=22.204sec, eval=11.458sec)
[2022-11-02 16:39:37,310 {dist_trainer.py:770}] <INFO> [  17/ 200] connecting edge count: 2
[2022-11-02 16:39:50,167 {dist_trainer.py:821}] <INFO> [  17/ 200] loss: (train=1.840, val=1.733, test=1.729, l2=15176.995), acc: (train=0.350, val=0.364, test=0.362), diff=0.00000126, proc(train=23.389sec, eval=11.826sec)
[2022-11-02 16:40:14,142 {dist_trainer.py:770}] <INFO> [  18/ 200] connecting edge count: 2
[2022-11-02 16:40:26,954 {dist_trainer.py:821}] <INFO> [  18/ 200] loss: (train=1.759, val=1.978, test=1.980, l2=15126.497), acc: (train=0.387, val=0.333, test=0.331), diff=0.00000080, proc(train=23.975sec, eval=11.563sec)
[2022-11-02 16:40:51,381 {dist_trainer.py:770}] <INFO> [  19/ 200] connecting edge count: 2
[2022-11-02 16:41:04,070 {dist_trainer.py:821}] <INFO> [  19/ 200] loss: (train=1.778, val=1.770, test=1.768, l2=15113.796), acc: (train=0.421, val=0.362, test=0.366), diff=0.00000036, proc(train=24.427sec, eval=11.626sec)
[2022-11-02 16:41:27,844 {dist_trainer.py:770}] <INFO> [  20/ 200] connecting edge count: 2
[2022-11-02 16:41:40,927 {dist_trainer.py:821}] <INFO> [  20/ 200] loss: (train=1.804, val=1.631, test=1.628, l2=15075.605), acc: (train=0.430, val=0.402, test=0.405), diff=0.00000059, proc(train=23.774sec, eval=11.796sec)
[2022-11-02 16:42:01,491 {dist_trainer.py:770}] <INFO> [  21/ 200] connecting edge count: 2
[2022-11-02 16:42:14,627 {dist_trainer.py:821}] <INFO> [  21/ 200] loss: (train=1.722, val=1.737, test=1.740, l2=15038.709), acc: (train=0.441, val=0.383, test=0.382), diff=0.00000092, proc(train=20.564sec, eval=11.629sec)
[2022-11-02 16:42:38,035 {dist_trainer.py:770}] <INFO> [  22/ 200] connecting edge count: 2
[2022-11-02 16:42:51,353 {dist_trainer.py:821}] <INFO> [  22/ 200] loss: (train=1.767, val=1.714, test=1.710, l2=15020.287), acc: (train=0.411, val=0.367, test=0.367), diff=0.00000085, proc(train=23.408sec, eval=11.823sec)
[2022-11-02 16:43:12,373 {dist_trainer.py:770}] <INFO> [  23/ 200] connecting edge count: 2
[2022-11-02 16:43:25,175 {dist_trainer.py:821}] <INFO> [  23/ 200] loss: (train=1.735, val=1.737, test=1.736, l2=14980.950), acc: (train=0.452, val=0.371, test=0.373), diff=0.00000058, proc(train=21.020sec, eval=11.679sec)
[2022-11-02 16:43:48,046 {dist_trainer.py:770}] <INFO> [  24/ 200] connecting edge count: 2
[2022-11-02 16:44:00,892 {dist_trainer.py:821}] <INFO> [  24/ 200] loss: (train=1.725, val=1.614, test=1.616, l2=14972.208), acc: (train=0.444, val=0.412, test=0.408), diff=0.00000053, proc(train=22.870sec, eval=11.818sec)
[2022-11-02 16:44:23,553 {dist_trainer.py:770}] <INFO> [  25/ 200] connecting edge count: 2
[2022-11-02 16:44:37,241 {dist_trainer.py:821}] <INFO> [  25/ 200] loss: (train=1.672, val=1.730, test=1.729, l2=14947.299), acc: (train=0.443, val=0.358, test=0.359), diff=0.00000071, proc(train=22.661sec, eval=11.839sec)
[2022-11-02 16:44:58,100 {dist_trainer.py:770}] <INFO> [  26/ 200] connecting edge count: 2
[2022-11-02 16:45:11,884 {dist_trainer.py:821}] <INFO> [  26/ 200] loss: (train=1.669, val=1.693, test=1.689, l2=14924.667), acc: (train=0.455, val=0.383, test=0.385), diff=0.00000098, proc(train=20.859sec, eval=11.661sec)
[2022-11-02 16:45:35,234 {dist_trainer.py:770}] <INFO> [  27/ 200] connecting edge count: 2
[2022-11-02 16:45:48,176 {dist_trainer.py:821}] <INFO> [  27/ 200] loss: (train=1.683, val=1.653, test=1.659, l2=14901.373), acc: (train=0.443, val=0.403, test=0.401), diff=0.00000076, proc(train=23.350sec, eval=11.943sec)
[2022-11-02 16:46:11,401 {dist_trainer.py:770}] <INFO> [  28/ 200] connecting edge count: 2
[2022-11-02 16:46:24,705 {dist_trainer.py:821}] <INFO> [  28/ 200] loss: (train=1.644, val=1.740, test=1.739, l2=14876.301), acc: (train=0.448, val=0.370, test=0.370), diff=0.00000076, proc(train=23.225sec, eval=11.712sec)
[2022-11-02 16:46:48,814 {dist_trainer.py:770}] <INFO> [  29/ 200] connecting edge count: 2
[2022-11-02 16:47:02,467 {dist_trainer.py:821}] <INFO> [  29/ 200] loss: (train=1.642, val=1.623, test=1.622, l2=14865.798), acc: (train=0.448, val=0.407, test=0.405), diff=0.00000077, proc(train=24.109sec, eval=11.863sec)
[2022-11-02 16:47:26,100 {dist_trainer.py:770}] <INFO> [  30/ 200] connecting edge count: 2
[2022-11-02 16:47:39,152 {dist_trainer.py:821}] <INFO> [  30/ 200] loss: (train=1.656, val=1.559, test=1.563, l2=14831.196), acc: (train=0.472, val=0.434, test=0.437), diff=0.00000066, proc(train=23.633sec, eval=11.638sec)
[2022-11-02 16:48:01,689 {dist_trainer.py:770}] <INFO> [  31/ 200] connecting edge count: 2
[2022-11-02 16:48:14,598 {dist_trainer.py:821}] <INFO> [  31/ 200] loss: (train=1.624, val=1.619, test=1.624, l2=14815.696), acc: (train=0.439, val=0.401, test=0.401), diff=2.18012619, proc(train=22.537sec, eval=11.786sec)
[2022-11-02 16:48:35,653 {dist_trainer.py:770}] <INFO> [  32/ 200] connecting edge count: 2
[2022-11-02 16:48:49,901 {dist_trainer.py:821}] <INFO> [  32/ 200] loss: (train=1.697, val=1.535, test=1.535, l2=12174.835), acc: (train=0.480, val=0.449, test=0.445), diff=0.00081140, proc(train=21.055sec, eval=11.892sec)
[2022-11-02 16:49:11,022 {dist_trainer.py:770}] <INFO> [  33/ 200] connecting edge count: 2
[2022-11-02 16:49:24,443 {dist_trainer.py:821}] <INFO> [  33/ 200] loss: (train=1.542, val=1.636, test=1.645, l2=12095.655), acc: (train=0.485, val=0.416, test=0.408), diff=0.00017328, proc(train=21.121sec, eval=11.682sec)
[2022-11-02 16:49:45,471 {dist_trainer.py:770}] <INFO> [  34/ 200] connecting edge count: 2
[2022-11-02 16:49:58,401 {dist_trainer.py:821}] <INFO> [  34/ 200] loss: (train=1.580, val=1.601, test=1.604, l2=11747.308), acc: (train=0.453, val=0.419, test=0.419), diff=0.00000150, proc(train=21.028sec, eval=11.843sec)
[2022-11-02 16:50:21,031 {dist_trainer.py:770}] <INFO> [  35/ 200] connecting edge count: 2
[2022-11-02 16:50:33,684 {dist_trainer.py:821}] <INFO> [  35/ 200] loss: (train=1.550, val=1.536, test=1.538, l2=11689.369), acc: (train=0.490, val=0.443, test=0.444), diff=0.00000089, proc(train=22.630sec, eval=11.494sec)
[2022-11-02 16:50:55,733 {dist_trainer.py:770}] <INFO> [  36/ 200] connecting edge count: 2
[2022-11-02 16:51:09,193 {dist_trainer.py:821}] <INFO> [  36/ 200] loss: (train=1.529, val=1.600, test=1.599, l2=11676.048), acc: (train=0.471, val=0.421, test=0.422), diff=0.00000044, proc(train=22.049sec, eval=11.740sec)
[2022-11-02 16:51:31,849 {dist_trainer.py:770}] <INFO> [  37/ 200] connecting edge count: 2
[2022-11-02 16:51:44,993 {dist_trainer.py:821}] <INFO> [  37/ 200] loss: (train=1.548, val=1.580, test=1.582, l2=11644.787), acc: (train=0.463, val=0.432, test=0.427), diff=0.00000052, proc(train=22.655sec, eval=11.827sec)
[2022-11-02 16:52:05,726 {dist_trainer.py:770}] <INFO> [  38/ 200] connecting edge count: 2
[2022-11-02 16:52:19,635 {dist_trainer.py:821}] <INFO> [  38/ 200] loss: (train=1.527, val=1.603, test=1.601, l2=11630.753), acc: (train=0.493, val=0.415, test=0.412), diff=0.00000088, proc(train=20.733sec, eval=11.568sec)
[2022-11-02 16:52:41,820 {dist_trainer.py:770}] <INFO> [  39/ 200] connecting edge count: 2
[2022-11-02 16:52:55,979 {dist_trainer.py:821}] <INFO> [  39/ 200] loss: (train=1.554, val=1.511, test=1.517, l2=11626.986), acc: (train=0.496, val=0.450, test=0.451), diff=0.00000042, proc(train=22.184sec, eval=11.878sec)
[2022-11-02 16:53:19,133 {dist_trainer.py:770}] <INFO> [  40/ 200] connecting edge count: 2
[2022-11-02 16:53:32,137 {dist_trainer.py:821}] <INFO> [  40/ 200] loss: (train=1.534, val=1.612, test=1.620, l2=11590.350), acc: (train=0.475, val=0.416, test=0.411), diff=0.00000123, proc(train=23.154sec, eval=11.661sec)
[2022-11-02 16:53:55,601 {dist_trainer.py:770}] <INFO> [  41/ 200] connecting edge count: 2
[2022-11-02 16:54:08,715 {dist_trainer.py:821}] <INFO> [  41/ 200] loss: (train=1.527, val=1.653, test=1.655, l2=11584.202), acc: (train=0.467, val=0.402, test=0.397), diff=0.00000056, proc(train=23.463sec, eval=11.850sec)
[2022-11-02 16:54:32,836 {dist_trainer.py:770}] <INFO> [  42/ 200] connecting edge count: 2
[2022-11-02 16:54:46,131 {dist_trainer.py:821}] <INFO> [  42/ 200] loss: (train=1.527, val=1.490, test=1.501, l2=11547.241), acc: (train=0.497, val=0.453, test=0.450), diff=0.00000054, proc(train=24.120sec, eval=11.679sec)
[2022-11-02 16:55:07,746 {dist_trainer.py:770}] <INFO> [  43/ 200] connecting edge count: 2
[2022-11-02 16:55:20,995 {dist_trainer.py:821}] <INFO> [  43/ 200] loss: (train=1.529, val=1.570, test=1.577, l2=11526.731), acc: (train=0.491, val=0.443, test=0.440), diff=0.00000116, proc(train=21.615sec, eval=11.752sec)
[2022-11-02 16:55:45,291 {dist_trainer.py:770}] <INFO> [  44/ 200] connecting edge count: 2
[2022-11-02 16:55:58,283 {dist_trainer.py:821}] <INFO> [  44/ 200] loss: (train=1.547, val=1.642, test=1.644, l2=11514.340), acc: (train=0.478, val=0.439, test=0.431), diff=0.00000071, proc(train=24.296sec, eval=11.851sec)
[2022-11-02 16:56:21,251 {dist_trainer.py:770}] <INFO> [  45/ 200] connecting edge count: 2
[2022-11-02 16:56:34,499 {dist_trainer.py:821}] <INFO> [  45/ 200] loss: (train=1.525, val=1.474, test=1.476, l2=11487.479), acc: (train=0.535, val=0.468, test=0.469), diff=0.00000093, proc(train=22.968sec, eval=11.632sec)
[2022-11-02 16:56:57,598 {dist_trainer.py:770}] <INFO> [  46/ 200] connecting edge count: 2
[2022-11-02 16:57:10,987 {dist_trainer.py:821}] <INFO> [  46/ 200] loss: (train=1.531, val=1.461, test=1.469, l2=11489.168), acc: (train=0.508, val=0.481, test=0.477), diff=0.00000119, proc(train=23.099sec, eval=11.765sec)
[2022-11-02 16:57:37,122 {dist_trainer.py:770}] <INFO> [  47/ 200] connecting edge count: 2
[2022-11-02 16:57:50,039 {dist_trainer.py:821}] <INFO> [  47/ 200] loss: (train=1.494, val=1.429, test=1.437, l2=11448.134), acc: (train=0.523, val=0.490, test=0.479), diff=0.00000088, proc(train=26.135sec, eval=11.592sec)
[2022-11-02 16:58:12,751 {dist_trainer.py:770}] <INFO> [  48/ 200] connecting edge count: 2
[2022-11-02 16:58:27,309 {dist_trainer.py:821}] <INFO> [  48/ 200] loss: (train=1.483, val=1.455, test=1.468, l2=11439.680), acc: (train=0.511, val=0.476, test=0.471), diff=0.00000051, proc(train=22.712sec, eval=11.814sec)
[2022-11-02 16:58:50,391 {dist_trainer.py:770}] <INFO> [  49/ 200] connecting edge count: 2
[2022-11-02 16:59:03,913 {dist_trainer.py:821}] <INFO> [  49/ 200] loss: (train=1.492, val=1.373, test=1.392, l2=11404.518), acc: (train=0.528, val=0.506, test=0.492), diff=0.00000043, proc(train=23.082sec, eval=11.705sec)
[2022-11-02 16:59:24,706 {dist_trainer.py:770}] <INFO> [  50/ 200] connecting edge count: 2
[2022-11-02 16:59:37,828 {dist_trainer.py:821}] <INFO> [  50/ 200] loss: (train=1.459, val=1.454, test=1.466, l2=11383.479), acc: (train=0.506, val=0.475, test=0.465), diff=0.00000086, proc(train=20.792sec, eval=11.672sec)
[2022-11-02 16:59:59,421 {dist_trainer.py:770}] <INFO> [  51/ 200] connecting edge count: 2
[2022-11-02 17:00:12,240 {dist_trainer.py:821}] <INFO> [  51/ 200] loss: (train=1.478, val=1.574, test=1.584, l2=11369.420), acc: (train=0.489, val=0.426, test=0.421), diff=0.00000050, proc(train=21.593sec, eval=11.738sec)
[2022-11-02 17:00:34,647 {dist_trainer.py:770}] <INFO> [  52/ 200] connecting edge count: 2
[2022-11-02 17:00:47,315 {dist_trainer.py:821}] <INFO> [  52/ 200] loss: (train=1.451, val=1.479, test=1.487, l2=11342.479), acc: (train=0.502, val=0.481, test=0.475), diff=0.00000058, proc(train=22.406sec, eval=11.461sec)
[2022-11-02 17:01:11,535 {dist_trainer.py:770}] <INFO> [  53/ 200] connecting edge count: 2
[2022-11-02 17:01:24,451 {dist_trainer.py:821}] <INFO> [  53/ 200] loss: (train=1.471, val=1.542, test=1.558, l2=11340.037), acc: (train=0.470, val=0.439, test=0.429), diff=0.00000045, proc(train=24.220sec, eval=11.898sec)
[2022-11-02 17:01:48,714 {dist_trainer.py:770}] <INFO> [  54/ 200] connecting edge count: 2
[2022-11-02 17:02:01,432 {dist_trainer.py:821}] <INFO> [  54/ 200] loss: (train=1.475, val=1.353, test=1.374, l2=11297.660), acc: (train=0.518, val=0.511, test=0.504), diff=0.00000044, proc(train=24.263sec, eval=11.474sec)
[2022-11-02 17:02:23,137 {dist_trainer.py:770}] <INFO> [  55/ 200] connecting edge count: 2
[2022-11-02 17:02:35,962 {dist_trainer.py:821}] <INFO> [  55/ 200] loss: (train=1.428, val=1.357, test=1.378, l2=11284.646), acc: (train=0.512, val=0.507, test=0.502), diff=0.00000046, proc(train=21.705sec, eval=11.671sec)
[2022-11-02 17:02:59,075 {dist_trainer.py:770}] <INFO> [  56/ 200] connecting edge count: 2
[2022-11-02 17:03:12,870 {dist_trainer.py:821}] <INFO> [  56/ 200] loss: (train=1.431, val=1.347, test=1.372, l2=11255.312), acc: (train=0.553, val=0.514, test=0.506), diff=0.00000052, proc(train=23.113sec, eval=11.847sec)
[2022-11-02 17:03:34,251 {dist_trainer.py:770}] <INFO> [  57/ 200] connecting edge count: 2
[2022-11-02 17:03:47,305 {dist_trainer.py:821}] <INFO> [  57/ 200] loss: (train=1.427, val=1.387, test=1.404, l2=11235.086), acc: (train=0.523, val=0.505, test=0.497), diff=0.00000101, proc(train=21.381sec, eval=11.475sec)
[2022-11-02 17:04:10,485 {dist_trainer.py:770}] <INFO> [  58/ 200] connecting edge count: 2
[2022-11-02 17:04:23,567 {dist_trainer.py:821}] <INFO> [  58/ 200] loss: (train=1.414, val=1.360, test=1.391, l2=11240.019), acc: (train=0.565, val=0.511, test=0.502), diff=0.00000071, proc(train=23.180sec, eval=11.806sec)
[2022-11-02 17:04:49,061 {dist_trainer.py:770}] <INFO> [  59/ 200] connecting edge count: 2
[2022-11-02 17:05:01,811 {dist_trainer.py:821}] <INFO> [  59/ 200] loss: (train=1.419, val=1.416, test=1.427, l2=11198.219), acc: (train=0.496, val=0.482, test=0.478), diff=0.00000083, proc(train=25.493sec, eval=11.535sec)
[2022-11-02 17:05:25,874 {dist_trainer.py:770}] <INFO> [  60/ 200] connecting edge count: 2
[2022-11-02 17:05:39,430 {dist_trainer.py:821}] <INFO> [  60/ 200] loss: (train=1.398, val=1.354, test=1.375, l2=11193.373), acc: (train=0.543, val=0.511, test=0.502), diff=0.00000049, proc(train=24.063sec, eval=11.756sec)
[2022-11-02 17:06:03,206 {dist_trainer.py:770}] <INFO> [  61/ 200] connecting edge count: 2
[2022-11-02 17:06:16,059 {dist_trainer.py:821}] <INFO> [  61/ 200] loss: (train=1.395, val=1.375, test=1.402, l2=11155.269), acc: (train=0.546, val=0.499, test=0.491), diff=0.00000040, proc(train=23.776sec, eval=11.599sec)
[2022-11-02 17:06:37,215 {dist_trainer.py:770}] <INFO> [  62/ 200] connecting edge count: 2
[2022-11-02 17:06:50,038 {dist_trainer.py:821}] <INFO> [  62/ 200] loss: (train=1.399, val=1.376, test=1.401, l2=11135.729), acc: (train=0.544, val=0.506, test=0.496), diff=0.00000102, proc(train=21.155sec, eval=11.476sec)
[2022-11-02 17:07:12,400 {dist_trainer.py:770}] <INFO> [  63/ 200] connecting edge count: 2
[2022-11-02 17:07:25,422 {dist_trainer.py:821}] <INFO> [  63/ 200] loss: (train=1.393, val=1.418, test=1.438, l2=11118.525), acc: (train=0.534, val=0.504, test=0.497), diff=0.00000052, proc(train=22.361sec, eval=11.749sec)
[2022-11-02 17:07:48,311 {dist_trainer.py:770}] <INFO> [  64/ 200] connecting edge count: 2
[2022-11-02 17:08:01,387 {dist_trainer.py:821}] <INFO> [  64/ 200] loss: (train=1.390, val=1.328, test=1.347, l2=11088.571), acc: (train=0.566, val=0.519, test=0.512), diff=0.00000088, proc(train=22.888sec, eval=11.587sec)
[2022-11-02 17:08:23,771 {dist_trainer.py:770}] <INFO> [  65/ 200] connecting edge count: 2
[2022-11-02 17:08:37,000 {dist_trainer.py:821}] <INFO> [  65/ 200] loss: (train=1.420, val=1.291, test=1.312, l2=11089.222), acc: (train=0.542, val=0.538, test=0.530), diff=0.00000077, proc(train=22.383sec, eval=11.744sec)
[2022-11-02 17:09:01,164 {dist_trainer.py:770}] <INFO> [  66/ 200] connecting edge count: 2
[2022-11-02 17:09:13,967 {dist_trainer.py:821}] <INFO> [  66/ 200] loss: (train=1.393, val=1.304, test=1.334, l2=11045.589), acc: (train=0.545, val=0.531, test=0.525), diff=0.00000038, proc(train=24.164sec, eval=11.472sec)
[2022-11-02 17:09:36,803 {dist_trainer.py:770}] <INFO> [  67/ 200] connecting edge count: 2
[2022-11-02 17:09:50,728 {dist_trainer.py:821}] <INFO> [  67/ 200] loss: (train=1.398, val=1.379, test=1.405, l2=11036.716), acc: (train=0.491, val=0.506, test=0.499), diff=0.00000040, proc(train=22.836sec, eval=11.664sec)
[2022-11-02 17:10:14,459 {dist_trainer.py:770}] <INFO> [  68/ 200] connecting edge count: 2
[2022-11-02 17:10:27,500 {dist_trainer.py:821}] <INFO> [  68/ 200] loss: (train=1.346, val=1.258, test=1.292, l2=11001.290), acc: (train=0.584, val=0.545, test=0.535), diff=0.00000066, proc(train=23.731sec, eval=11.695sec)
[2022-11-02 17:10:48,506 {dist_trainer.py:770}] <INFO> [  69/ 200] connecting edge count: 2
[2022-11-02 17:11:01,823 {dist_trainer.py:821}] <INFO> [  69/ 200] loss: (train=1.381, val=1.283, test=1.317, l2=10975.054), acc: (train=0.555, val=0.543, test=0.527), diff=0.00000098, proc(train=21.005sec, eval=11.575sec)
[2022-11-02 17:11:24,643 {dist_trainer.py:770}] <INFO> [  70/ 200] connecting edge count: 2
[2022-11-02 17:11:37,531 {dist_trainer.py:821}] <INFO> [  70/ 200] loss: (train=1.369, val=1.291, test=1.320, l2=10974.028), acc: (train=0.561, val=0.535, test=0.526), diff=0.00000036, proc(train=22.820sec, eval=11.756sec)
[2022-11-02 17:12:01,061 {dist_trainer.py:770}] <INFO> [  71/ 200] connecting edge count: 2
[2022-11-02 17:12:13,841 {dist_trainer.py:821}] <INFO> [  71/ 200] loss: (train=1.343, val=1.635, test=1.659, l2=10941.735), acc: (train=0.485, val=0.430, test=0.425), diff=0.00000070, proc(train=23.530sec, eval=11.497sec)
[2022-11-02 17:12:37,622 {dist_trainer.py:770}] <INFO> [  72/ 200] connecting edge count: 2
[2022-11-02 17:12:51,180 {dist_trainer.py:821}] <INFO> [  72/ 200] loss: (train=1.325, val=1.394, test=1.427, l2=10936.875), acc: (train=0.541, val=0.507, test=0.499), diff=0.00000036, proc(train=23.781sec, eval=11.777sec)
[2022-11-02 17:13:16,321 {dist_trainer.py:770}] <INFO> [  73/ 200] connecting edge count: 2
[2022-11-02 17:13:29,389 {dist_trainer.py:821}] <INFO> [  73/ 200] loss: (train=1.334, val=1.260, test=1.299, l2=10895.358), acc: (train=0.553, val=0.552, test=0.542), diff=0.00000027, proc(train=25.140sec, eval=11.475sec)
[2022-11-02 17:13:51,018 {dist_trainer.py:770}] <INFO> [  74/ 200] connecting edge count: 2
[2022-11-02 17:14:03,800 {dist_trainer.py:821}] <INFO> [  74/ 200] loss: (train=1.348, val=1.260, test=1.298, l2=10881.621), acc: (train=0.569, val=0.546, test=0.536), diff=0.00000071, proc(train=21.629sec, eval=11.502sec)
[2022-11-02 17:14:29,944 {dist_trainer.py:770}] <INFO> [  75/ 200] connecting edge count: 2
[2022-11-02 17:14:43,637 {dist_trainer.py:821}] <INFO> [  75/ 200] loss: (train=1.303, val=1.228, test=1.266, l2=10852.623), acc: (train=0.564, val=0.559, test=0.551), diff=0.00000046, proc(train=26.144sec, eval=11.659sec)
[2022-11-02 17:15:04,818 {dist_trainer.py:770}] <INFO> [  76/ 200] connecting edge count: 2
[2022-11-02 17:15:17,960 {dist_trainer.py:821}] <INFO> [  76/ 200] loss: (train=1.321, val=1.264, test=1.301, l2=10829.727), acc: (train=0.534, val=0.542, test=0.527), diff=0.00000089, proc(train=21.181sec, eval=11.510sec)
[2022-11-02 17:15:40,883 {dist_trainer.py:770}] <INFO> [  77/ 200] connecting edge count: 2
[2022-11-02 17:15:55,368 {dist_trainer.py:821}] <INFO> [  77/ 200] loss: (train=1.335, val=1.329, test=1.374, l2=10833.370), acc: (train=0.560, val=0.530, test=0.525), diff=0.00000067, proc(train=22.922sec, eval=11.876sec)
[2022-11-02 17:16:19,159 {dist_trainer.py:770}] <INFO> [  78/ 200] connecting edge count: 2
[2022-11-02 17:16:31,717 {dist_trainer.py:821}] <INFO> [  78/ 200] loss: (train=1.319, val=1.262, test=1.305, l2=10798.114), acc: (train=0.553, val=0.543, test=0.528), diff=0.00000058, proc(train=23.791sec, eval=11.429sec)
[2022-11-02 17:16:55,407 {dist_trainer.py:770}] <INFO> [  79/ 200] connecting edge count: 2
[2022-11-02 17:17:09,096 {dist_trainer.py:821}] <INFO> [  79/ 200] loss: (train=1.313, val=1.235, test=1.276, l2=10794.072), acc: (train=0.562, val=0.555, test=0.545), diff=0.00000036, proc(train=23.690sec, eval=11.852sec)
[2022-11-02 17:17:33,663 {dist_trainer.py:770}] <INFO> [  80/ 200] connecting edge count: 2
[2022-11-02 17:17:46,520 {dist_trainer.py:821}] <INFO> [  80/ 200] loss: (train=1.301, val=1.242, test=1.289, l2=10754.632), acc: (train=0.543, val=0.555, test=0.540), diff=0.00000043, proc(train=24.566sec, eval=11.457sec)
[2022-11-02 17:18:08,514 {dist_trainer.py:770}] <INFO> [  81/ 200] connecting edge count: 2
[2022-11-02 17:18:22,108 {dist_trainer.py:821}] <INFO> [  81/ 200] loss: (train=1.277, val=1.233, test=1.276, l2=10739.715), acc: (train=0.602, val=0.561, test=0.545), diff=0.00000081, proc(train=21.993sec, eval=11.539sec)
[2022-11-02 17:18:46,236 {dist_trainer.py:770}] <INFO> [  82/ 200] connecting edge count: 2
[2022-11-02 17:19:00,579 {dist_trainer.py:821}] <INFO> [  82/ 200] loss: (train=1.280, val=1.323, test=1.366, l2=10713.214), acc: (train=0.564, val=0.530, test=0.519), diff=0.00000051, proc(train=24.127sec, eval=11.786sec)
[2022-11-02 17:19:22,295 {dist_trainer.py:770}] <INFO> [  83/ 200] connecting edge count: 2
[2022-11-02 17:19:35,695 {dist_trainer.py:821}] <INFO> [  83/ 200] loss: (train=1.301, val=1.277, test=1.307, l2=10701.637), acc: (train=0.587, val=0.548, test=0.539), diff=0.00000088, proc(train=21.715sec, eval=11.636sec)
[2022-11-02 17:19:58,480 {dist_trainer.py:770}] <INFO> [  84/ 200] connecting edge count: 2
[2022-11-02 17:20:11,431 {dist_trainer.py:821}] <INFO> [  84/ 200] loss: (train=1.279, val=1.237, test=1.289, l2=10700.979), acc: (train=0.581, val=0.560, test=0.549), diff=0.00000049, proc(train=22.785sec, eval=11.881sec)
[2022-11-02 17:20:35,150 {dist_trainer.py:770}] <INFO> [  85/ 200] connecting edge count: 2
[2022-11-02 17:20:47,910 {dist_trainer.py:821}] <INFO> [  85/ 200] loss: (train=1.263, val=1.197, test=1.238, l2=10663.934), acc: (train=0.598, val=0.576, test=0.564), diff=0.00000058, proc(train=23.719sec, eval=11.583sec)
[2022-11-02 17:21:11,330 {dist_trainer.py:770}] <INFO> [  86/ 200] connecting edge count: 2
[2022-11-02 17:21:24,295 {dist_trainer.py:821}] <INFO> [  86/ 200] loss: (train=1.236, val=1.239, test=1.278, l2=10658.630), acc: (train=0.620, val=0.556, test=0.538), diff=0.00000043, proc(train=23.420sec, eval=11.708sec)
[2022-11-02 17:21:47,596 {dist_trainer.py:770}] <INFO> [  87/ 200] connecting edge count: 2
[2022-11-02 17:22:00,482 {dist_trainer.py:821}] <INFO> [  87/ 200] loss: (train=1.264, val=1.156, test=1.213, l2=10620.215), acc: (train=0.599, val=0.591, test=0.571), diff=0.00000035, proc(train=23.301sec, eval=11.623sec)
[2022-11-02 17:22:21,831 {dist_trainer.py:770}] <INFO> [  88/ 200] connecting edge count: 2
[2022-11-02 17:22:35,239 {dist_trainer.py:821}] <INFO> [  88/ 200] loss: (train=1.237, val=1.151, test=1.204, l2=10599.706), acc: (train=0.597, val=0.591, test=0.575), diff=0.00000061, proc(train=21.349sec, eval=11.505sec)
[2022-11-02 17:22:57,375 {dist_trainer.py:770}] <INFO> [  89/ 200] connecting edge count: 2
[2022-11-02 17:23:11,011 {dist_trainer.py:821}] <INFO> [  89/ 200] loss: (train=1.240, val=1.204, test=1.258, l2=10588.201), acc: (train=0.601, val=0.575, test=0.558), diff=0.00000050, proc(train=22.136sec, eval=11.773sec)
[2022-11-02 17:23:34,322 {dist_trainer.py:770}] <INFO> [  90/ 200] connecting edge count: 2
[2022-11-02 17:23:47,209 {dist_trainer.py:821}] <INFO> [  90/ 200] loss: (train=1.228, val=1.205, test=1.266, l2=10560.790), acc: (train=0.596, val=0.579, test=0.558), diff=0.00000055, proc(train=23.310sec, eval=11.442sec)
[2022-11-02 17:24:11,279 {dist_trainer.py:770}] <INFO> [  91/ 200] connecting edge count: 2
[2022-11-02 17:24:24,177 {dist_trainer.py:821}] <INFO> [  91/ 200] loss: (train=1.273, val=1.182, test=1.232, l2=10557.551), acc: (train=0.587, val=0.579, test=0.561), diff=0.00000041, proc(train=24.070sec, eval=11.858sec)
[2022-11-02 17:24:50,724 {dist_trainer.py:770}] <INFO> [  92/ 200] connecting edge count: 2
[2022-11-02 17:25:03,422 {dist_trainer.py:821}] <INFO> [  92/ 200] loss: (train=1.247, val=1.217, test=1.282, l2=10518.650), acc: (train=0.606, val=0.567, test=0.546), diff=0.00000047, proc(train=26.547sec, eval=11.437sec)
[2022-11-02 17:25:25,740 {dist_trainer.py:770}] <INFO> [  93/ 200] connecting edge count: 2
[2022-11-02 17:25:38,553 {dist_trainer.py:821}] <INFO> [  93/ 200] loss: (train=1.285, val=1.180, test=1.231, l2=10511.252), acc: (train=0.612, val=0.581, test=0.564), diff=0.00000048, proc(train=22.318sec, eval=11.647sec)
[2022-11-02 17:26:02,016 {dist_trainer.py:770}] <INFO> [  94/ 200] connecting edge count: 2
[2022-11-02 17:26:16,204 {dist_trainer.py:821}] <INFO> [  94/ 200] loss: (train=1.223, val=1.283, test=1.335, l2=10480.757), acc: (train=0.531, val=0.541, test=0.526), diff=0.00000048, proc(train=23.463sec, eval=11.767sec)
[2022-11-02 17:26:37,353 {dist_trainer.py:770}] <INFO> [  95/ 200] connecting edge count: 2
[2022-11-02 17:26:50,609 {dist_trainer.py:821}] <INFO> [  95/ 200] loss: (train=1.269, val=1.308, test=1.351, l2=10455.393), acc: (train=0.558, val=0.543, test=0.533), diff=0.00000114, proc(train=21.149sec, eval=11.486sec)
[2022-11-02 17:27:13,815 {dist_trainer.py:770}] <INFO> [  96/ 200] connecting edge count: 2
[2022-11-02 17:27:27,685 {dist_trainer.py:821}] <INFO> [  96/ 200] loss: (train=1.329, val=1.193, test=1.253, l2=10458.538), acc: (train=0.579, val=0.573, test=0.556), diff=0.00000065, proc(train=23.206sec, eval=11.715sec)
[2022-11-02 17:27:52,112 {dist_trainer.py:770}] <INFO> [  97/ 200] connecting edge count: 2
[2022-11-02 17:28:04,851 {dist_trainer.py:821}] <INFO> [  97/ 200] loss: (train=1.244, val=1.160, test=1.216, l2=10421.574), acc: (train=0.630, val=0.594, test=0.575), diff=0.00000053, proc(train=24.427sec, eval=11.490sec)
[2022-11-02 17:28:28,718 {dist_trainer.py:770}] <INFO> [  98/ 200] connecting edge count: 2
[2022-11-02 17:28:41,787 {dist_trainer.py:821}] <INFO> [  98/ 200] loss: (train=1.233, val=1.202, test=1.259, l2=10417.297), acc: (train=0.561, val=0.565, test=0.548), diff=0.00000044, proc(train=23.866sec, eval=11.823sec)
[2022-11-02 17:29:04,856 {dist_trainer.py:770}] <INFO> [  99/ 200] connecting edge count: 2
[2022-11-02 17:29:17,951 {dist_trainer.py:821}] <INFO> [  99/ 200] loss: (train=1.221, val=1.112, test=1.180, l2=10381.257), acc: (train=0.635, val=0.606, test=0.583), diff=0.00000036, proc(train=23.069sec, eval=11.542sec)
[2022-11-02 17:29:39,289 {dist_trainer.py:770}] <INFO> [ 100/ 200] connecting edge count: 2
[2022-11-02 17:29:52,113 {dist_trainer.py:821}] <INFO> [ 100/ 200] loss: (train=1.189, val=1.147, test=1.206, l2=10363.644), acc: (train=0.596, val=0.588, test=0.571), diff=0.00000070, proc(train=21.338sec, eval=11.521sec)
[2022-11-02 17:30:15,973 {dist_trainer.py:770}] <INFO> [ 101/ 200] connecting edge count: 2
[2022-11-02 17:30:28,821 {dist_trainer.py:821}] <INFO> [ 101/ 200] loss: (train=1.194, val=1.083, test=1.154, l2=10344.572), acc: (train=0.633, val=0.617, test=0.596), diff=0.00000055, proc(train=23.860sec, eval=11.762sec)
[2022-11-02 17:30:51,731 {dist_trainer.py:770}] <INFO> [ 102/ 200] connecting edge count: 2
[2022-11-02 17:31:04,704 {dist_trainer.py:821}] <INFO> [ 102/ 200] loss: (train=1.197, val=1.138, test=1.200, l2=10328.857), acc: (train=0.646, val=0.598, test=0.574), diff=0.00000077, proc(train=22.910sec, eval=11.489sec)
[2022-11-02 17:31:28,164 {dist_trainer.py:770}] <INFO> [ 103/ 200] connecting edge count: 2
[2022-11-02 17:31:41,029 {dist_trainer.py:821}] <INFO> [ 103/ 200] loss: (train=1.195, val=1.132, test=1.198, l2=10328.489), acc: (train=0.612, val=0.602, test=0.584), diff=0.00000082, proc(train=23.460sec, eval=11.737sec)
[2022-11-02 17:32:06,776 {dist_trainer.py:770}] <INFO> [ 104/ 200] connecting edge count: 2
[2022-11-02 17:32:20,009 {dist_trainer.py:821}] <INFO> [ 104/ 200] loss: (train=1.188, val=1.110, test=1.180, l2=10289.713), acc: (train=0.603, val=0.607, test=0.591), diff=0.00000036, proc(train=25.747sec, eval=11.466sec)
[2022-11-02 17:32:42,584 {dist_trainer.py:770}] <INFO> [ 105/ 200] connecting edge count: 2
[2022-11-02 17:32:56,321 {dist_trainer.py:821}] <INFO> [ 105/ 200] loss: (train=1.241, val=1.103, test=1.173, l2=10280.501), acc: (train=0.615, val=0.608, test=0.587), diff=0.00000040, proc(train=22.575sec, eval=11.631sec)
[2022-11-02 17:33:20,841 {dist_trainer.py:770}] <INFO> [ 106/ 200] connecting edge count: 2
[2022-11-02 17:33:34,127 {dist_trainer.py:821}] <INFO> [ 106/ 200] loss: (train=1.153, val=1.111, test=1.188, l2=10248.881), acc: (train=0.615, val=0.610, test=0.585), diff=0.00000036, proc(train=24.519sec, eval=11.753sec)
[2022-11-02 17:33:54,891 {dist_trainer.py:770}] <INFO> [ 107/ 200] connecting edge count: 2
[2022-11-02 17:34:07,873 {dist_trainer.py:821}] <INFO> [ 107/ 200] loss: (train=1.169, val=1.218, test=1.288, l2=10228.912), acc: (train=0.580, val=0.562, test=0.542), diff=0.00000067, proc(train=20.763sec, eval=11.506sec)
[2022-11-02 17:34:30,502 {dist_trainer.py:770}] <INFO> [ 108/ 200] connecting edge count: 2
[2022-11-02 17:34:44,247 {dist_trainer.py:821}] <INFO> [ 108/ 200] loss: (train=1.189, val=1.121, test=1.197, l2=10220.025), acc: (train=0.610, val=0.601, test=0.580), diff=0.00000041, proc(train=22.629sec, eval=11.789sec)
[2022-11-02 17:35:08,855 {dist_trainer.py:770}] <INFO> [ 109/ 200] connecting edge count: 2
[2022-11-02 17:35:22,300 {dist_trainer.py:821}] <INFO> [ 109/ 200] loss: (train=1.161, val=1.087, test=1.173, l2=10191.309), acc: (train=0.624, val=0.615, test=0.591), diff=0.00000053, proc(train=24.608sec, eval=11.503sec)
[2022-11-02 17:35:45,062 {dist_trainer.py:770}] <INFO> [ 110/ 200] connecting edge count: 2
[2022-11-02 17:35:57,950 {dist_trainer.py:821}] <INFO> [ 110/ 200] loss: (train=1.172, val=1.077, test=1.148, l2=10189.135), acc: (train=0.628, val=0.620, test=0.593), diff=0.00000032, proc(train=22.762sec, eval=11.840sec)
[2022-11-02 17:36:22,680 {dist_trainer.py:770}] <INFO> [ 111/ 200] connecting edge count: 2
[2022-11-02 17:36:35,963 {dist_trainer.py:821}] <INFO> [ 111/ 200] loss: (train=1.146, val=1.089, test=1.173, l2=10152.325), acc: (train=0.610, val=0.620, test=0.595), diff=0.00000034, proc(train=24.729sec, eval=11.398sec)
[2022-11-02 17:36:58,232 {dist_trainer.py:770}] <INFO> [ 112/ 200] connecting edge count: 2
[2022-11-02 17:37:12,267 {dist_trainer.py:821}] <INFO> [ 112/ 200] loss: (train=1.167, val=1.136, test=1.210, l2=10140.716), acc: (train=0.594, val=0.591, test=0.570), diff=0.00000033, proc(train=22.269sec, eval=11.673sec)
[2022-11-02 17:37:36,502 {dist_trainer.py:770}] <INFO> [ 113/ 200] connecting edge count: 2
[2022-11-02 17:37:50,138 {dist_trainer.py:821}] <INFO> [ 113/ 200] loss: (train=1.145, val=1.102, test=1.172, l2=10108.410), acc: (train=0.640, val=0.609, test=0.589), diff=0.00000043, proc(train=24.235sec, eval=11.670sec)
[2022-11-02 17:38:11,358 {dist_trainer.py:770}] <INFO> [ 114/ 200] connecting edge count: 2
[2022-11-02 17:38:24,671 {dist_trainer.py:821}] <INFO> [ 114/ 200] loss: (train=1.128, val=1.064, test=1.140, l2=10087.823), acc: (train=0.645, val=0.632, test=0.604), diff=0.00000067, proc(train=21.219sec, eval=11.502sec)
[2022-11-02 17:38:47,932 {dist_trainer.py:770}] <INFO> [ 115/ 200] connecting edge count: 2
[2022-11-02 17:39:02,326 {dist_trainer.py:821}] <INFO> [ 115/ 200] loss: (train=1.139, val=1.078, test=1.172, l2=10080.342), acc: (train=0.631, val=0.624, test=0.599), diff=0.00000075, proc(train=23.261sec, eval=11.831sec)
[2022-11-02 17:39:25,937 {dist_trainer.py:770}] <INFO> [ 116/ 200] connecting edge count: 2
[2022-11-02 17:39:38,895 {dist_trainer.py:821}] <INFO> [ 116/ 200] loss: (train=1.135, val=1.085, test=1.167, l2=10060.154), acc: (train=0.586, val=0.613, test=0.591), diff=0.00000066, proc(train=23.611sec, eval=11.473sec)
[2022-11-02 17:40:02,310 {dist_trainer.py:770}] <INFO> [ 117/ 200] connecting edge count: 2
[2022-11-02 17:40:15,130 {dist_trainer.py:821}] <INFO> [ 117/ 200] loss: (train=1.162, val=1.046, test=1.122, l2=10058.220), acc: (train=0.650, val=0.632, test=0.606), diff=0.00000047, proc(train=23.414sec, eval=11.802sec)
[2022-11-02 17:40:39,646 {dist_trainer.py:770}] <INFO> [ 118/ 200] connecting edge count: 2
[2022-11-02 17:40:52,546 {dist_trainer.py:821}] <INFO> [ 118/ 200] loss: (train=1.136, val=1.098, test=1.189, l2=10021.643), acc: (train=0.652, val=0.613, test=0.583), diff=0.00000030, proc(train=24.516sec, eval=11.465sec)
[2022-11-02 17:41:14,847 {dist_trainer.py:770}] <INFO> [ 119/ 200] connecting edge count: 2
[2022-11-02 17:41:27,432 {dist_trainer.py:821}] <INFO> [ 119/ 200] loss: (train=1.159, val=1.078, test=1.159, l2=10006.565), acc: (train=0.635, val=0.618, test=0.592), diff=0.00000051, proc(train=22.301sec, eval=11.529sec)
[2022-11-02 17:41:52,277 {dist_trainer.py:770}] <INFO> [ 120/ 200] connecting edge count: 2
[2022-11-02 17:42:05,381 {dist_trainer.py:821}] <INFO> [ 120/ 200] loss: (train=1.100, val=1.086, test=1.173, l2=9981.072), acc: (train=0.644, val=0.623, test=0.593), diff=0.00000038, proc(train=24.845sec, eval=11.711sec)
[2022-11-02 17:42:26,218 {dist_trainer.py:770}] <INFO> [ 121/ 200] connecting edge count: 2
[2022-11-02 17:42:40,486 {dist_trainer.py:821}] <INFO> [ 121/ 200] loss: (train=1.144, val=1.115, test=1.201, l2=9960.135), acc: (train=0.628, val=0.613, test=0.586), diff=0.00000085, proc(train=20.838sec, eval=11.457sec)
[2022-11-02 17:43:02,712 {dist_trainer.py:770}] <INFO> [ 122/ 200] connecting edge count: 2
[2022-11-02 17:43:15,538 {dist_trainer.py:821}] <INFO> [ 122/ 200] loss: (train=1.202, val=1.056, test=1.147, l2=9967.261), acc: (train=0.649, val=0.630, test=0.603), diff=0.00000067, proc(train=22.226sec, eval=11.698sec)
[2022-11-02 17:43:39,302 {dist_trainer.py:770}] <INFO> [ 123/ 200] connecting edge count: 2
[2022-11-02 17:43:52,129 {dist_trainer.py:821}] <INFO> [ 123/ 200] loss: (train=1.111, val=1.058, test=1.159, l2=9928.028), acc: (train=0.650, val=0.627, test=0.597), diff=0.00000048, proc(train=23.763sec, eval=11.472sec)
[2022-11-02 17:44:15,424 {dist_trainer.py:770}] <INFO> [ 124/ 200] connecting edge count: 2
[2022-11-02 17:44:28,288 {dist_trainer.py:821}] <INFO> [ 124/ 200] loss: (train=1.106, val=1.081, test=1.187, l2=9925.709), acc: (train=0.608, val=0.619, test=0.586), diff=0.00000035, proc(train=23.289sec, eval=11.596sec)
[2022-11-02 17:44:54,485 {dist_trainer.py:770}] <INFO> [ 125/ 200] connecting edge count: 2
[2022-11-02 17:45:07,413 {dist_trainer.py:821}] <INFO> [ 125/ 200] loss: (train=1.079, val=1.065, test=1.167, l2=9887.938), acc: (train=0.637, val=0.625, test=0.594), diff=0.00000034, proc(train=26.197sec, eval=11.603sec)
[2022-11-02 17:45:29,115 {dist_trainer.py:770}] <INFO> [ 126/ 200] connecting edge count: 2
[2022-11-02 17:45:42,065 {dist_trainer.py:821}] <INFO> [ 126/ 200] loss: (train=1.104, val=1.114, test=1.195, l2=9871.792), acc: (train=0.631, val=0.602, test=0.581), diff=0.00000075, proc(train=21.701sec, eval=11.509sec)
[2022-11-02 17:46:06,661 {dist_trainer.py:770}] <INFO> [ 127/ 200] connecting edge count: 2
[2022-11-02 17:46:19,931 {dist_trainer.py:821}] <INFO> [ 127/ 200] loss: (train=1.106, val=1.023, test=1.131, l2=9850.862), acc: (train=0.646, val=0.644, test=0.614), diff=0.00000042, proc(train=24.595sec, eval=11.721sec)
[2022-11-02 17:46:42,115 {dist_trainer.py:770}] <INFO> [ 128/ 200] connecting edge count: 2
[2022-11-02 17:46:55,422 {dist_trainer.py:821}] <INFO> [ 128/ 200] loss: (train=1.093, val=0.999, test=1.099, l2=9828.063), acc: (train=0.652, val=0.653, test=0.622), diff=0.00000071, proc(train=22.183sec, eval=11.449sec)
[2022-11-02 17:47:18,853 {dist_trainer.py:770}] <INFO> [ 129/ 200] connecting edge count: 2
[2022-11-02 17:47:32,033 {dist_trainer.py:821}] <INFO> [ 129/ 200] loss: (train=1.119, val=1.037, test=1.142, l2=9836.415), acc: (train=0.623, val=0.637, test=0.605), diff=0.00000082, proc(train=23.431sec, eval=11.680sec)
[2022-11-02 17:47:55,929 {dist_trainer.py:770}] <INFO> [ 130/ 200] connecting edge count: 2
[2022-11-02 17:48:08,723 {dist_trainer.py:821}] <INFO> [ 130/ 200] loss: (train=1.067, val=0.993, test=1.098, l2=9797.729), acc: (train=0.655, val=0.650, test=0.620), diff=0.00000041, proc(train=23.895sec, eval=11.457sec)
[2022-11-02 17:48:32,469 {dist_trainer.py:770}] <INFO> [ 131/ 200] connecting edge count: 2
[2022-11-02 17:48:46,830 {dist_trainer.py:821}] <INFO> [ 131/ 200] loss: (train=1.127, val=1.062, test=1.144, l2=9795.330), acc: (train=0.632, val=0.621, test=0.591), diff=0.00000033, proc(train=23.745sec, eval=11.682sec)
[2022-11-02 17:49:15,610 {dist_trainer.py:770}] <INFO> [ 132/ 200] connecting edge count: 2
[2022-11-02 17:49:28,221 {dist_trainer.py:821}] <INFO> [ 132/ 200] loss: (train=1.074, val=1.001, test=1.115, l2=9757.257), acc: (train=0.666, val=0.653, test=0.621), diff=0.00000046, proc(train=28.780sec, eval=11.397sec)
[2022-11-02 17:49:50,540 {dist_trainer.py:770}] <INFO> [ 133/ 200] connecting edge count: 2
[2022-11-02 17:50:03,181 {dist_trainer.py:821}] <INFO> [ 133/ 200] loss: (train=1.109, val=1.026, test=1.138, l2=9750.688), acc: (train=0.623, val=0.638, test=0.602), diff=0.00000040, proc(train=22.319sec, eval=11.563sec)
[2022-11-02 17:50:27,954 {dist_trainer.py:770}] <INFO> [ 134/ 200] connecting edge count: 2
[2022-11-02 17:50:41,581 {dist_trainer.py:821}] <INFO> [ 134/ 200] loss: (train=1.047, val=0.945, test=1.067, l2=9720.229), acc: (train=0.666, val=0.670, test=0.633), diff=0.00000053, proc(train=24.772sec, eval=11.622sec)
[2022-11-02 17:51:02,875 {dist_trainer.py:770}] <INFO> [ 135/ 200] connecting edge count: 2
[2022-11-02 17:51:16,109 {dist_trainer.py:821}] <INFO> [ 135/ 200] loss: (train=1.080, val=0.998, test=1.108, l2=9701.916), acc: (train=0.660, val=0.650, test=0.615), diff=0.00000058, proc(train=21.294sec, eval=11.455sec)
[2022-11-02 17:51:39,007 {dist_trainer.py:770}] <INFO> [ 136/ 200] connecting edge count: 2
[2022-11-02 17:51:52,012 {dist_trainer.py:821}] <INFO> [ 136/ 200] loss: (train=1.117, val=1.000, test=1.112, l2=9691.396), acc: (train=0.643, val=0.655, test=0.627), diff=0.00000065, proc(train=22.898sec, eval=11.667sec)
[2022-11-02 17:52:14,909 {dist_trainer.py:770}] <INFO> [ 137/ 200] connecting edge count: 2
[2022-11-02 17:52:27,602 {dist_trainer.py:821}] <INFO> [ 137/ 200] loss: (train=1.055, val=0.998, test=1.106, l2=9670.729), acc: (train=0.658, val=0.654, test=0.621), diff=0.00000052, proc(train=22.897sec, eval=11.452sec)
[2022-11-02 17:52:50,859 {dist_trainer.py:770}] <INFO> [ 138/ 200] connecting edge count: 2
[2022-11-02 17:53:04,227 {dist_trainer.py:821}] <INFO> [ 138/ 200] loss: (train=1.077, val=1.047, test=1.147, l2=9668.525), acc: (train=0.635, val=0.638, test=0.604), diff=0.00000033, proc(train=23.256sec, eval=11.772sec)
[2022-11-02 17:53:30,598 {dist_trainer.py:770}] <INFO> [ 139/ 200] connecting edge count: 2
[2022-11-02 17:53:43,833 {dist_trainer.py:821}] <INFO> [ 139/ 200] loss: (train=1.067, val=1.038, test=1.160, l2=9630.763), acc: (train=0.677, val=0.638, test=0.603), diff=0.00000041, proc(train=26.371sec, eval=11.395sec)
[2022-11-02 17:54:06,795 {dist_trainer.py:770}] <INFO> [ 140/ 200] connecting edge count: 2
[2022-11-02 17:54:20,526 {dist_trainer.py:821}] <INFO> [ 140/ 200] loss: (train=1.059, val=0.979, test=1.080, l2=9621.749), acc: (train=0.661, val=0.659, test=0.625), diff=0.00000034, proc(train=22.962sec, eval=11.548sec)
[2022-11-02 17:54:46,078 {dist_trainer.py:770}] <INFO> [ 141/ 200] connecting edge count: 2
[2022-11-02 17:54:58,912 {dist_trainer.py:821}] <INFO> [ 141/ 200] loss: (train=1.021, val=0.971, test=1.094, l2=9590.424), acc: (train=0.625, val=0.658, test=0.620), diff=0.00000042, proc(train=25.552sec, eval=11.621sec)
[2022-11-02 17:55:20,240 {dist_trainer.py:770}] <INFO> [ 142/ 200] connecting edge count: 2
[2022-11-02 17:55:33,374 {dist_trainer.py:821}] <INFO> [ 142/ 200] loss: (train=1.048, val=1.020, test=1.120, l2=9572.110), acc: (train=0.662, val=0.646, test=0.617), diff=0.00000071, proc(train=21.328sec, eval=11.509sec)
[2022-11-02 17:55:56,057 {dist_trainer.py:770}] <INFO> [ 143/ 200] connecting edge count: 2
[2022-11-02 17:56:09,909 {dist_trainer.py:821}] <INFO> [ 143/ 200] loss: (train=1.073, val=1.060, test=1.171, l2=9563.603), acc: (train=0.652, val=0.634, test=0.602), diff=0.00000042, proc(train=22.683sec, eval=11.683sec)
[2022-11-02 17:56:33,163 {dist_trainer.py:770}] <INFO> [ 144/ 200] connecting edge count: 2
[2022-11-02 17:56:46,136 {dist_trainer.py:821}] <INFO> [ 144/ 200] loss: (train=1.039, val=1.063, test=1.180, l2=9538.157), acc: (train=0.654, val=0.627, test=0.592), diff=0.00000057, proc(train=23.254sec, eval=11.489sec)
[2022-11-02 17:57:10,295 {dist_trainer.py:770}] <INFO> [ 145/ 200] connecting edge count: 2
[2022-11-02 17:57:23,515 {dist_trainer.py:821}] <INFO> [ 145/ 200] loss: (train=1.074, val=0.983, test=1.088, l2=9535.338), acc: (train=0.660, val=0.651, test=0.617), diff=0.12771870, proc(train=24.159sec, eval=11.719sec)
[2022-11-02 17:57:48,865 {dist_trainer.py:770}] <INFO> [ 146/ 200] connecting edge count: 2
[2022-11-02 17:58:01,558 {dist_trainer.py:821}] <INFO> [ 146/ 200] loss: (train=1.099, val=0.931, test=1.061, l2=10067.678), acc: (train=0.684, val=0.675, test=0.635), diff=0.00013714, proc(train=25.349sec, eval=11.452sec)
[2022-11-02 17:58:23,644 {dist_trainer.py:770}] <INFO> [ 147/ 200] connecting edge count: 2
[2022-11-02 17:58:36,950 {dist_trainer.py:821}] <INFO> [ 147/ 200] loss: (train=0.997, val=0.947, test=1.058, l2=10470.601), acc: (train=0.689, val=0.670, test=0.633), diff=0.00010128, proc(train=22.085sec, eval=11.591sec)
[2022-11-02 17:59:02,363 {dist_trainer.py:770}] <INFO> [ 148/ 200] connecting edge count: 2
[2022-11-02 17:59:15,176 {dist_trainer.py:821}] <INFO> [ 148/ 200] loss: (train=1.023, val=0.942, test=1.073, l2=10260.367), acc: (train=0.652, val=0.670, test=0.632), diff=0.00000248, proc(train=25.412sec, eval=11.578sec)
[2022-11-02 17:59:36,322 {dist_trainer.py:770}] <INFO> [ 149/ 200] connecting edge count: 2
[2022-11-02 17:59:49,716 {dist_trainer.py:821}] <INFO> [ 149/ 200] loss: (train=1.028, val=0.959, test=1.077, l2=10196.596), acc: (train=0.677, val=0.660, test=0.626), diff=0.00000073, proc(train=21.146sec, eval=11.463sec)
[2022-11-02 18:00:12,087 {dist_trainer.py:770}] <INFO> [ 150/ 200] connecting edge count: 2
[2022-11-02 18:00:25,153 {dist_trainer.py:821}] <INFO> [ 150/ 200] loss: (train=1.031, val=0.911, test=1.046, l2=10192.593), acc: (train=0.694, val=0.683, test=0.640), diff=0.00000038, proc(train=22.371sec, eval=11.845sec)
[2022-11-02 18:00:49,133 {dist_trainer.py:770}] <INFO> [ 151/ 200] connecting edge count: 2
[2022-11-02 18:01:01,861 {dist_trainer.py:821}] <INFO> [ 151/ 200] loss: (train=1.018, val=0.904, test=1.034, l2=10166.770), acc: (train=0.683, val=0.683, test=0.638), diff=0.00000064, proc(train=23.980sec, eval=11.464sec)
[2022-11-02 18:01:26,046 {dist_trainer.py:770}] <INFO> [ 152/ 200] connecting edge count: 2
[2022-11-02 18:01:39,637 {dist_trainer.py:821}] <INFO> [ 152/ 200] loss: (train=1.058, val=1.014, test=1.126, l2=10164.589), acc: (train=0.625, val=0.640, test=0.604), diff=0.00000036, proc(train=24.184sec, eval=11.806sec)
[2022-11-02 18:02:02,833 {dist_trainer.py:770}] <INFO> [ 153/ 200] connecting edge count: 2
[2022-11-02 18:02:15,662 {dist_trainer.py:821}] <INFO> [ 153/ 200] loss: (train=0.992, val=0.926, test=1.051, l2=10129.378), acc: (train=0.693, val=0.676, test=0.636), diff=0.00000051, proc(train=23.195sec, eval=11.570sec)
[2022-11-02 18:02:36,676 {dist_trainer.py:770}] <INFO> [ 154/ 200] connecting edge count: 2
[2022-11-02 18:02:49,595 {dist_trainer.py:821}] <INFO> [ 154/ 200] loss: (train=0.992, val=0.945, test=1.073, l2=10114.608), acc: (train=0.665, val=0.667, test=0.630), diff=0.00000063, proc(train=21.014sec, eval=11.424sec)
[2022-11-02 18:03:14,241 {dist_trainer.py:770}] <INFO> [ 155/ 200] connecting edge count: 2
[2022-11-02 18:03:29,180 {dist_trainer.py:821}] <INFO> [ 155/ 200] loss: (train=0.981, val=0.928, test=1.094, l2=10092.169), acc: (train=0.687, val=0.684, test=0.637), diff=0.00000051, proc(train=24.645sec, eval=11.788sec)
[2022-11-02 18:03:50,735 {dist_trainer.py:770}] <INFO> [ 156/ 200] connecting edge count: 2
[2022-11-02 18:04:04,364 {dist_trainer.py:821}] <INFO> [ 156/ 200] loss: (train=1.012, val=0.939, test=1.049, l2=10080.502), acc: (train=0.688, val=0.670, test=0.633), diff=0.00000079, proc(train=21.555sec, eval=11.489sec)
[2022-11-02 18:04:27,347 {dist_trainer.py:770}] <INFO> [ 157/ 200] connecting edge count: 2
[2022-11-02 18:04:40,145 {dist_trainer.py:821}] <INFO> [ 157/ 200] loss: (train=1.034, val=0.938, test=1.080, l2=10076.717), acc: (train=0.682, val=0.671, test=0.628), diff=0.00000044, proc(train=22.983sec, eval=11.862sec)
[2022-11-02 18:05:05,466 {dist_trainer.py:770}] <INFO> [ 158/ 200] connecting edge count: 2
[2022-11-02 18:05:18,120 {dist_trainer.py:821}] <INFO> [ 158/ 200] loss: (train=0.969, val=1.035, test=1.162, l2=10046.379), acc: (train=0.624, val=0.627, test=0.592), diff=0.00000057, proc(train=25.320sec, eval=11.533sec)
[2022-11-02 18:05:41,688 {dist_trainer.py:770}] <INFO> [ 159/ 200] connecting edge count: 2
[2022-11-02 18:05:54,477 {dist_trainer.py:821}] <INFO> [ 159/ 200] loss: (train=0.997, val=1.038, test=1.157, l2=10042.182), acc: (train=0.639, val=0.626, test=0.590), diff=0.00000042, proc(train=23.567sec, eval=11.779sec)
[2022-11-02 18:06:20,201 {dist_trainer.py:770}] <INFO> [ 160/ 200] connecting edge count: 2
[2022-11-02 18:06:33,074 {dist_trainer.py:821}] <INFO> [ 160/ 200] loss: (train=0.964, val=0.935, test=1.081, l2=10005.718), acc: (train=0.694, val=0.670, test=0.628), diff=0.00000043, proc(train=25.723sec, eval=11.455sec)
[2022-11-02 18:06:54,697 {dist_trainer.py:770}] <INFO> [ 161/ 200] connecting edge count: 2
[2022-11-02 18:07:07,607 {dist_trainer.py:821}] <INFO> [ 161/ 200] loss: (train=0.985, val=0.932, test=1.071, l2=9990.366), acc: (train=0.699, val=0.677, test=0.634), diff=0.00000064, proc(train=21.622sec, eval=11.471sec)
[2022-11-02 18:07:31,195 {dist_trainer.py:770}] <INFO> [ 162/ 200] connecting edge count: 2
[2022-11-02 18:07:44,298 {dist_trainer.py:821}] <INFO> [ 162/ 200] loss: (train=0.971, val=0.872, test=1.029, l2=9969.731), acc: (train=0.680, val=0.693, test=0.645), diff=0.00000037, proc(train=23.587sec, eval=11.621sec)
[2022-11-02 18:08:06,416 {dist_trainer.py:770}] <INFO> [ 163/ 200] connecting edge count: 2
[2022-11-02 18:08:19,756 {dist_trainer.py:821}] <INFO> [ 163/ 200] loss: (train=0.979, val=0.998, test=1.146, l2=9951.572), acc: (train=0.674, val=0.659, test=0.614), diff=0.00000074, proc(train=22.118sec, eval=11.456sec)
[2022-11-02 18:08:43,471 {dist_trainer.py:770}] <INFO> [ 164/ 200] connecting edge count: 2
[2022-11-02 18:08:57,944 {dist_trainer.py:821}] <INFO> [ 164/ 200] loss: (train=1.031, val=0.954, test=1.111, l2=9957.360), acc: (train=0.660, val=0.670, test=0.628), diff=0.00000108, proc(train=23.715sec, eval=11.834sec)
[2022-11-02 18:09:20,597 {dist_trainer.py:770}] <INFO> [ 165/ 200] connecting edge count: 2
[2022-11-02 18:09:33,803 {dist_trainer.py:821}] <INFO> [ 165/ 200] loss: (train=0.985, val=0.895, test=1.041, l2=9919.666), acc: (train=0.692, val=0.688, test=0.640), diff=0.00000057, proc(train=22.652sec, eval=11.510sec)
[2022-11-02 18:09:56,919 {dist_trainer.py:770}] <INFO> [ 166/ 200] connecting edge count: 2
[2022-11-02 18:10:09,628 {dist_trainer.py:821}] <INFO> [ 166/ 200] loss: (train=0.967, val=0.915, test=1.042, l2=9912.144), acc: (train=0.679, val=0.681, test=0.638), diff=0.00000038, proc(train=23.115sec, eval=11.664sec)
[2022-11-02 18:10:36,730 {dist_trainer.py:770}] <INFO> [ 167/ 200] connecting edge count: 2
[2022-11-02 18:10:49,495 {dist_trainer.py:821}] <INFO> [ 167/ 200] loss: (train=0.944, val=0.886, test=1.028, l2=9877.426), acc: (train=0.694, val=0.690, test=0.646), diff=0.00000043, proc(train=27.101sec, eval=11.575sec)
[2022-11-02 18:11:10,904 {dist_trainer.py:770}] <INFO> [ 168/ 200] connecting edge count: 2
[2022-11-02 18:11:23,629 {dist_trainer.py:821}] <INFO> [ 168/ 200] loss: (train=0.976, val=1.092, test=1.227, l2=9860.650), acc: (train=0.607, val=0.622, test=0.578), diff=0.00000081, proc(train=21.409sec, eval=11.489sec)
[2022-11-02 18:11:48,298 {dist_trainer.py:770}] <INFO> [ 169/ 200] connecting edge count: 2
[2022-11-02 18:12:01,167 {dist_trainer.py:821}] <INFO> [ 169/ 200] loss: (train=0.993, val=0.848, test=1.011, l2=9843.574), acc: (train=0.699, val=0.707, test=0.654), diff=0.00000043, proc(train=24.669sec, eval=11.738sec)
[2022-11-02 18:12:23,958 {dist_trainer.py:770}] <INFO> [ 170/ 200] connecting edge count: 2
[2022-11-02 18:12:36,849 {dist_trainer.py:821}] <INFO> [ 170/ 200] loss: (train=0.943, val=0.937, test=1.068, l2=9829.236), acc: (train=0.695, val=0.672, test=0.633), diff=0.00000068, proc(train=22.791sec, eval=11.429sec)
[2022-11-02 18:12:59,737 {dist_trainer.py:770}] <INFO> [ 171/ 200] connecting edge count: 2
[2022-11-02 18:13:12,656 {dist_trainer.py:821}] <INFO> [ 171/ 200] loss: (train=1.025, val=0.885, test=1.025, l2=9829.121), acc: (train=0.717, val=0.690, test=0.646), diff=0.00000052, proc(train=22.888sec, eval=11.701sec)
[2022-11-02 18:13:37,811 {dist_trainer.py:770}] <INFO> [ 172/ 200] connecting edge count: 2
[2022-11-02 18:13:50,485 {dist_trainer.py:821}] <INFO> [ 172/ 200] loss: (train=0.969, val=0.917, test=1.070, l2=9793.593), acc: (train=0.683, val=0.680, test=0.636), diff=0.00000062, proc(train=25.155sec, eval=11.478sec)
[2022-11-02 18:14:13,605 {dist_trainer.py:770}] <INFO> [ 173/ 200] connecting edge count: 2
[2022-11-02 18:14:26,295 {dist_trainer.py:821}] <INFO> [ 173/ 200] loss: (train=0.958, val=1.038, test=1.168, l2=9789.620), acc: (train=0.676, val=0.638, test=0.601), diff=0.00000046, proc(train=23.119sec, eval=11.674sec)
[2022-11-02 18:14:50,491 {dist_trainer.py:770}] <INFO> [ 174/ 200] connecting edge count: 2
[2022-11-02 18:15:03,665 {dist_trainer.py:821}] <INFO> [ 174/ 200] loss: (train=0.939, val=0.859, test=1.031, l2=9757.379), acc: (train=0.692, val=0.700, test=0.652), diff=0.00000047, proc(train=24.196sec, eval=11.662sec)
[2022-11-02 18:15:24,442 {dist_trainer.py:770}] <INFO> [ 175/ 200] connecting edge count: 2
[2022-11-02 18:15:38,142 {dist_trainer.py:821}] <INFO> [ 175/ 200] loss: (train=0.937, val=0.870, test=1.007, l2=9738.533), acc: (train=0.705, val=0.693, test=0.649), diff=0.00000069, proc(train=20.776sec, eval=11.469sec)
[2022-11-02 18:16:02,345 {dist_trainer.py:770}] <INFO> [ 176/ 200] connecting edge count: 2
[2022-11-02 18:16:15,263 {dist_trainer.py:821}] <INFO> [ 176/ 200] loss: (train=0.974, val=0.815, test=0.985, l2=9727.658), acc: (train=0.714, val=0.714, test=0.666), diff=0.00000036, proc(train=24.202sec, eval=11.644sec)
[2022-11-02 18:16:38,039 {dist_trainer.py:770}] <INFO> [ 177/ 200] connecting edge count: 2
[2022-11-02 18:16:51,142 {dist_trainer.py:821}] <INFO> [ 177/ 200] loss: (train=0.929, val=0.926, test=1.077, l2=9704.684), acc: (train=0.703, val=0.674, test=0.626), diff=0.00000060, proc(train=22.776sec, eval=11.502sec)
[2022-11-02 18:17:15,221 {dist_trainer.py:770}] <INFO> [ 178/ 200] connecting edge count: 2
[2022-11-02 18:17:29,893 {dist_trainer.py:821}] <INFO> [ 178/ 200] loss: (train=0.972, val=0.924, test=1.063, l2=9702.911), acc: (train=0.693, val=0.681, test=0.638), diff=0.00000033, proc(train=24.079sec, eval=11.808sec)
[2022-11-02 18:17:54,109 {dist_trainer.py:770}] <INFO> [ 179/ 200] connecting edge count: 2
[2022-11-02 18:18:06,742 {dist_trainer.py:821}] <INFO> [ 179/ 200] loss: (train=0.937, val=0.834, test=1.008, l2=9667.740), acc: (train=0.702, val=0.707, test=0.655), diff=0.00000042, proc(train=24.215sec, eval=11.476sec)
[2022-11-02 18:18:29,285 {dist_trainer.py:770}] <INFO> [ 180/ 200] connecting edge count: 2
[2022-11-02 18:18:42,109 {dist_trainer.py:821}] <INFO> [ 180/ 200] loss: (train=0.920, val=0.872, test=1.031, l2=9662.045), acc: (train=0.697, val=0.697, test=0.648), diff=0.00000035, proc(train=22.543sec, eval=11.603sec)
[2022-11-02 18:19:06,741 {dist_trainer.py:770}] <INFO> [ 181/ 200] connecting edge count: 2
[2022-11-02 18:19:19,712 {dist_trainer.py:821}] <INFO> [ 181/ 200] loss: (train=0.910, val=0.793, test=0.976, l2=9629.519), acc: (train=0.719, val=0.724, test=0.669), diff=0.00000049, proc(train=24.632sec, eval=11.640sec)
[2022-11-02 18:19:40,776 {dist_trainer.py:770}] <INFO> [ 182/ 200] connecting edge count: 2
[2022-11-02 18:19:54,013 {dist_trainer.py:821}] <INFO> [ 182/ 200] loss: (train=0.908, val=0.905, test=1.066, l2=9609.397), acc: (train=0.687, val=0.677, test=0.625), diff=0.00000057, proc(train=21.064sec, eval=11.482sec)
[2022-11-02 18:20:16,556 {dist_trainer.py:770}] <INFO> [ 183/ 200] connecting edge count: 2
[2022-11-02 18:20:29,837 {dist_trainer.py:821}] <INFO> [ 183/ 200] loss: (train=0.950, val=0.812, test=1.002, l2=9604.118), acc: (train=0.711, val=0.715, test=0.662), diff=0.00000049, proc(train=22.543sec, eval=11.655sec)
[2022-11-02 18:20:54,725 {dist_trainer.py:770}] <INFO> [ 184/ 200] connecting edge count: 2
[2022-11-02 18:21:07,612 {dist_trainer.py:821}] <INFO> [ 184/ 200] loss: (train=0.906, val=0.870, test=1.039, l2=9579.701), acc: (train=0.719, val=0.697, test=0.642), diff=0.00000060, proc(train=24.887sec, eval=11.486sec)
[2022-11-02 18:21:31,293 {dist_trainer.py:770}] <INFO> [ 185/ 200] connecting edge count: 2
[2022-11-02 18:21:44,773 {dist_trainer.py:821}] <INFO> [ 185/ 200] loss: (train=0.958, val=0.881, test=1.058, l2=9577.305), acc: (train=0.713, val=0.695, test=0.641), diff=0.00000034, proc(train=23.681sec, eval=11.683sec)
[2022-11-02 18:22:09,697 {dist_trainer.py:770}] <INFO> [ 186/ 200] connecting edge count: 2
[2022-11-02 18:22:22,945 {dist_trainer.py:821}] <INFO> [ 186/ 200] loss: (train=0.901, val=0.799, test=0.993, l2=9541.043), acc: (train=0.715, val=0.722, test=0.663), diff=0.00000030, proc(train=24.924sec, eval=11.391sec)
[2022-11-02 18:22:45,704 {dist_trainer.py:770}] <INFO> [ 187/ 200] connecting edge count: 2
[2022-11-02 18:22:59,263 {dist_trainer.py:821}] <INFO> [ 187/ 200] loss: (train=0.898, val=0.886, test=1.042, l2=9529.874), acc: (train=0.729, val=0.690, test=0.642), diff=0.00000039, proc(train=22.758sec, eval=11.626sec)
[2022-11-02 18:23:24,140 {dist_trainer.py:770}] <INFO> [ 188/ 200] connecting edge count: 2
[2022-11-02 18:23:37,149 {dist_trainer.py:821}] <INFO> [ 188/ 200] loss: (train=0.915, val=0.803, test=0.988, l2=9501.763), acc: (train=0.739, val=0.720, test=0.658), diff=0.00000046, proc(train=24.876sec, eval=11.621sec)
[2022-11-02 18:23:58,051 {dist_trainer.py:770}] <INFO> [ 189/ 200] connecting edge count: 2
[2022-11-02 18:24:11,384 {dist_trainer.py:821}] <INFO> [ 189/ 200] loss: (train=0.889, val=0.876, test=1.050, l2=9482.433), acc: (train=0.715, val=0.693, test=0.637), diff=0.00000064, proc(train=20.891sec, eval=11.462sec)
[2022-11-02 18:24:34,461 {dist_trainer.py:770}] <INFO> [ 190/ 200] connecting edge count: 2
[2022-11-02 18:24:47,477 {dist_trainer.py:821}] <INFO> [ 190/ 200] loss: (train=0.912, val=0.801, test=0.996, l2=9477.674), acc: (train=0.717, val=0.721, test=0.666), diff=0.00000049, proc(train=23.077sec, eval=11.786sec)
[2022-11-02 18:25:12,748 {dist_trainer.py:770}] <INFO> [ 191/ 200] connecting edge count: 2
[2022-11-02 18:25:25,446 {dist_trainer.py:821}] <INFO> [ 191/ 200] loss: (train=0.903, val=0.868, test=1.040, l2=9454.191), acc: (train=0.729, val=0.697, test=0.643), diff=0.00000064, proc(train=25.271sec, eval=11.490sec)
[2022-11-02 18:25:49,580 {dist_trainer.py:770}] <INFO> [ 192/ 200] connecting edge count: 2
[2022-11-02 18:26:02,863 {dist_trainer.py:821}] <INFO> [ 192/ 200] loss: (train=0.939, val=0.861, test=1.025, l2=9451.593), acc: (train=0.700, val=0.702, test=0.646), diff=0.00000037, proc(train=24.134sec, eval=11.778sec)
[2022-11-02 18:26:30,175 {dist_trainer.py:770}] <INFO> [ 193/ 200] connecting edge count: 2
[2022-11-02 18:26:43,800 {dist_trainer.py:821}] <INFO> [ 193/ 200] loss: (train=0.915, val=0.760, test=0.958, l2=9418.629), acc: (train=0.743, val=0.736, test=0.672), diff=0.00000044, proc(train=27.312sec, eval=11.469sec)
[2022-11-02 18:27:07,262 {dist_trainer.py:770}] <INFO> [ 194/ 200] connecting edge count: 2
[2022-11-02 18:27:20,217 {dist_trainer.py:821}] <INFO> [ 194/ 200] loss: (train=0.898, val=0.851, test=1.021, l2=9412.114), acc: (train=0.720, val=0.707, test=0.659), diff=0.00000049, proc(train=23.462sec, eval=11.753sec)
[2022-11-02 18:27:44,296 {dist_trainer.py:770}] <INFO> [ 195/ 200] connecting edge count: 2
[2022-11-02 18:27:57,361 {dist_trainer.py:821}] <INFO> [ 195/ 200] loss: (train=0.889, val=0.801, test=1.006, l2=9382.073), acc: (train=0.733, val=0.724, test=0.655), diff=0.00000044, proc(train=24.078sec, eval=11.638sec)
[2022-11-02 18:28:18,563 {dist_trainer.py:770}] <INFO> [ 196/ 200] connecting edge count: 2
[2022-11-02 18:28:31,968 {dist_trainer.py:821}] <INFO> [ 196/ 200] loss: (train=0.870, val=0.795, test=0.981, l2=9364.906), acc: (train=0.726, val=0.725, test=0.662), diff=0.00000065, proc(train=21.201sec, eval=11.509sec)
[2022-11-02 18:28:53,670 {dist_trainer.py:770}] <INFO> [ 197/ 200] connecting edge count: 2
[2022-11-02 18:29:06,869 {dist_trainer.py:821}] <INFO> [ 197/ 200] loss: (train=0.891, val=0.766, test=0.968, l2=9357.734), acc: (train=0.738, val=0.735, test=0.668), diff=0.00000044, proc(train=21.702sec, eval=11.622sec)
[2022-11-02 18:29:31,397 {dist_trainer.py:770}] <INFO> [ 198/ 200] connecting edge count: 2
[2022-11-02 18:29:44,087 {dist_trainer.py:821}] <INFO> [ 198/ 200] loss: (train=0.873, val=0.860, test=1.068, l2=9334.870), acc: (train=0.713, val=0.700, test=0.637), diff=0.00000058, proc(train=24.527sec, eval=11.448sec)
[2022-11-02 18:30:07,480 {dist_trainer.py:770}] <INFO> [ 199/ 200] connecting edge count: 2
[2022-11-02 18:30:20,605 {dist_trainer.py:821}] <INFO> [ 199/ 200] loss: (train=0.904, val=0.871, test=1.063, l2=9332.357), acc: (train=0.708, val=0.696, test=0.636), diff=0.00000039, proc(train=23.393sec, eval=11.715sec)
[2022-11-02 18:30:47,387 {dist_trainer.py:770}] <INFO> [ 200/ 200] connecting edge count: 2
[2022-11-02 18:31:00,077 {dist_trainer.py:821}] <INFO> [ 200/ 200] loss: (train=0.865, val=0.805, test=1.026, l2=9296.978), acc: (train=0.715, val=0.722, test=0.661), diff=0.00000032, proc(train=26.781sec, eval=11.458sec)
[2022-11-02 18:31:13,307 {dist_trainer.py:899}] <INFO> [EVAL] loss: (train=0.833, val=0.805, test=1.026, l2=9296.792), acc: (train=0.715, val=0.722, test=0.661), proc=13.228sec
[2022-11-02 18:31:13,419 {dist_trainer.py:380}] <INFO> GC: check garbage []
[2022-11-02 18:31:13,727 {main.py:231}] <INFO> GC: check garbage []
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
