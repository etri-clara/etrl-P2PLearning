[2022-11-04 19:18:08,344 {main.py:152}] <INFO> Namespace(datadir='./data', outdir='./output/ring2', epochs=200, batch_size=100, seed=569, data_init_seed=11, model_init_seed=13, l2_lambda=0.01, model_name='resnet50', dataset_name='cifar10', train_data_length=10000, group_channels=32, drop_rate=0.1, last_drop_rate=0.5, cuda=True, cuda_device_no=2, plot=False, scheduler='StepLR', step_size=410, gamma=0.9, sleep_factor=0.0, loglevel=<LogLevel.INFO: 20>, logfile=None, optimizer='AdmmSGD', nodename='node1', conf='./conf/node_list.json', host='./conf/hosts.json', lr=0.002, mu=200, eta=1.0, rho=0.1, round_step=False, swap_timeout=10)
[2022-11-04 19:18:08,344 {main.py:247}] <INFO> {'nodes': {'node0': {'device': 'cuda', 'round': 10, 'edges': {'node2': 0, 'node1': 4}}, 'node1': {'device': 'cuda', 'round': 10, 'edges': {'node0': 1, 'node2': 5}}, 'node2': {'device': 'cuda', 'round': 10, 'edges': {'node1': 2, 'node0': 6}}}}
[2022-11-04 19:18:08,471 {dist_trainer.py:186}] <INFO> : <class 'model.resnet.ResNet'>
[2022-11-04 19:18:08,471 {dist_trainer.py:186}] <INFO> conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,471 {dist_trainer.py:183}] <INFO> bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-04 19:18:08,471 {dist_trainer.py:186}] <INFO> relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,471 {dist_trainer.py:186}] <INFO> maxpool: <class 'torch.nn.modules.pooling.MaxPool2d'>
[2022-11-04 19:18:08,471 {dist_trainer.py:186}] <INFO> dropout1: <class 'torch.nn.modules.dropout.Dropout2d'>
[2022-11-04 19:18:08,471 {dist_trainer.py:186}] <INFO> layer1: <class 'torch.nn.modules.container.Sequential'>
[2022-11-04 19:18:08,471 {dist_trainer.py:186}] <INFO> layer1.0: <class 'model.resnet.Bottleneck'>
[2022-11-04 19:18:08,471 {dist_trainer.py:186}] <INFO> layer1.0.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,471 {dist_trainer.py:183}] <INFO> layer1.0.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-04 19:18:08,472 {dist_trainer.py:186}] <INFO> layer1.0.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,472 {dist_trainer.py:183}] <INFO> layer1.0.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-04 19:18:08,472 {dist_trainer.py:186}] <INFO> layer1.0.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,472 {dist_trainer.py:183}] <INFO> layer1.0.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-04 19:18:08,472 {dist_trainer.py:186}] <INFO> layer1.0.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,472 {dist_trainer.py:186}] <INFO> layer1.0.downsample: <class 'torch.nn.modules.container.Sequential'>
[2022-11-04 19:18:08,472 {dist_trainer.py:186}] <INFO> layer1.0.downsample.0: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,472 {dist_trainer.py:183}] <INFO> layer1.0.downsample.1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-04 19:18:08,472 {dist_trainer.py:186}] <INFO> layer1.1: <class 'model.resnet.Bottleneck'>
[2022-11-04 19:18:08,472 {dist_trainer.py:186}] <INFO> layer1.1.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,472 {dist_trainer.py:183}] <INFO> layer1.1.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-04 19:18:08,472 {dist_trainer.py:186}] <INFO> layer1.1.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,472 {dist_trainer.py:183}] <INFO> layer1.1.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-04 19:18:08,472 {dist_trainer.py:186}] <INFO> layer1.1.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,472 {dist_trainer.py:183}] <INFO> layer1.1.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-04 19:18:08,472 {dist_trainer.py:186}] <INFO> layer1.1.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,472 {dist_trainer.py:186}] <INFO> layer1.2: <class 'model.resnet.Bottleneck'>
[2022-11-04 19:18:08,472 {dist_trainer.py:186}] <INFO> layer1.2.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,472 {dist_trainer.py:183}] <INFO> layer1.2.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-04 19:18:08,472 {dist_trainer.py:186}] <INFO> layer1.2.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,472 {dist_trainer.py:183}] <INFO> layer1.2.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-04 19:18:08,472 {dist_trainer.py:186}] <INFO> layer1.2.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,472 {dist_trainer.py:183}] <INFO> layer1.2.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-04 19:18:08,472 {dist_trainer.py:186}] <INFO> layer1.2.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,472 {dist_trainer.py:186}] <INFO> layer1.3: <class 'torch.nn.modules.dropout.Dropout2d'>
[2022-11-04 19:18:08,472 {dist_trainer.py:186}] <INFO> layer2: <class 'torch.nn.modules.container.Sequential'>
[2022-11-04 19:18:08,472 {dist_trainer.py:186}] <INFO> layer2.0: <class 'model.resnet.Bottleneck'>
[2022-11-04 19:18:08,472 {dist_trainer.py:186}] <INFO> layer2.0.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,472 {dist_trainer.py:183}] <INFO> layer2.0.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-04 19:18:08,472 {dist_trainer.py:186}] <INFO> layer2.0.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,472 {dist_trainer.py:183}] <INFO> layer2.0.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-04 19:18:08,472 {dist_trainer.py:186}] <INFO> layer2.0.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,472 {dist_trainer.py:183}] <INFO> layer2.0.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-04 19:18:08,472 {dist_trainer.py:186}] <INFO> layer2.0.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,472 {dist_trainer.py:186}] <INFO> layer2.0.downsample: <class 'torch.nn.modules.container.Sequential'>
[2022-11-04 19:18:08,473 {dist_trainer.py:186}] <INFO> layer2.0.downsample.0: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,473 {dist_trainer.py:183}] <INFO> layer2.0.downsample.1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-04 19:18:08,473 {dist_trainer.py:186}] <INFO> layer2.1: <class 'model.resnet.Bottleneck'>
[2022-11-04 19:18:08,473 {dist_trainer.py:186}] <INFO> layer2.1.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,473 {dist_trainer.py:183}] <INFO> layer2.1.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-04 19:18:08,473 {dist_trainer.py:186}] <INFO> layer2.1.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,473 {dist_trainer.py:183}] <INFO> layer2.1.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-04 19:18:08,473 {dist_trainer.py:186}] <INFO> layer2.1.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,473 {dist_trainer.py:183}] <INFO> layer2.1.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-04 19:18:08,473 {dist_trainer.py:186}] <INFO> layer2.1.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,473 {dist_trainer.py:186}] <INFO> layer2.2: <class 'model.resnet.Bottleneck'>
[2022-11-04 19:18:08,473 {dist_trainer.py:186}] <INFO> layer2.2.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,473 {dist_trainer.py:183}] <INFO> layer2.2.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-04 19:18:08,473 {dist_trainer.py:186}] <INFO> layer2.2.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,473 {dist_trainer.py:183}] <INFO> layer2.2.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-04 19:18:08,473 {dist_trainer.py:186}] <INFO> layer2.2.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,473 {dist_trainer.py:183}] <INFO> layer2.2.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-04 19:18:08,473 {dist_trainer.py:186}] <INFO> layer2.2.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,473 {dist_trainer.py:186}] <INFO> layer2.3: <class 'model.resnet.Bottleneck'>
[2022-11-04 19:18:08,473 {dist_trainer.py:186}] <INFO> layer2.3.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,473 {dist_trainer.py:183}] <INFO> layer2.3.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-04 19:18:08,473 {dist_trainer.py:186}] <INFO> layer2.3.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,473 {dist_trainer.py:183}] <INFO> layer2.3.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-04 19:18:08,473 {dist_trainer.py:186}] <INFO> layer2.3.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,473 {dist_trainer.py:183}] <INFO> layer2.3.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-04 19:18:08,473 {dist_trainer.py:186}] <INFO> layer2.3.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,473 {dist_trainer.py:186}] <INFO> layer2.4: <class 'torch.nn.modules.dropout.Dropout2d'>
[2022-11-04 19:18:08,473 {dist_trainer.py:186}] <INFO> layer3: <class 'torch.nn.modules.container.Sequential'>
[2022-11-04 19:18:08,473 {dist_trainer.py:186}] <INFO> layer3.0: <class 'model.resnet.Bottleneck'>
[2022-11-04 19:18:08,473 {dist_trainer.py:186}] <INFO> layer3.0.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,473 {dist_trainer.py:183}] <INFO> layer3.0.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-04 19:18:08,473 {dist_trainer.py:186}] <INFO> layer3.0.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,473 {dist_trainer.py:183}] <INFO> layer3.0.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-04 19:18:08,473 {dist_trainer.py:186}] <INFO> layer3.0.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,474 {dist_trainer.py:183}] <INFO> layer3.0.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-04 19:18:08,474 {dist_trainer.py:186}] <INFO> layer3.0.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,474 {dist_trainer.py:186}] <INFO> layer3.0.downsample: <class 'torch.nn.modules.container.Sequential'>
[2022-11-04 19:18:08,474 {dist_trainer.py:186}] <INFO> layer3.0.downsample.0: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,474 {dist_trainer.py:183}] <INFO> layer3.0.downsample.1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-04 19:18:08,474 {dist_trainer.py:186}] <INFO> layer3.1: <class 'model.resnet.Bottleneck'>
[2022-11-04 19:18:08,474 {dist_trainer.py:186}] <INFO> layer3.1.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,474 {dist_trainer.py:183}] <INFO> layer3.1.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-04 19:18:08,474 {dist_trainer.py:186}] <INFO> layer3.1.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,474 {dist_trainer.py:183}] <INFO> layer3.1.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-04 19:18:08,474 {dist_trainer.py:186}] <INFO> layer3.1.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,474 {dist_trainer.py:183}] <INFO> layer3.1.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-04 19:18:08,474 {dist_trainer.py:186}] <INFO> layer3.1.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,474 {dist_trainer.py:186}] <INFO> layer3.2: <class 'model.resnet.Bottleneck'>
[2022-11-04 19:18:08,474 {dist_trainer.py:186}] <INFO> layer3.2.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,474 {dist_trainer.py:183}] <INFO> layer3.2.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-04 19:18:08,474 {dist_trainer.py:186}] <INFO> layer3.2.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,474 {dist_trainer.py:183}] <INFO> layer3.2.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-04 19:18:08,474 {dist_trainer.py:186}] <INFO> layer3.2.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,474 {dist_trainer.py:183}] <INFO> layer3.2.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-04 19:18:08,474 {dist_trainer.py:186}] <INFO> layer3.2.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,474 {dist_trainer.py:186}] <INFO> layer3.3: <class 'model.resnet.Bottleneck'>
[2022-11-04 19:18:08,474 {dist_trainer.py:186}] <INFO> layer3.3.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,474 {dist_trainer.py:183}] <INFO> layer3.3.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-04 19:18:08,474 {dist_trainer.py:186}] <INFO> layer3.3.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,474 {dist_trainer.py:183}] <INFO> layer3.3.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-04 19:18:08,474 {dist_trainer.py:186}] <INFO> layer3.3.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,474 {dist_trainer.py:183}] <INFO> layer3.3.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-04 19:18:08,474 {dist_trainer.py:186}] <INFO> layer3.3.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,474 {dist_trainer.py:186}] <INFO> layer3.4: <class 'model.resnet.Bottleneck'>
[2022-11-04 19:18:08,474 {dist_trainer.py:186}] <INFO> layer3.4.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,474 {dist_trainer.py:183}] <INFO> layer3.4.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-04 19:18:08,474 {dist_trainer.py:186}] <INFO> layer3.4.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,474 {dist_trainer.py:183}] <INFO> layer3.4.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-04 19:18:08,475 {dist_trainer.py:186}] <INFO> layer3.4.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,475 {dist_trainer.py:183}] <INFO> layer3.4.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-04 19:18:08,475 {dist_trainer.py:186}] <INFO> layer3.4.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,475 {dist_trainer.py:186}] <INFO> layer3.5: <class 'model.resnet.Bottleneck'>
[2022-11-04 19:18:08,475 {dist_trainer.py:186}] <INFO> layer3.5.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,475 {dist_trainer.py:183}] <INFO> layer3.5.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-04 19:18:08,475 {dist_trainer.py:186}] <INFO> layer3.5.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,475 {dist_trainer.py:183}] <INFO> layer3.5.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-04 19:18:08,475 {dist_trainer.py:186}] <INFO> layer3.5.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,475 {dist_trainer.py:183}] <INFO> layer3.5.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-04 19:18:08,475 {dist_trainer.py:186}] <INFO> layer3.5.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,475 {dist_trainer.py:186}] <INFO> layer3.6: <class 'torch.nn.modules.dropout.Dropout2d'>
[2022-11-04 19:18:08,475 {dist_trainer.py:186}] <INFO> layer4: <class 'torch.nn.modules.container.Sequential'>
[2022-11-04 19:18:08,475 {dist_trainer.py:186}] <INFO> layer4.0: <class 'model.resnet.Bottleneck'>
[2022-11-04 19:18:08,475 {dist_trainer.py:186}] <INFO> layer4.0.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,475 {dist_trainer.py:183}] <INFO> layer4.0.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-04 19:18:08,475 {dist_trainer.py:186}] <INFO> layer4.0.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,475 {dist_trainer.py:183}] <INFO> layer4.0.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-04 19:18:08,475 {dist_trainer.py:186}] <INFO> layer4.0.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,475 {dist_trainer.py:183}] <INFO> layer4.0.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 64, channels: 2048, eps: 0.000010, affine: True
[2022-11-04 19:18:08,475 {dist_trainer.py:186}] <INFO> layer4.0.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,475 {dist_trainer.py:186}] <INFO> layer4.0.downsample: <class 'torch.nn.modules.container.Sequential'>
[2022-11-04 19:18:08,475 {dist_trainer.py:186}] <INFO> layer4.0.downsample.0: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,475 {dist_trainer.py:183}] <INFO> layer4.0.downsample.1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 64, channels: 2048, eps: 0.000010, affine: True
[2022-11-04 19:18:08,475 {dist_trainer.py:186}] <INFO> layer4.1: <class 'model.resnet.Bottleneck'>
[2022-11-04 19:18:08,475 {dist_trainer.py:186}] <INFO> layer4.1.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,475 {dist_trainer.py:183}] <INFO> layer4.1.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-04 19:18:08,475 {dist_trainer.py:186}] <INFO> layer4.1.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,475 {dist_trainer.py:183}] <INFO> layer4.1.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-04 19:18:08,475 {dist_trainer.py:186}] <INFO> layer4.1.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,475 {dist_trainer.py:183}] <INFO> layer4.1.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 64, channels: 2048, eps: 0.000010, affine: True
[2022-11-04 19:18:08,475 {dist_trainer.py:186}] <INFO> layer4.1.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,475 {dist_trainer.py:186}] <INFO> layer4.2: <class 'model.resnet.Bottleneck'>
[2022-11-04 19:18:08,475 {dist_trainer.py:186}] <INFO> layer4.2.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,475 {dist_trainer.py:183}] <INFO> layer4.2.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-04 19:18:08,475 {dist_trainer.py:186}] <INFO> layer4.2.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,476 {dist_trainer.py:183}] <INFO> layer4.2.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-04 19:18:08,476 {dist_trainer.py:186}] <INFO> layer4.2.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,476 {dist_trainer.py:183}] <INFO> layer4.2.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 64, channels: 2048, eps: 0.000010, affine: True
[2022-11-04 19:18:08,476 {dist_trainer.py:186}] <INFO> layer4.2.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,476 {dist_trainer.py:186}] <INFO> avgpool: <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>
[2022-11-04 19:18:08,476 {dist_trainer.py:186}] <INFO> dropout_fc: <class 'torch.nn.modules.dropout.Dropout'>
[2022-11-04 19:18:08,476 {dist_trainer.py:186}] <INFO> fc: <class 'torch.nn.modules.linear.Linear'>
[2022-11-04 19:18:08,476 {dist_trainer.py:192}] <INFO> parameter size: conv1.weight 37632B
[2022-11-04 19:18:08,476 {dist_trainer.py:192}] <INFO> parameter size: bn1.weight 256B
[2022-11-04 19:18:08,476 {dist_trainer.py:192}] <INFO> parameter size: bn1.bias 256B
[2022-11-04 19:18:08,476 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.conv1.weight 16384B
[2022-11-04 19:18:08,476 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.bn1.weight 256B
[2022-11-04 19:18:08,476 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.bn1.bias 256B
[2022-11-04 19:18:08,476 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.conv2.weight 147456B
[2022-11-04 19:18:08,476 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.bn2.weight 256B
[2022-11-04 19:18:08,476 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.bn2.bias 256B
[2022-11-04 19:18:08,476 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.conv3.weight 65536B
[2022-11-04 19:18:08,476 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.bn3.weight 1024B
[2022-11-04 19:18:08,476 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.bn3.bias 1024B
[2022-11-04 19:18:08,476 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.downsample.0.weight 65536B
[2022-11-04 19:18:08,476 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.downsample.1.weight 1024B
[2022-11-04 19:18:08,476 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.downsample.1.bias 1024B
[2022-11-04 19:18:08,477 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.conv1.weight 65536B
[2022-11-04 19:18:08,477 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.bn1.weight 256B
[2022-11-04 19:18:08,477 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.bn1.bias 256B
[2022-11-04 19:18:08,477 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.conv2.weight 147456B
[2022-11-04 19:18:08,477 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.bn2.weight 256B
[2022-11-04 19:18:08,477 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.bn2.bias 256B
[2022-11-04 19:18:08,477 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.conv3.weight 65536B
[2022-11-04 19:18:08,477 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.bn3.weight 1024B
[2022-11-04 19:18:08,477 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.bn3.bias 1024B
[2022-11-04 19:18:08,477 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.conv1.weight 65536B
[2022-11-04 19:18:08,477 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.bn1.weight 256B
[2022-11-04 19:18:08,477 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.bn1.bias 256B
[2022-11-04 19:18:08,477 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.conv2.weight 147456B
[2022-11-04 19:18:08,477 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.bn2.weight 256B
[2022-11-04 19:18:08,477 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.bn2.bias 256B
[2022-11-04 19:18:08,477 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.conv3.weight 65536B
[2022-11-04 19:18:08,477 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.bn3.weight 1024B
[2022-11-04 19:18:08,477 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.bn3.bias 1024B
[2022-11-04 19:18:08,478 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.conv1.weight 131072B
[2022-11-04 19:18:08,478 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.bn1.weight 512B
[2022-11-04 19:18:08,478 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.bn1.bias 512B
[2022-11-04 19:18:08,478 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.conv2.weight 589824B
[2022-11-04 19:18:08,478 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.bn2.weight 512B
[2022-11-04 19:18:08,478 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.bn2.bias 512B
[2022-11-04 19:18:08,478 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.conv3.weight 262144B
[2022-11-04 19:18:08,478 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.bn3.weight 2048B
[2022-11-04 19:18:08,478 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.bn3.bias 2048B
[2022-11-04 19:18:08,478 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.downsample.0.weight 524288B
[2022-11-04 19:18:08,478 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.downsample.1.weight 2048B
[2022-11-04 19:18:08,478 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.downsample.1.bias 2048B
[2022-11-04 19:18:08,478 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.conv1.weight 262144B
[2022-11-04 19:18:08,478 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.bn1.weight 512B
[2022-11-04 19:18:08,478 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.bn1.bias 512B
[2022-11-04 19:18:08,478 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.conv2.weight 589824B
[2022-11-04 19:18:08,478 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.bn2.weight 512B
[2022-11-04 19:18:08,478 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.bn2.bias 512B
[2022-11-04 19:18:08,478 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.conv3.weight 262144B
[2022-11-04 19:18:08,478 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.bn3.weight 2048B
[2022-11-04 19:18:08,478 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.bn3.bias 2048B
[2022-11-04 19:18:08,478 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.conv1.weight 262144B
[2022-11-04 19:18:08,479 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.bn1.weight 512B
[2022-11-04 19:18:08,479 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.bn1.bias 512B
[2022-11-04 19:18:08,479 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.conv2.weight 589824B
[2022-11-04 19:18:08,479 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.bn2.weight 512B
[2022-11-04 19:18:08,479 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.bn2.bias 512B
[2022-11-04 19:18:08,479 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.conv3.weight 262144B
[2022-11-04 19:18:08,479 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.bn3.weight 2048B
[2022-11-04 19:18:08,479 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.bn3.bias 2048B
[2022-11-04 19:18:08,479 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.conv1.weight 262144B
[2022-11-04 19:18:08,479 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.bn1.weight 512B
[2022-11-04 19:18:08,479 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.bn1.bias 512B
[2022-11-04 19:18:08,479 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.conv2.weight 589824B
[2022-11-04 19:18:08,479 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.bn2.weight 512B
[2022-11-04 19:18:08,479 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.bn2.bias 512B
[2022-11-04 19:18:08,479 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.conv3.weight 262144B
[2022-11-04 19:18:08,479 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.bn3.weight 2048B
[2022-11-04 19:18:08,479 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.bn3.bias 2048B
[2022-11-04 19:18:08,479 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.conv1.weight 524288B
[2022-11-04 19:18:08,479 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.bn1.weight 1024B
[2022-11-04 19:18:08,479 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.bn1.bias 1024B
[2022-11-04 19:18:08,479 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.conv2.weight 2359296B
[2022-11-04 19:18:08,479 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.bn2.weight 1024B
[2022-11-04 19:18:08,479 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.bn2.bias 1024B
[2022-11-04 19:18:08,480 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.conv3.weight 1048576B
[2022-11-04 19:18:08,480 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.bn3.weight 4096B
[2022-11-04 19:18:08,480 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.bn3.bias 4096B
[2022-11-04 19:18:08,480 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.downsample.0.weight 2097152B
[2022-11-04 19:18:08,480 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.downsample.1.weight 4096B
[2022-11-04 19:18:08,480 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.downsample.1.bias 4096B
[2022-11-04 19:18:08,480 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.conv1.weight 1048576B
[2022-11-04 19:18:08,480 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.bn1.weight 1024B
[2022-11-04 19:18:08,480 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.bn1.bias 1024B
[2022-11-04 19:18:08,480 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.conv2.weight 2359296B
[2022-11-04 19:18:08,480 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.bn2.weight 1024B
[2022-11-04 19:18:08,480 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.bn2.bias 1024B
[2022-11-04 19:18:08,480 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.conv3.weight 1048576B
[2022-11-04 19:18:08,480 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.bn3.weight 4096B
[2022-11-04 19:18:08,480 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.bn3.bias 4096B
[2022-11-04 19:18:08,480 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.conv1.weight 1048576B
[2022-11-04 19:18:08,480 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.bn1.weight 1024B
[2022-11-04 19:18:08,480 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.bn1.bias 1024B
[2022-11-04 19:18:08,480 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.conv2.weight 2359296B
[2022-11-04 19:18:08,480 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.bn2.weight 1024B
[2022-11-04 19:18:08,480 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.bn2.bias 1024B
[2022-11-04 19:18:08,480 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.conv3.weight 1048576B
[2022-11-04 19:18:08,480 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.bn3.weight 4096B
[2022-11-04 19:18:08,481 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.bn3.bias 4096B
[2022-11-04 19:18:08,481 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.conv1.weight 1048576B
[2022-11-04 19:18:08,481 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.bn1.weight 1024B
[2022-11-04 19:18:08,481 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.bn1.bias 1024B
[2022-11-04 19:18:08,481 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.conv2.weight 2359296B
[2022-11-04 19:18:08,481 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.bn2.weight 1024B
[2022-11-04 19:18:08,481 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.bn2.bias 1024B
[2022-11-04 19:18:08,481 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.conv3.weight 1048576B
[2022-11-04 19:18:08,481 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.bn3.weight 4096B
[2022-11-04 19:18:08,481 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.bn3.bias 4096B
[2022-11-04 19:18:08,481 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.conv1.weight 1048576B
[2022-11-04 19:18:08,481 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.bn1.weight 1024B
[2022-11-04 19:18:08,481 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.bn1.bias 1024B
[2022-11-04 19:18:08,481 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.conv2.weight 2359296B
[2022-11-04 19:18:08,481 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.bn2.weight 1024B
[2022-11-04 19:18:08,481 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.bn2.bias 1024B
[2022-11-04 19:18:08,481 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.conv3.weight 1048576B
[2022-11-04 19:18:08,481 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.bn3.weight 4096B
[2022-11-04 19:18:08,481 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.bn3.bias 4096B
[2022-11-04 19:18:08,481 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.conv1.weight 1048576B
[2022-11-04 19:18:08,481 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.bn1.weight 1024B
[2022-11-04 19:18:08,481 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.bn1.bias 1024B
[2022-11-04 19:18:08,481 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.conv2.weight 2359296B
[2022-11-04 19:18:08,482 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.bn2.weight 1024B
[2022-11-04 19:18:08,482 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.bn2.bias 1024B
[2022-11-04 19:18:08,482 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.conv3.weight 1048576B
[2022-11-04 19:18:08,482 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.bn3.weight 4096B
[2022-11-04 19:18:08,482 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.bn3.bias 4096B
[2022-11-04 19:18:08,482 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.conv1.weight 2097152B
[2022-11-04 19:18:08,482 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.bn1.weight 2048B
[2022-11-04 19:18:08,482 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.bn1.bias 2048B
[2022-11-04 19:18:08,482 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.conv2.weight 9437184B
[2022-11-04 19:18:08,482 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.bn2.weight 2048B
[2022-11-04 19:18:08,482 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.bn2.bias 2048B
[2022-11-04 19:18:08,482 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.conv3.weight 4194304B
[2022-11-04 19:18:08,482 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.bn3.weight 8192B
[2022-11-04 19:18:08,482 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.bn3.bias 8192B
[2022-11-04 19:18:08,482 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.downsample.0.weight 8388608B
[2022-11-04 19:18:08,482 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.downsample.1.weight 8192B
[2022-11-04 19:18:08,482 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.downsample.1.bias 8192B
[2022-11-04 19:18:08,482 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.conv1.weight 4194304B
[2022-11-04 19:18:08,482 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.bn1.weight 2048B
[2022-11-04 19:18:08,482 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.bn1.bias 2048B
[2022-11-04 19:18:08,482 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.conv2.weight 9437184B
[2022-11-04 19:18:08,482 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.bn2.weight 2048B
[2022-11-04 19:18:08,483 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.bn2.bias 2048B
[2022-11-04 19:18:08,483 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.conv3.weight 4194304B
[2022-11-04 19:18:08,483 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.bn3.weight 8192B
[2022-11-04 19:18:08,483 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.bn3.bias 8192B
[2022-11-04 19:18:08,483 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.conv1.weight 4194304B
[2022-11-04 19:18:08,483 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.bn1.weight 2048B
[2022-11-04 19:18:08,483 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.bn1.bias 2048B
[2022-11-04 19:18:08,483 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.conv2.weight 9437184B
[2022-11-04 19:18:08,483 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.bn2.weight 2048B
[2022-11-04 19:18:08,483 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.bn2.bias 2048B
[2022-11-04 19:18:08,483 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.conv3.weight 4194304B
[2022-11-04 19:18:08,483 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.bn3.weight 8192B
[2022-11-04 19:18:08,483 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.bn3.bias 8192B
[2022-11-04 19:18:08,483 {dist_trainer.py:192}] <INFO> parameter size: fc.weight 81920B
[2022-11-04 19:18:08,483 {dist_trainer.py:192}] <INFO> parameter size: fc.bias 40B
[2022-11-04 19:18:08,483 {dist_trainer.py:194}] <INFO> Model: resnet50 size: 89.754MiB
[2022-11-04 19:18:10,406 {dist_trainer.py:78}] <INFO> device: cuda:2 0/4, NVIDIA TITAN RTX
[2022-11-04 19:18:11,724 {dist_trainer.py:494}] <INFO> node0: [7,8,2,6,4,5,1,3]
[2022-11-04 19:18:11,724 {dist_trainer.py:494}] <INFO> node1: [4,5,1,3,0,9,7,8]
[2022-11-04 19:18:11,724 {dist_trainer.py:494}] <INFO> node2: [0,9,7,8,2,6,4,5]
[2022-11-04 19:18:11,724 {dist_trainer.py:497}] <INFO> class 0, [node1:0.472,node2:0.528]
[2022-11-04 19:18:11,724 {dist_trainer.py:497}] <INFO> class 1, [node0:0.505,node1:0.495]
[2022-11-04 19:18:11,724 {dist_trainer.py:497}] <INFO> class 2, [node0:0.535,node2:0.465]
[2022-11-04 19:18:11,724 {dist_trainer.py:497}] <INFO> class 3, [node0:0.502,node1:0.498]
[2022-11-04 19:18:11,724 {dist_trainer.py:497}] <INFO> class 4, [node0:0.325,node1:0.361,node2:0.314]
[2022-11-04 19:18:11,724 {dist_trainer.py:497}] <INFO> class 5, [node0:0.327,node1:0.343,node2:0.330]
[2022-11-04 19:18:11,724 {dist_trainer.py:497}] <INFO> class 6, [node0:0.497,node2:0.503]
[2022-11-04 19:18:11,724 {dist_trainer.py:497}] <INFO> class 7, [node0:0.340,node1:0.338,node2:0.322]
[2022-11-04 19:18:11,724 {dist_trainer.py:497}] <INFO> class 8, [node0:0.305,node1:0.352,node2:0.343]
[2022-11-04 19:18:11,724 {dist_trainer.py:497}] <INFO> class 9, [node1:0.475,node2:0.525]
[2022-11-04 19:18:11,726 {dist_trainer.py:527}] <INFO> train data node0: 1:2523,2:2675,3:2509,4:1624,5:1634,6:2484,7:1700,8:1524
[2022-11-04 19:18:11,726 {dist_trainer.py:527}] <INFO> train data node1: 0:2360,1:2477,3:2491,4:1806,5:1714,7:1690,8:1758,9:2375
[2022-11-04 19:18:11,726 {dist_trainer.py:527}] <INFO> train data node2: 0:2640,2:2325,4:1570,5:1652,6:2516,7:1610,8:1718,9:2625
[2022-11-04 19:18:24,753 {dist_trainer.py:531}] <INFO> split_load_datas(END)
[2022-11-04 19:18:24,754 {dist_trainer.py:114}] <INFO> datasets(END)
[2022-11-04 19:18:24,754 {dist_trainer.py:713}] <INFO> build_criterion(1)
[2022-11-04 19:18:24,754 {dist_trainer.py:721}] <INFO> build_criterion(2)
[2022-11-04 19:18:24,765 {contract.py:21}] <INFO> 0
[2022-11-04 19:18:24,765 {contract.py:21}] <INFO> 1
[2022-11-04 19:18:24,765 {contract.py:21}] <INFO> 2
[2022-11-04 19:18:28,098 {distributed_c10d.py:228}] <INFO> Added key: store_based_barrier_key:1 to store for rank: 1
[2022-11-04 19:18:28,098 {distributed_c10d.py:262}] <INFO> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
[2022-11-04 19:18:28,197 {gateway.py:85}] <INFO> node0
[2022-11-04 19:18:28,268 {gateway.py:85}] <INFO> node2
[2022-11-04 19:18:28,279 {contract.py:36}] <INFO> contract(1)
[2022-11-04 19:18:28,319 {contract.py:44}] <INFO> <CLI> node1 : edge setup.
[2022-11-04 19:18:28,378 {gateway.py:59}] <INFO> <SRV> node1 : edge setup.
[2022-11-04 19:18:28,680 {contract.py:59}] <INFO> contract(2)
[2022-11-04 19:18:28,693 {admm_sgd.py:51}] <INFO> Optimizer <class 'optimizer.admm_sgd.AdmmSGD'> params: {'lr': 0.005, 'mu': 200, 'eta': 1.0, 'rho': 0.1, 'initial_lr': 0.005, 'eta_rate': 0.005}
[2022-11-04 19:18:28,693 {dist_trainer.py:725}] <INFO> build_optimizer()
[2022-11-04 19:18:28,693 {dist_trainer.py:736}] <INFO> Setup scheduler: <torch.optim.lr_scheduler.StepLR object at 0x7febbd492490>
[2022-11-04 19:18:55,701 {dist_trainer.py:770}] <INFO> [   1/ 200] connecting edge count: 2
[2022-11-04 19:19:09,223 {dist_trainer.py:821}] <INFO> [   1/ 200] loss: (train=2.455, val=2.693, test=2.693, l2=11637.143), acc: (train=0.115, val=0.118, test=0.119), diff=0.00261237, proc(train=27.007sec, eval=11.707sec)
[2022-11-04 19:19:31,697 {dist_trainer.py:770}] <INFO> [   2/ 200] connecting edge count: 2
[2022-11-04 19:19:45,138 {dist_trainer.py:821}] <INFO> [   2/ 200] loss: (train=2.591, val=2.499, test=2.498, l2=12559.608), acc: (train=0.148, val=0.101, test=0.101), diff=0.00017483, proc(train=22.474sec, eval=11.419sec)
[2022-11-04 19:20:09,248 {dist_trainer.py:770}] <INFO> [   3/ 200] connecting edge count: 2
[2022-11-04 19:20:23,312 {dist_trainer.py:821}] <INFO> [   3/ 200] loss: (train=2.541, val=2.359, test=2.359, l2=12507.485), acc: (train=0.211, val=0.163, test=0.162), diff=0.00002871, proc(train=24.109sec, eval=11.761sec)
[2022-11-04 19:20:47,478 {dist_trainer.py:770}] <INFO> [   4/ 200] connecting edge count: 2
[2022-11-04 19:21:00,661 {dist_trainer.py:821}] <INFO> [   4/ 200] loss: (train=2.348, val=2.352, test=2.345, l2=12448.283), acc: (train=0.191, val=0.125, test=0.126), diff=0.00000098, proc(train=24.166sec, eval=11.434sec)
[2022-11-04 19:21:25,044 {dist_trainer.py:770}] <INFO> [   5/ 200] connecting edge count: 2
[2022-11-04 19:21:39,691 {dist_trainer.py:821}] <INFO> [   5/ 200] loss: (train=2.328, val=2.166, test=2.163, l2=12440.576), acc: (train=0.214, val=0.169, test=0.169), diff=0.00000078, proc(train=24.383sec, eval=11.689sec)
[2022-11-04 19:22:03,574 {dist_trainer.py:770}] <INFO> [   6/ 200] connecting edge count: 2
[2022-11-04 19:22:16,457 {dist_trainer.py:821}] <INFO> [   6/ 200] loss: (train=2.261, val=2.149, test=2.149, l2=12377.835), acc: (train=0.240, val=0.209, test=0.210), diff=0.00000098, proc(train=23.883sec, eval=11.557sec)
[2022-11-04 19:22:38,292 {dist_trainer.py:770}] <INFO> [   7/ 200] connecting edge count: 2
[2022-11-04 19:22:51,512 {dist_trainer.py:821}] <INFO> [   7/ 200] loss: (train=2.143, val=2.114, test=2.110, l2=12357.415), acc: (train=0.205, val=0.186, test=0.183), diff=0.00000063, proc(train=21.835sec, eval=11.653sec)
[2022-11-04 19:23:17,368 {dist_trainer.py:770}] <INFO> [   8/ 200] connecting edge count: 2
[2022-11-04 19:23:30,102 {dist_trainer.py:821}] <INFO> [   8/ 200] loss: (train=2.119, val=2.111, test=2.106, l2=12313.350), acc: (train=0.239, val=0.194, test=0.201), diff=0.00000057, proc(train=25.856sec, eval=11.713sec)
[2022-11-04 19:23:52,515 {dist_trainer.py:770}] <INFO> [   9/ 200] connecting edge count: 2
[2022-11-04 19:24:06,115 {dist_trainer.py:821}] <INFO> [   9/ 200] loss: (train=2.133, val=2.100, test=2.098, l2=12287.176), acc: (train=0.200, val=0.211, test=0.213), diff=0.00000088, proc(train=22.412sec, eval=11.460sec)
[2022-11-04 19:24:30,654 {dist_trainer.py:770}] <INFO> [  10/ 200] connecting edge count: 2
[2022-11-04 19:24:43,457 {dist_trainer.py:821}] <INFO> [  10/ 200] loss: (train=2.123, val=1.949, test=1.939, l2=12286.265), acc: (train=0.320, val=0.239, test=0.238), diff=0.00000124, proc(train=24.539sec, eval=11.667sec)
[2022-11-04 19:25:10,204 {dist_trainer.py:770}] <INFO> [  11/ 200] connecting edge count: 2
[2022-11-04 19:25:23,135 {dist_trainer.py:821}] <INFO> [  11/ 200] loss: (train=2.046, val=2.084, test=2.072, l2=12228.847), acc: (train=0.271, val=0.194, test=0.193), diff=0.00000053, proc(train=26.747sec, eval=11.420sec)
[2022-11-04 19:25:47,699 {dist_trainer.py:770}] <INFO> [  12/ 200] connecting edge count: 2
[2022-11-04 19:26:00,931 {dist_trainer.py:821}] <INFO> [  12/ 200] loss: (train=2.085, val=2.329, test=2.330, l2=12215.175), acc: (train=0.238, val=0.193, test=0.193), diff=0.00000064, proc(train=24.564sec, eval=11.702sec)
[2022-11-04 19:26:24,766 {dist_trainer.py:770}] <INFO> [  13/ 200] connecting edge count: 2
[2022-11-04 19:26:37,876 {dist_trainer.py:821}] <INFO> [  13/ 200] loss: (train=2.000, val=1.832, test=1.822, l2=12158.236), acc: (train=0.361, val=0.323, test=0.330), diff=0.00000076, proc(train=23.835sec, eval=11.572sec)
[2022-11-04 19:26:59,822 {dist_trainer.py:770}] <INFO> [  14/ 200] connecting edge count: 2
[2022-11-04 19:27:12,867 {dist_trainer.py:821}] <INFO> [  14/ 200] loss: (train=2.004, val=2.024, test=2.011, l2=12133.068), acc: (train=0.269, val=0.263, test=0.268), diff=0.00000063, proc(train=21.946sec, eval=11.424sec)
[2022-11-04 19:27:38,037 {dist_trainer.py:770}] <INFO> [  15/ 200] connecting edge count: 2
[2022-11-04 19:27:51,119 {dist_trainer.py:821}] <INFO> [  15/ 200] loss: (train=1.947, val=2.006, test=1.994, l2=12097.648), acc: (train=0.314, val=0.300, test=0.307), diff=0.00000115, proc(train=25.170sec, eval=11.715sec)
[2022-11-04 19:28:14,981 {dist_trainer.py:770}] <INFO> [  16/ 200] connecting edge count: 2
[2022-11-04 19:28:28,514 {dist_trainer.py:821}] <INFO> [  16/ 200] loss: (train=1.899, val=1.947, test=1.939, l2=12066.161), acc: (train=0.298, val=0.298, test=0.307), diff=0.00000085, proc(train=23.862sec, eval=11.387sec)
[2022-11-04 19:28:52,037 {dist_trainer.py:770}] <INFO> [  17/ 200] connecting edge count: 2
[2022-11-04 19:29:05,274 {dist_trainer.py:821}] <INFO> [  17/ 200] loss: (train=1.943, val=1.878, test=1.870, l2=12067.055), acc: (train=0.340, val=0.308, test=0.311), diff=0.00000254, proc(train=23.523sec, eval=11.721sec)
[2022-11-04 19:29:32,071 {dist_trainer.py:770}] <INFO> [  18/ 200] connecting edge count: 2
[2022-11-04 19:29:44,760 {dist_trainer.py:821}] <INFO> [  18/ 200] loss: (train=1.859, val=1.828, test=1.823, l2=12004.989), acc: (train=0.380, val=0.344, test=0.343), diff=0.00000072, proc(train=26.797sec, eval=11.447sec)
[2022-11-04 19:30:08,884 {dist_trainer.py:770}] <INFO> [  19/ 200] connecting edge count: 2
[2022-11-04 19:30:22,034 {dist_trainer.py:821}] <INFO> [  19/ 200] loss: (train=1.883, val=1.739, test=1.728, l2=11994.315), acc: (train=0.393, val=0.358, test=0.368), diff=0.00000059, proc(train=24.124sec, eval=11.553sec)
[2022-11-04 19:30:47,042 {dist_trainer.py:770}] <INFO> [  20/ 200] connecting edge count: 2
[2022-11-04 19:31:00,036 {dist_trainer.py:821}] <INFO> [  20/ 200] loss: (train=1.863, val=1.789, test=1.782, l2=11937.338), acc: (train=0.358, val=0.344, test=0.346), diff=0.00000080, proc(train=25.007sec, eval=11.528sec)
[2022-11-04 19:31:22,019 {dist_trainer.py:770}] <INFO> [  21/ 200] connecting edge count: 2
[2022-11-04 19:31:34,922 {dist_trainer.py:821}] <INFO> [  21/ 200] loss: (train=1.854, val=1.715, test=1.713, l2=11912.829), acc: (train=0.417, val=0.377, test=0.381), diff=0.00000068, proc(train=21.983sec, eval=11.409sec)
[2022-11-04 19:31:58,593 {dist_trainer.py:770}] <INFO> [  22/ 200] connecting edge count: 2
[2022-11-04 19:32:12,471 {dist_trainer.py:821}] <INFO> [  22/ 200] loss: (train=1.810, val=1.660, test=1.653, l2=11879.811), acc: (train=0.452, val=0.382, test=0.385), diff=0.00000128, proc(train=23.671sec, eval=11.665sec)
[2022-11-04 19:32:36,337 {dist_trainer.py:770}] <INFO> [  23/ 200] connecting edge count: 2
[2022-11-04 19:32:49,926 {dist_trainer.py:821}] <INFO> [  23/ 200] loss: (train=1.795, val=1.673, test=1.671, l2=11855.762), acc: (train=0.454, val=0.387, test=0.386), diff=0.00000073, proc(train=23.865sec, eval=11.411sec)
[2022-11-04 19:33:15,438 {dist_trainer.py:770}] <INFO> [  24/ 200] connecting edge count: 2
[2022-11-04 19:33:29,070 {dist_trainer.py:821}] <INFO> [  24/ 200] loss: (train=1.826, val=1.651, test=1.650, l2=11850.243), acc: (train=0.394, val=0.394, test=0.393), diff=0.00000127, proc(train=25.511sec, eval=11.714sec)
[2022-11-04 19:33:55,735 {dist_trainer.py:770}] <INFO> [  25/ 200] connecting edge count: 2
[2022-11-04 19:34:08,482 {dist_trainer.py:821}] <INFO> [  25/ 200] loss: (train=1.716, val=1.724, test=1.722, l2=11794.400), acc: (train=0.428, val=0.363, test=0.363), diff=0.00000072, proc(train=26.665sec, eval=11.478sec)
[2022-11-04 19:34:33,227 {dist_trainer.py:770}] <INFO> [  26/ 200] connecting edge count: 2
[2022-11-04 19:34:46,370 {dist_trainer.py:821}] <INFO> [  26/ 200] loss: (train=1.750, val=1.664, test=1.656, l2=11783.169), acc: (train=0.432, val=0.384, test=0.392), diff=0.00000056, proc(train=24.744sec, eval=11.705sec)
[2022-11-04 19:35:12,656 {dist_trainer.py:770}] <INFO> [  27/ 200] connecting edge count: 2
[2022-11-04 19:35:26,203 {dist_trainer.py:821}] <INFO> [  27/ 200] loss: (train=1.709, val=1.600, test=1.601, l2=11727.268), acc: (train=0.475, val=0.421, test=0.419), diff=0.00000083, proc(train=26.286sec, eval=11.628sec)
[2022-11-04 19:35:48,053 {dist_trainer.py:770}] <INFO> [  28/ 200] connecting edge count: 2
[2022-11-04 19:36:00,824 {dist_trainer.py:821}] <INFO> [  28/ 200] loss: (train=1.696, val=1.691, test=1.687, l2=11702.846), acc: (train=0.439, val=0.381, test=0.384), diff=0.00000066, proc(train=21.850sec, eval=11.513sec)
[2022-11-04 19:36:24,853 {dist_trainer.py:770}] <INFO> [  29/ 200] connecting edge count: 2
[2022-11-04 19:36:37,454 {dist_trainer.py:821}] <INFO> [  29/ 200] loss: (train=1.706, val=1.591, test=1.588, l2=11671.677), acc: (train=0.467, val=0.422, test=0.420), diff=0.00000068, proc(train=24.029sec, eval=11.723sec)
[2022-11-04 19:37:00,917 {dist_trainer.py:770}] <INFO> [  30/ 200] connecting edge count: 2
[2022-11-04 19:37:14,376 {dist_trainer.py:821}] <INFO> [  30/ 200] loss: (train=1.657, val=1.551, test=1.556, l2=11630.770), acc: (train=0.443, val=0.431, test=0.426), diff=0.00000059, proc(train=23.463sec, eval=11.430sec)
[2022-11-04 19:37:39,083 {dist_trainer.py:770}] <INFO> [  31/ 200] connecting edge count: 2
[2022-11-04 19:37:52,357 {dist_trainer.py:821}] <INFO> [  31/ 200] loss: (train=1.684, val=1.611, test=1.617, l2=11624.440), acc: (train=0.453, val=0.413, test=0.410), diff=0.00000076, proc(train=24.707sec, eval=11.713sec)
[2022-11-04 19:38:19,010 {dist_trainer.py:770}] <INFO> [  32/ 200] connecting edge count: 2
[2022-11-04 19:38:31,720 {dist_trainer.py:821}] <INFO> [  32/ 200] loss: (train=1.650, val=1.489, test=1.500, l2=11566.622), acc: (train=0.449, val=0.464, test=0.456), diff=0.00000054, proc(train=26.652sec, eval=11.434sec)
[2022-11-04 19:38:54,847 {dist_trainer.py:770}] <INFO> [  33/ 200] connecting edge count: 2
[2022-11-04 19:39:07,719 {dist_trainer.py:821}] <INFO> [  33/ 200] loss: (train=1.633, val=1.613, test=1.630, l2=11552.138), acc: (train=0.439, val=0.430, test=0.419), diff=0.00000050, proc(train=23.126sec, eval=11.582sec)
[2022-11-04 19:39:33,964 {dist_trainer.py:770}] <INFO> [  34/ 200] connecting edge count: 2
[2022-11-04 19:39:47,193 {dist_trainer.py:821}] <INFO> [  34/ 200] loss: (train=1.605, val=1.570, test=1.576, l2=11501.887), acc: (train=0.435, val=0.443, test=0.436), diff=0.00000089, proc(train=26.244sec, eval=11.627sec)
[2022-11-04 19:40:09,387 {dist_trainer.py:770}] <INFO> [  35/ 200] connecting edge count: 2
[2022-11-04 19:40:22,435 {dist_trainer.py:821}] <INFO> [  35/ 200] loss: (train=1.593, val=1.506, test=1.514, l2=11476.920), acc: (train=0.462, val=0.454, test=0.452), diff=0.00000065, proc(train=22.193sec, eval=11.484sec)
[2022-11-04 19:40:46,285 {dist_trainer.py:770}] <INFO> [  36/ 200] connecting edge count: 2
[2022-11-04 19:40:59,102 {dist_trainer.py:821}] <INFO> [  36/ 200] loss: (train=1.599, val=1.530, test=1.538, l2=11462.356), acc: (train=0.472, val=0.448, test=0.441), diff=0.00000091, proc(train=23.849sec, eval=11.844sec)
[2022-11-04 19:41:24,083 {dist_trainer.py:770}] <INFO> [  37/ 200] connecting edge count: 2
[2022-11-04 19:41:36,817 {dist_trainer.py:821}] <INFO> [  37/ 200] loss: (train=1.606, val=1.512, test=1.526, l2=11416.146), acc: (train=0.434, val=0.453, test=0.449), diff=0.00000063, proc(train=24.981sec, eval=11.524sec)
[2022-11-04 19:42:01,674 {dist_trainer.py:770}] <INFO> [  38/ 200] connecting edge count: 2
[2022-11-04 19:42:15,136 {dist_trainer.py:821}] <INFO> [  38/ 200] loss: (train=1.588, val=1.677, test=1.678, l2=11407.957), acc: (train=0.438, val=0.377, test=0.377), diff=0.00000080, proc(train=24.857sec, eval=11.764sec)
[2022-11-04 19:42:39,712 {dist_trainer.py:770}] <INFO> [  39/ 200] connecting edge count: 2
[2022-11-04 19:42:52,661 {dist_trainer.py:821}] <INFO> [  39/ 200] loss: (train=1.585, val=1.569, test=1.574, l2=11355.418), acc: (train=0.478, val=0.429, test=0.432), diff=0.00000092, proc(train=24.576sec, eval=11.697sec)
[2022-11-04 19:43:14,631 {dist_trainer.py:770}] <INFO> [  40/ 200] connecting edge count: 2
[2022-11-04 19:43:27,602 {dist_trainer.py:821}] <INFO> [  40/ 200] loss: (train=1.563, val=1.519, test=1.539, l2=11332.745), acc: (train=0.469, val=0.458, test=0.450), diff=0.00000112, proc(train=21.970sec, eval=11.616sec)
[2022-11-04 19:43:51,445 {dist_trainer.py:770}] <INFO> [  41/ 200] connecting edge count: 2
[2022-11-04 19:44:04,598 {dist_trainer.py:821}] <INFO> [  41/ 200] loss: (train=1.539, val=1.612, test=1.613, l2=11297.501), acc: (train=0.468, val=0.412, test=0.413), diff=0.00000105, proc(train=23.843sec, eval=11.756sec)
[2022-11-04 19:44:26,744 {dist_trainer.py:770}] <INFO> [  42/ 200] connecting edge count: 2
[2022-11-04 19:44:39,948 {dist_trainer.py:821}] <INFO> [  42/ 200] loss: (train=1.574, val=1.493, test=1.506, l2=11266.848), acc: (train=0.464, val=0.455, test=0.447), diff=0.00000083, proc(train=22.146sec, eval=11.728sec)
[2022-11-04 19:45:03,178 {dist_trainer.py:770}] <INFO> [  43/ 200] connecting edge count: 2
[2022-11-04 19:45:16,689 {dist_trainer.py:821}] <INFO> [  43/ 200] loss: (train=1.577, val=1.479, test=1.495, l2=11264.684), acc: (train=0.486, val=0.470, test=0.460), diff=0.00000086, proc(train=23.230sec, eval=11.904sec)
[2022-11-04 19:45:43,833 {dist_trainer.py:770}] <INFO> [  44/ 200] connecting edge count: 2
[2022-11-04 19:45:56,582 {dist_trainer.py:821}] <INFO> [  44/ 200] loss: (train=1.511, val=1.419, test=1.434, l2=11207.194), acc: (train=0.492, val=0.483, test=0.478), diff=0.00000093, proc(train=27.144sec, eval=11.584sec)
[2022-11-04 19:46:21,571 {dist_trainer.py:770}] <INFO> [  45/ 200] connecting edge count: 2
[2022-11-04 19:46:34,251 {dist_trainer.py:821}] <INFO> [  45/ 200] loss: (train=1.571, val=1.511, test=1.528, l2=11197.957), acc: (train=0.482, val=0.469, test=0.461), diff=0.00000080, proc(train=24.989sec, eval=11.737sec)
[2022-11-04 19:46:57,864 {dist_trainer.py:770}] <INFO> [  46/ 200] connecting edge count: 2
[2022-11-04 19:47:11,016 {dist_trainer.py:821}] <INFO> [  46/ 200] loss: (train=1.526, val=1.469, test=1.494, l2=11154.373), acc: (train=0.555, val=0.476, test=0.463), diff=0.00000092, proc(train=23.613sec, eval=11.952sec)
[2022-11-04 19:47:33,059 {dist_trainer.py:770}] <INFO> [  47/ 200] connecting edge count: 2
[2022-11-04 19:47:46,345 {dist_trainer.py:821}] <INFO> [  47/ 200] loss: (train=1.498, val=1.454, test=1.463, l2=11125.495), acc: (train=0.512, val=0.469, test=0.465), diff=0.00000101, proc(train=22.042sec, eval=11.658sec)
[2022-11-04 19:48:12,021 {dist_trainer.py:770}] <INFO> [  48/ 200] connecting edge count: 2
[2022-11-04 19:48:25,139 {dist_trainer.py:821}] <INFO> [  48/ 200] loss: (train=1.503, val=1.403, test=1.426, l2=11093.690), acc: (train=0.475, val=0.491, test=0.482), diff=0.00000084, proc(train=25.675sec, eval=11.869sec)
[2022-11-04 19:48:47,332 {dist_trainer.py:770}] <INFO> [  49/ 200] connecting edge count: 2
[2022-11-04 19:49:00,360 {dist_trainer.py:821}] <INFO> [  49/ 200] loss: (train=1.513, val=1.449, test=1.474, l2=11059.138), acc: (train=0.509, val=0.484, test=0.476), diff=0.00000077, proc(train=22.193sec, eval=11.734sec)
[2022-11-04 19:49:23,652 {dist_trainer.py:770}] <INFO> [  50/ 200] connecting edge count: 2
[2022-11-04 19:49:37,083 {dist_trainer.py:821}] <INFO> [  50/ 200] loss: (train=1.460, val=1.411, test=1.431, l2=11056.271), acc: (train=0.504, val=0.493, test=0.481), diff=0.00000091, proc(train=23.292sec, eval=11.977sec)
[2022-11-04 19:49:59,753 {dist_trainer.py:770}] <INFO> [  51/ 200] connecting edge count: 2
[2022-11-04 19:50:13,442 {dist_trainer.py:821}] <INFO> [  51/ 200] loss: (train=1.491, val=1.353, test=1.374, l2=11010.767), acc: (train=0.549, val=0.511, test=0.506), diff=0.00000103, proc(train=22.669sec, eval=11.805sec)
[2022-11-04 19:50:35,711 {dist_trainer.py:770}] <INFO> [  52/ 200] connecting edge count: 2
[2022-11-04 19:50:48,749 {dist_trainer.py:821}] <INFO> [  52/ 200] loss: (train=1.553, val=1.693, test=1.719, l2=10989.659), acc: (train=0.396, val=0.417, test=0.414), diff=0.00000106, proc(train=22.269sec, eval=11.715sec)
[2022-11-04 19:51:10,671 {dist_trainer.py:770}] <INFO> [  53/ 200] connecting edge count: 2
[2022-11-04 19:51:24,031 {dist_trainer.py:821}] <INFO> [  53/ 200] loss: (train=1.530, val=1.418, test=1.450, l2=10967.492), acc: (train=0.475, val=0.478, test=0.466), diff=0.00000096, proc(train=21.922sec, eval=11.945sec)
[2022-11-04 19:51:47,236 {dist_trainer.py:770}] <INFO> [  54/ 200] connecting edge count: 2
[2022-11-04 19:52:00,295 {dist_trainer.py:821}] <INFO> [  54/ 200] loss: (train=1.475, val=1.396, test=1.421, l2=10942.335), acc: (train=0.509, val=0.497, test=0.484), diff=0.00000068, proc(train=23.204sec, eval=11.662sec)
[2022-11-04 19:52:24,909 {dist_trainer.py:770}] <INFO> [  55/ 200] connecting edge count: 2
[2022-11-04 19:52:39,234 {dist_trainer.py:821}] <INFO> [  55/ 200] loss: (train=1.457, val=1.471, test=1.497, l2=10930.122), acc: (train=0.455, val=0.463, test=0.453), diff=0.00000126, proc(train=24.614sec, eval=11.947sec)
[2022-11-04 19:53:03,361 {dist_trainer.py:770}] <INFO> [  56/ 200] connecting edge count: 2
[2022-11-04 19:53:16,317 {dist_trainer.py:821}] <INFO> [  56/ 200] loss: (train=1.422, val=1.317, test=1.343, l2=10891.575), acc: (train=0.557, val=0.526, test=0.519), diff=0.00000100, proc(train=24.127sec, eval=11.695sec)
[2022-11-04 19:53:39,963 {dist_trainer.py:770}] <INFO> [  57/ 200] connecting edge count: 2
[2022-11-04 19:53:52,912 {dist_trainer.py:821}] <INFO> [  57/ 200] loss: (train=1.450, val=1.380, test=1.401, l2=10877.173), acc: (train=0.505, val=0.505, test=0.495), diff=0.00625153, proc(train=23.645sec, eval=11.818sec)
[2022-11-04 19:54:17,995 {dist_trainer.py:770}] <INFO> [  58/ 200] connecting edge count: 2
[2022-11-04 19:54:31,951 {dist_trainer.py:821}] <INFO> [  58/ 200] loss: (train=1.391, val=1.310, test=1.337, l2=9513.087), acc: (train=0.562, val=0.525, test=0.515), diff=0.00015240, proc(train=25.082sec, eval=11.947sec)
[2022-11-04 19:54:54,651 {dist_trainer.py:770}] <INFO> [  59/ 200] connecting edge count: 2
[2022-11-04 19:55:08,172 {dist_trainer.py:821}] <INFO> [  59/ 200] loss: (train=1.380, val=1.429, test=1.442, l2=9586.925), acc: (train=0.501, val=0.484, test=0.488), diff=0.00007126, proc(train=22.699sec, eval=11.704sec)
[2022-11-04 19:55:30,906 {dist_trainer.py:770}] <INFO> [  60/ 200] connecting edge count: 2
[2022-11-04 19:55:44,868 {dist_trainer.py:821}] <INFO> [  60/ 200] loss: (train=1.420, val=1.321, test=1.350, l2=9593.197), acc: (train=0.535, val=0.528, test=0.523), diff=0.00002017, proc(train=22.734sec, eval=11.893sec)
[2022-11-04 19:56:06,982 {dist_trainer.py:770}] <INFO> [  61/ 200] connecting edge count: 2
[2022-11-04 19:56:20,124 {dist_trainer.py:821}] <INFO> [  61/ 200] loss: (train=1.405, val=1.315, test=1.351, l2=9559.363), acc: (train=0.551, val=0.522, test=0.505), diff=0.00000161, proc(train=22.113sec, eval=11.686sec)
[2022-11-04 19:56:44,314 {dist_trainer.py:770}] <INFO> [  62/ 200] connecting edge count: 2
[2022-11-04 19:56:58,430 {dist_trainer.py:821}] <INFO> [  62/ 200] loss: (train=1.406, val=1.314, test=1.347, l2=9551.054), acc: (train=0.534, val=0.529, test=0.517), diff=0.00000133, proc(train=24.190sec, eval=11.934sec)
[2022-11-04 19:57:24,475 {dist_trainer.py:770}] <INFO> [  63/ 200] connecting edge count: 2
[2022-11-04 19:57:37,591 {dist_trainer.py:821}] <INFO> [  63/ 200] loss: (train=1.423, val=1.321, test=1.349, l2=9508.740), acc: (train=0.544, val=0.537, test=0.527), diff=0.00000073, proc(train=26.044sec, eval=11.730sec)
[2022-11-04 19:58:01,201 {dist_trainer.py:770}] <INFO> [  64/ 200] connecting edge count: 2
[2022-11-04 19:58:14,043 {dist_trainer.py:821}] <INFO> [  64/ 200] loss: (train=1.409, val=1.331, test=1.369, l2=9498.696), acc: (train=0.539, val=0.524, test=0.517), diff=0.00000055, proc(train=23.610sec, eval=11.814sec)
[2022-11-04 19:58:38,076 {dist_trainer.py:770}] <INFO> [  65/ 200] connecting edge count: 2
[2022-11-04 19:58:51,327 {dist_trainer.py:821}] <INFO> [  65/ 200] loss: (train=1.394, val=1.259, test=1.295, l2=9467.210), acc: (train=0.569, val=0.553, test=0.542), diff=0.00000103, proc(train=24.033sec, eval=11.829sec)
[2022-11-04 19:59:14,158 {dist_trainer.py:770}] <INFO> [  66/ 200] connecting edge count: 2
[2022-11-04 19:59:28,193 {dist_trainer.py:821}] <INFO> [  66/ 200] loss: (train=1.342, val=1.284, test=1.321, l2=9441.050), acc: (train=0.535, val=0.541, test=0.532), diff=0.00000085, proc(train=22.831sec, eval=11.658sec)
[2022-11-04 19:59:51,366 {dist_trainer.py:770}] <INFO> [  67/ 200] connecting edge count: 2
[2022-11-04 20:00:05,103 {dist_trainer.py:821}] <INFO> [  67/ 200] loss: (train=1.365, val=1.374, test=1.411, l2=9425.142), acc: (train=0.535, val=0.511, test=0.505), diff=0.00000112, proc(train=23.172sec, eval=11.896sec)
[2022-11-04 20:00:29,188 {dist_trainer.py:770}] <INFO> [  68/ 200] connecting edge count: 2
[2022-11-04 20:00:42,213 {dist_trainer.py:821}] <INFO> [  68/ 200] loss: (train=1.374, val=1.361, test=1.396, l2=9393.212), acc: (train=0.578, val=0.508, test=0.500), diff=0.00000099, proc(train=24.085sec, eval=11.788sec)
[2022-11-04 20:01:05,770 {dist_trainer.py:770}] <INFO> [  69/ 200] connecting edge count: 2
[2022-11-04 20:01:19,578 {dist_trainer.py:821}] <INFO> [  69/ 200] loss: (train=1.408, val=1.331, test=1.366, l2=9386.452), acc: (train=0.516, val=0.524, test=0.517), diff=0.00000094, proc(train=23.557sec, eval=11.927sec)
[2022-11-04 20:01:42,070 {dist_trainer.py:770}] <INFO> [  70/ 200] connecting edge count: 2
[2022-11-04 20:01:55,660 {dist_trainer.py:821}] <INFO> [  70/ 200] loss: (train=1.338, val=1.323, test=1.347, l2=9348.062), acc: (train=0.525, val=0.526, test=0.521), diff=0.00000084, proc(train=22.492sec, eval=11.779sec)
[2022-11-04 20:02:19,144 {dist_trainer.py:770}] <INFO> [  71/ 200] connecting edge count: 2
[2022-11-04 20:02:32,481 {dist_trainer.py:821}] <INFO> [  71/ 200] loss: (train=1.324, val=1.690, test=1.714, l2=9339.301), acc: (train=0.466, val=0.423, test=0.416), diff=0.00000109, proc(train=23.484sec, eval=11.668sec)
[2022-11-04 20:02:53,765 {dist_trainer.py:770}] <INFO> [  72/ 200] connecting edge count: 2
[2022-11-04 20:03:06,903 {dist_trainer.py:821}] <INFO> [  72/ 200] loss: (train=1.309, val=1.636, test=1.672, l2=9317.080), acc: (train=0.485, val=0.444, test=0.442), diff=0.00000084, proc(train=21.283sec, eval=11.959sec)
[2022-11-04 20:03:30,109 {dist_trainer.py:770}] <INFO> [  73/ 200] connecting edge count: 2
[2022-11-04 20:03:43,186 {dist_trainer.py:821}] <INFO> [  73/ 200] loss: (train=1.328, val=1.377, test=1.407, l2=9291.142), acc: (train=0.531, val=0.512, test=0.503), diff=0.00000147, proc(train=23.205sec, eval=11.715sec)
[2022-11-04 20:04:07,400 {dist_trainer.py:770}] <INFO> [  74/ 200] connecting edge count: 2
[2022-11-04 20:04:21,130 {dist_trainer.py:821}] <INFO> [  74/ 200] loss: (train=1.353, val=1.308, test=1.353, l2=9286.035), acc: (train=0.539, val=0.542, test=0.533), diff=0.00000105, proc(train=24.214sec, eval=11.820sec)
[2022-11-04 20:04:43,756 {dist_trainer.py:770}] <INFO> [  75/ 200] connecting edge count: 2
[2022-11-04 20:04:57,024 {dist_trainer.py:821}] <INFO> [  75/ 200] loss: (train=1.312, val=1.259, test=1.296, l2=9246.184), acc: (train=0.576, val=0.554, test=0.545), diff=0.00000068, proc(train=22.626sec, eval=11.661sec)
[2022-11-04 20:05:19,860 {dist_trainer.py:770}] <INFO> [  76/ 200] connecting edge count: 2
[2022-11-04 20:05:34,468 {dist_trainer.py:821}] <INFO> [  76/ 200] loss: (train=1.328, val=1.398, test=1.439, l2=9231.071), acc: (train=0.509, val=0.506, test=0.496), diff=0.00000062, proc(train=22.836sec, eval=11.857sec)
[2022-11-04 20:05:59,326 {dist_trainer.py:770}] <INFO> [  77/ 200] connecting edge count: 2
[2022-11-04 20:06:13,366 {dist_trainer.py:821}] <INFO> [  77/ 200] loss: (train=1.287, val=1.220, test=1.274, l2=9195.083), acc: (train=0.553, val=0.566, test=0.546), diff=0.00000115, proc(train=24.859sec, eval=11.816sec)
[2022-11-04 20:06:36,299 {dist_trainer.py:770}] <INFO> [  78/ 200] connecting edge count: 2
[2022-11-04 20:06:50,195 {dist_trainer.py:821}] <INFO> [  78/ 200] loss: (train=1.320, val=1.215, test=1.264, l2=9172.854), acc: (train=0.527, val=0.554, test=0.536), diff=0.00000090, proc(train=22.933sec, eval=11.761sec)
[2022-11-04 20:07:14,866 {dist_trainer.py:770}] <INFO> [  79/ 200] connecting edge count: 2
[2022-11-04 20:07:27,924 {dist_trainer.py:821}] <INFO> [  79/ 200] loss: (train=1.312, val=1.302, test=1.347, l2=9149.731), acc: (train=0.521, val=0.533, test=0.527), diff=0.00000118, proc(train=24.670sec, eval=12.003sec)
[2022-11-04 20:07:51,612 {dist_trainer.py:770}] <INFO> [  80/ 200] connecting edge count: 2
[2022-11-04 20:08:04,904 {dist_trainer.py:821}] <INFO> [  80/ 200] loss: (train=1.312, val=1.229, test=1.273, l2=9123.781), acc: (train=0.573, val=0.565, test=0.558), diff=0.00000085, proc(train=23.688sec, eval=11.746sec)
[2022-11-04 20:08:28,732 {dist_trainer.py:770}] <INFO> [  81/ 200] connecting edge count: 2
[2022-11-04 20:08:41,869 {dist_trainer.py:821}] <INFO> [  81/ 200] loss: (train=1.306, val=1.206, test=1.263, l2=9115.728), acc: (train=0.596, val=0.571, test=0.554), diff=0.00000149, proc(train=23.828sec, eval=11.876sec)
[2022-11-04 20:09:07,454 {dist_trainer.py:770}] <INFO> [  82/ 200] connecting edge count: 2
[2022-11-04 20:09:20,285 {dist_trainer.py:821}] <INFO> [  82/ 200] loss: (train=1.314, val=1.192, test=1.236, l2=9077.748), acc: (train=0.568, val=0.576, test=0.565), diff=0.00000122, proc(train=25.585sec, eval=11.632sec)
[2022-11-04 20:09:44,599 {dist_trainer.py:770}] <INFO> [  83/ 200] connecting edge count: 2
[2022-11-04 20:09:57,539 {dist_trainer.py:821}] <INFO> [  83/ 200] loss: (train=1.383, val=1.315, test=1.363, l2=9077.206), acc: (train=0.498, val=0.511, test=0.500), diff=0.00000089, proc(train=24.313sec, eval=11.833sec)
[2022-11-04 20:10:21,637 {dist_trainer.py:770}] <INFO> [  84/ 200] connecting edge count: 2
[2022-11-04 20:10:35,336 {dist_trainer.py:821}] <INFO> [  84/ 200] loss: (train=1.289, val=1.229, test=1.285, l2=9047.854), acc: (train=0.570, val=0.568, test=0.548), diff=0.00000101, proc(train=24.098sec, eval=11.820sec)
[2022-11-04 20:10:58,015 {dist_trainer.py:770}] <INFO> [  85/ 200] connecting edge count: 2
[2022-11-04 20:11:11,879 {dist_trainer.py:821}] <INFO> [  85/ 200] loss: (train=1.269, val=1.150, test=1.202, l2=9026.169), acc: (train=0.603, val=0.594, test=0.585), diff=0.00000097, proc(train=22.679sec, eval=11.665sec)
[2022-11-04 20:11:35,333 {dist_trainer.py:770}] <INFO> [  86/ 200] connecting edge count: 2
[2022-11-04 20:11:49,739 {dist_trainer.py:821}] <INFO> [  86/ 200] loss: (train=1.266, val=1.220, test=1.274, l2=8999.618), acc: (train=0.596, val=0.571, test=0.556), diff=0.00000143, proc(train=23.454sec, eval=11.883sec)
[2022-11-04 20:12:12,865 {dist_trainer.py:770}] <INFO> [  87/ 200] connecting edge count: 2
[2022-11-04 20:12:25,754 {dist_trainer.py:821}] <INFO> [  87/ 200] loss: (train=1.277, val=1.188, test=1.247, l2=8969.371), acc: (train=0.608, val=0.584, test=0.567), diff=0.00000074, proc(train=23.126sec, eval=11.637sec)
[2022-11-04 20:12:49,274 {dist_trainer.py:770}] <INFO> [  88/ 200] connecting edge count: 2
[2022-11-04 20:13:03,213 {dist_trainer.py:821}] <INFO> [  88/ 200] loss: (train=1.245, val=1.130, test=1.182, l2=8964.367), acc: (train=0.604, val=0.599, test=0.585), diff=0.00000094, proc(train=23.520sec, eval=12.010sec)
[2022-11-04 20:13:26,423 {dist_trainer.py:770}] <INFO> [  89/ 200] connecting edge count: 2
[2022-11-04 20:13:39,989 {dist_trainer.py:821}] <INFO> [  89/ 200] loss: (train=1.233, val=1.221, test=1.266, l2=8926.541), acc: (train=0.582, val=0.575, test=0.564), diff=0.00000125, proc(train=23.210sec, eval=11.711sec)
[2022-11-04 20:14:04,404 {dist_trainer.py:770}] <INFO> [  90/ 200] connecting edge count: 2
[2022-11-04 20:14:18,451 {dist_trainer.py:821}] <INFO> [  90/ 200] loss: (train=1.244, val=1.177, test=1.237, l2=8913.725), acc: (train=0.595, val=0.588, test=0.570), diff=0.00000074, proc(train=24.415sec, eval=11.765sec)
[2022-11-04 20:14:41,922 {dist_trainer.py:770}] <INFO> [  91/ 200] connecting edge count: 2
[2022-11-04 20:14:54,916 {dist_trainer.py:821}] <INFO> [  91/ 200] loss: (train=1.218, val=1.134, test=1.194, l2=8886.320), acc: (train=0.586, val=0.594, test=0.575), diff=0.00000106, proc(train=23.471sec, eval=11.989sec)
[2022-11-04 20:15:18,187 {dist_trainer.py:770}] <INFO> [  92/ 200] connecting edge count: 2
[2022-11-04 20:15:31,480 {dist_trainer.py:821}] <INFO> [  92/ 200] loss: (train=1.235, val=1.198, test=1.266, l2=8862.721), acc: (train=0.594, val=0.579, test=0.559), diff=0.00000089, proc(train=23.270sec, eval=11.725sec)
[2022-11-04 20:15:55,114 {dist_trainer.py:770}] <INFO> [  93/ 200] connecting edge count: 2
[2022-11-04 20:16:08,875 {dist_trainer.py:821}] <INFO> [  93/ 200] loss: (train=1.246, val=1.139, test=1.205, l2=8842.280), acc: (train=0.608, val=0.596, test=0.582), diff=0.00000128, proc(train=23.634sec, eval=12.099sec)
[2022-11-04 20:16:32,463 {dist_trainer.py:770}] <INFO> [  94/ 200] connecting edge count: 2
[2022-11-04 20:16:45,430 {dist_trainer.py:821}] <INFO> [  94/ 200] loss: (train=1.198, val=1.258, test=1.310, l2=8809.610), acc: (train=0.559, val=0.561, test=0.551), diff=0.00000079, proc(train=23.588sec, eval=11.660sec)
[2022-11-04 20:17:08,374 {dist_trainer.py:770}] <INFO> [  95/ 200] connecting edge count: 2
[2022-11-04 20:17:21,546 {dist_trainer.py:821}] <INFO> [  95/ 200] loss: (train=1.247, val=1.161, test=1.211, l2=8804.126), acc: (train=0.615, val=0.600, test=0.586), diff=0.00000081, proc(train=22.943sec, eval=12.080sec)
[2022-11-04 20:17:46,597 {dist_trainer.py:770}] <INFO> [  96/ 200] connecting edge count: 2
[2022-11-04 20:17:59,532 {dist_trainer.py:821}] <INFO> [  96/ 200] loss: (train=1.222, val=1.190, test=1.248, l2=8771.455), acc: (train=0.595, val=0.588, test=0.573), diff=0.00000091, proc(train=25.050sec, eval=11.776sec)
[2022-11-04 20:18:23,134 {dist_trainer.py:770}] <INFO> [  97/ 200] connecting edge count: 2
[2022-11-04 20:18:36,637 {dist_trainer.py:821}] <INFO> [  97/ 200] loss: (train=1.232, val=1.134, test=1.185, l2=8759.862), acc: (train=0.639, val=0.600, test=0.585), diff=0.00000094, proc(train=23.602sec, eval=11.748sec)
[2022-11-04 20:19:00,438 {dist_trainer.py:770}] <INFO> [  98/ 200] connecting edge count: 2
[2022-11-04 20:19:13,900 {dist_trainer.py:821}] <INFO> [  98/ 200] loss: (train=1.223, val=1.254, test=1.317, l2=8739.894), acc: (train=0.558, val=0.568, test=0.553), diff=0.00000101, proc(train=23.801sec, eval=11.863sec)
[2022-11-04 20:19:36,528 {dist_trainer.py:770}] <INFO> [  99/ 200] connecting edge count: 2
[2022-11-04 20:19:49,814 {dist_trainer.py:821}] <INFO> [  99/ 200] loss: (train=1.180, val=1.100, test=1.164, l2=8720.863), acc: (train=0.640, val=0.612, test=0.591), diff=0.00000102, proc(train=22.628sec, eval=11.636sec)
[2022-11-04 20:20:15,560 {dist_trainer.py:770}] <INFO> [ 100/ 200] connecting edge count: 2
[2022-11-04 20:20:28,567 {dist_trainer.py:821}] <INFO> [ 100/ 200] loss: (train=1.203, val=1.226, test=1.298, l2=8707.312), acc: (train=0.601, val=0.566, test=0.544), diff=0.00000090, proc(train=25.745sec, eval=11.880sec)
[2022-11-04 20:20:51,138 {dist_trainer.py:770}] <INFO> [ 101/ 200] connecting edge count: 2
[2022-11-04 20:21:04,027 {dist_trainer.py:821}] <INFO> [ 101/ 200] loss: (train=1.187, val=1.060, test=1.128, l2=8684.795), acc: (train=0.648, val=0.627, test=0.605), diff=0.00000122, proc(train=22.571sec, eval=11.649sec)
[2022-11-04 20:21:27,309 {dist_trainer.py:770}] <INFO> [ 102/ 200] connecting edge count: 2
[2022-11-04 20:21:40,669 {dist_trainer.py:821}] <INFO> [ 102/ 200] loss: (train=1.186, val=1.131, test=1.195, l2=8671.019), acc: (train=0.653, val=0.606, test=0.588), diff=0.00000075, proc(train=23.281sec, eval=11.784sec)
[2022-11-04 20:22:03,968 {dist_trainer.py:770}] <INFO> [ 103/ 200] connecting edge count: 2
[2022-11-04 20:22:17,482 {dist_trainer.py:821}] <INFO> [ 103/ 200] loss: (train=1.167, val=1.091, test=1.169, l2=8640.873), acc: (train=0.648, val=0.615, test=0.591), diff=0.00000109, proc(train=23.299sec, eval=11.822sec)
[2022-11-04 20:22:40,030 {dist_trainer.py:770}] <INFO> [ 104/ 200] connecting edge count: 2
[2022-11-04 20:22:53,748 {dist_trainer.py:821}] <INFO> [ 104/ 200] loss: (train=1.207, val=1.173, test=1.227, l2=8625.174), acc: (train=0.617, val=0.591, test=0.570), diff=0.00000113, proc(train=22.547sec, eval=11.683sec)
[2022-11-04 20:23:16,816 {dist_trainer.py:770}] <INFO> [ 105/ 200] connecting edge count: 2
[2022-11-04 20:23:30,369 {dist_trainer.py:821}] <INFO> [ 105/ 200] loss: (train=1.264, val=1.171, test=1.234, l2=8606.662), acc: (train=0.559, val=0.586, test=0.569), diff=0.00000096, proc(train=23.067sec, eval=11.976sec)
[2022-11-04 20:23:54,936 {dist_trainer.py:770}] <INFO> [ 106/ 200] connecting edge count: 2
[2022-11-04 20:24:08,149 {dist_trainer.py:821}] <INFO> [ 106/ 200] loss: (train=1.171, val=1.153, test=1.210, l2=8575.986), acc: (train=0.648, val=0.597, test=0.582), diff=0.00000193, proc(train=24.566sec, eval=11.684sec)
[2022-11-04 20:24:32,093 {dist_trainer.py:770}] <INFO> [ 107/ 200] connecting edge count: 2
[2022-11-04 20:24:45,314 {dist_trainer.py:821}] <INFO> [ 107/ 200] loss: (train=1.222, val=1.268, test=1.341, l2=8569.898), acc: (train=0.540, val=0.565, test=0.548), diff=0.00000115, proc(train=23.944sec, eval=12.011sec)
[2022-11-04 20:25:08,213 {dist_trainer.py:770}] <INFO> [ 108/ 200] connecting edge count: 2
[2022-11-04 20:25:21,100 {dist_trainer.py:821}] <INFO> [ 108/ 200] loss: (train=1.188, val=1.074, test=1.145, l2=8531.427), acc: (train=0.626, val=0.617, test=0.599), diff=0.00000091, proc(train=22.898sec, eval=11.759sec)
[2022-11-04 20:25:44,140 {dist_trainer.py:770}] <INFO> [ 109/ 200] connecting edge count: 2
[2022-11-04 20:25:57,593 {dist_trainer.py:821}] <INFO> [ 109/ 200] loss: (train=1.217, val=1.190, test=1.251, l2=8519.682), acc: (train=0.573, val=0.584, test=0.565), diff=0.00000080, proc(train=23.040sec, eval=11.818sec)
[2022-11-04 20:26:22,200 {dist_trainer.py:770}] <INFO> [ 110/ 200] connecting edge count: 2
[2022-11-04 20:26:35,774 {dist_trainer.py:821}] <INFO> [ 110/ 200] loss: (train=1.163, val=1.104, test=1.174, l2=8490.579), acc: (train=0.634, val=0.601, test=0.584), diff=0.00000106, proc(train=24.607sec, eval=12.014sec)
[2022-11-04 20:26:58,861 {dist_trainer.py:770}] <INFO> [ 111/ 200] connecting edge count: 2
[2022-11-04 20:27:12,368 {dist_trainer.py:821}] <INFO> [ 111/ 200] loss: (train=1.165, val=1.087, test=1.159, l2=8464.414), acc: (train=0.606, val=0.618, test=0.592), diff=0.00000124, proc(train=23.087sec, eval=11.663sec)
[2022-11-04 20:27:36,560 {dist_trainer.py:770}] <INFO> [ 112/ 200] connecting edge count: 2
[2022-11-04 20:27:49,711 {dist_trainer.py:821}] <INFO> [ 112/ 200] loss: (train=1.180, val=1.081, test=1.155, l2=8447.436), acc: (train=0.615, val=0.623, test=0.599), diff=0.00000127, proc(train=24.192sec, eval=11.950sec)
[2022-11-04 20:28:13,026 {dist_trainer.py:770}] <INFO> [ 113/ 200] connecting edge count: 2
[2022-11-04 20:28:26,169 {dist_trainer.py:821}] <INFO> [ 113/ 200] loss: (train=1.175, val=1.051, test=1.139, l2=8416.150), acc: (train=0.653, val=0.629, test=0.597), diff=0.00000133, proc(train=23.315sec, eval=11.749sec)
[2022-11-04 20:28:49,526 {dist_trainer.py:770}] <INFO> [ 114/ 200] connecting edge count: 2
[2022-11-04 20:29:02,547 {dist_trainer.py:821}] <INFO> [ 114/ 200] loss: (train=1.165, val=1.055, test=1.130, l2=8404.130), acc: (train=0.654, val=0.629, test=0.607), diff=0.00000094, proc(train=23.356sec, eval=11.963sec)
[2022-11-04 20:29:26,659 {dist_trainer.py:770}] <INFO> [ 115/ 200] connecting edge count: 2
[2022-11-04 20:29:39,680 {dist_trainer.py:821}] <INFO> [ 115/ 200] loss: (train=1.162, val=1.015, test=1.098, l2=8372.335), acc: (train=0.648, val=0.643, test=0.615), diff=0.00000110, proc(train=24.112sec, eval=11.772sec)
[2022-11-04 20:30:03,314 {dist_trainer.py:770}] <INFO> [ 116/ 200] connecting edge count: 2
[2022-11-04 20:30:16,753 {dist_trainer.py:821}] <INFO> [ 116/ 200] loss: (train=1.113, val=1.067, test=1.139, l2=8361.107), acc: (train=0.622, val=0.625, test=0.604), diff=0.00000130, proc(train=23.634sec, eval=11.710sec)
[2022-11-04 20:30:40,960 {dist_trainer.py:770}] <INFO> [ 117/ 200] connecting edge count: 2
[2022-11-04 20:30:55,210 {dist_trainer.py:821}] <INFO> [ 117/ 200] loss: (train=1.137, val=1.033, test=1.123, l2=8343.827), acc: (train=0.646, val=0.633, test=0.609), diff=0.00000123, proc(train=24.206sec, eval=11.927sec)
[2022-11-04 20:31:19,670 {dist_trainer.py:770}] <INFO> [ 118/ 200] connecting edge count: 2
[2022-11-04 20:31:32,879 {dist_trainer.py:821}] <INFO> [ 118/ 200] loss: (train=1.119, val=1.461, test=1.519, l2=8320.327), acc: (train=0.604, val=0.493, test=0.474), diff=0.00000140, proc(train=24.459sec, eval=11.624sec)
[2022-11-04 20:31:56,832 {dist_trainer.py:770}] <INFO> [ 119/ 200] connecting edge count: 2
[2022-11-04 20:32:10,762 {dist_trainer.py:821}] <INFO> [ 119/ 200] loss: (train=1.149, val=1.058, test=1.137, l2=8312.133), acc: (train=0.627, val=0.628, test=0.608), diff=0.00000099, proc(train=23.953sec, eval=11.989sec)
[2022-11-04 20:32:34,466 {dist_trainer.py:770}] <INFO> [ 120/ 200] connecting edge count: 2
[2022-11-04 20:32:47,360 {dist_trainer.py:821}] <INFO> [ 120/ 200] loss: (train=1.089, val=1.207, test=1.278, l2=8281.280), acc: (train=0.600, val=0.588, test=0.574), diff=0.00000108, proc(train=23.703sec, eval=11.665sec)
[2022-11-04 20:33:10,769 {dist_trainer.py:770}] <INFO> [ 121/ 200] connecting edge count: 2
[2022-11-04 20:33:23,873 {dist_trainer.py:821}] <INFO> [ 121/ 200] loss: (train=1.088, val=1.075, test=1.161, l2=8269.286), acc: (train=0.632, val=0.629, test=0.608), diff=0.00000077, proc(train=23.408sec, eval=12.029sec)
[2022-11-04 20:33:47,424 {dist_trainer.py:770}] <INFO> [ 122/ 200] connecting edge count: 2
[2022-11-04 20:34:00,595 {dist_trainer.py:821}] <INFO> [ 122/ 200] loss: (train=1.108, val=1.059, test=1.137, l2=8239.184), acc: (train=0.649, val=0.628, test=0.601), diff=0.00000107, proc(train=23.550sec, eval=11.831sec)
[2022-11-04 20:34:22,031 {dist_trainer.py:770}] <INFO> [ 123/ 200] connecting edge count: 2
[2022-11-04 20:34:35,160 {dist_trainer.py:821}] <INFO> [ 123/ 200] loss: (train=1.068, val=1.041, test=1.123, l2=8220.638), acc: (train=0.656, val=0.635, test=0.611), diff=0.00000118, proc(train=21.436sec, eval=11.670sec)
[2022-11-04 20:34:58,143 {dist_trainer.py:770}] <INFO> [ 124/ 200] connecting edge count: 2
[2022-11-04 20:35:11,611 {dist_trainer.py:821}] <INFO> [ 124/ 200] loss: (train=1.093, val=1.000, test=1.101, l2=8202.883), acc: (train=0.641, val=0.650, test=0.625), diff=0.00000094, proc(train=22.983sec, eval=11.907sec)
[2022-11-04 20:35:36,094 {dist_trainer.py:770}] <INFO> [ 125/ 200] connecting edge count: 2
[2022-11-04 20:35:49,050 {dist_trainer.py:821}] <INFO> [ 125/ 200] loss: (train=1.079, val=1.120, test=1.189, l2=8170.025), acc: (train=0.654, val=0.597, test=0.572), diff=0.00000207, proc(train=24.483sec, eval=11.732sec)
[2022-11-04 20:36:12,874 {dist_trainer.py:770}] <INFO> [ 126/ 200] connecting edge count: 2
[2022-11-04 20:36:26,674 {dist_trainer.py:821}] <INFO> [ 126/ 200] loss: (train=1.099, val=1.112, test=1.192, l2=8164.844), acc: (train=0.644, val=0.613, test=0.593), diff=0.00000096, proc(train=23.824sec, eval=11.927sec)
[2022-11-04 20:36:50,906 {dist_trainer.py:770}] <INFO> [ 127/ 200] connecting edge count: 2
[2022-11-04 20:37:04,065 {dist_trainer.py:821}] <INFO> [ 127/ 200] loss: (train=1.051, val=1.002, test=1.095, l2=8127.036), acc: (train=0.654, val=0.651, test=0.623), diff=0.00000094, proc(train=24.231sec, eval=11.687sec)
[2022-11-04 20:37:26,576 {dist_trainer.py:770}] <INFO> [ 128/ 200] connecting edge count: 2
[2022-11-04 20:37:39,395 {dist_trainer.py:821}] <INFO> [ 128/ 200] loss: (train=1.064, val=1.047, test=1.141, l2=8112.098), acc: (train=0.640, val=0.643, test=0.615), diff=0.00000118, proc(train=22.510sec, eval=11.616sec)
[2022-11-04 20:38:03,071 {dist_trainer.py:770}] <INFO> [ 129/ 200] connecting edge count: 2
[2022-11-04 20:38:16,236 {dist_trainer.py:821}] <INFO> [ 129/ 200] loss: (train=1.059, val=1.027, test=1.118, l2=8090.879), acc: (train=0.642, val=0.639, test=0.618), diff=0.00000094, proc(train=23.675sec, eval=11.909sec)
[2022-11-04 20:38:39,627 {dist_trainer.py:770}] <INFO> [ 130/ 200] connecting edge count: 2
[2022-11-04 20:38:52,825 {dist_trainer.py:821}] <INFO> [ 130/ 200] loss: (train=1.088, val=0.990, test=1.084, l2=8065.812), acc: (train=0.638, val=0.650, test=0.622), diff=0.00000144, proc(train=23.390sec, eval=11.694sec)
[2022-11-04 20:39:16,683 {dist_trainer.py:770}] <INFO> [ 131/ 200] connecting edge count: 2
[2022-11-04 20:39:30,120 {dist_trainer.py:821}] <INFO> [ 131/ 200] loss: (train=1.107, val=0.957, test=1.065, l2=8061.891), acc: (train=0.679, val=0.668, test=0.636), diff=0.00000125, proc(train=23.858sec, eval=11.786sec)
[2022-11-04 20:39:54,046 {dist_trainer.py:770}] <INFO> [ 132/ 200] connecting edge count: 2
[2022-11-04 20:40:06,899 {dist_trainer.py:821}] <INFO> [ 132/ 200] loss: (train=1.040, val=1.058, test=1.161, l2=8025.607), acc: (train=0.638, val=0.636, test=0.608), diff=0.00000134, proc(train=23.926sec, eval=11.612sec)
[2022-11-04 20:40:30,180 {dist_trainer.py:770}] <INFO> [ 133/ 200] connecting edge count: 2
[2022-11-04 20:40:43,923 {dist_trainer.py:821}] <INFO> [ 133/ 200] loss: (train=1.053, val=1.018, test=1.121, l2=8012.843), acc: (train=0.636, val=0.648, test=0.623), diff=0.00000086, proc(train=23.280sec, eval=11.785sec)
[2022-11-04 20:41:08,371 {dist_trainer.py:770}] <INFO> [ 134/ 200] connecting edge count: 2
[2022-11-04 20:41:21,450 {dist_trainer.py:821}] <INFO> [ 134/ 200] loss: (train=1.027, val=0.953, test=1.064, l2=7981.929), acc: (train=0.701, val=0.664, test=0.630), diff=0.00000116, proc(train=24.448sec, eval=11.870sec)
[2022-11-04 20:41:43,546 {dist_trainer.py:770}] <INFO> [ 135/ 200] connecting edge count: 2
[2022-11-04 20:41:57,423 {dist_trainer.py:821}] <INFO> [ 135/ 200] loss: (train=1.081, val=0.966, test=1.069, l2=7971.269), acc: (train=0.678, val=0.664, test=0.635), diff=0.00000132, proc(train=22.096sec, eval=11.613sec)
[2022-11-04 20:42:21,368 {dist_trainer.py:770}] <INFO> [ 136/ 200] connecting edge count: 2
[2022-11-04 20:42:34,946 {dist_trainer.py:821}] <INFO> [ 136/ 200] loss: (train=1.076, val=0.961, test=1.066, l2=7955.526), acc: (train=0.649, val=0.664, test=0.630), diff=0.00000106, proc(train=23.945sec, eval=11.753sec)
[2022-11-04 20:42:59,434 {dist_trainer.py:770}] <INFO> [ 137/ 200] connecting edge count: 2
[2022-11-04 20:43:12,294 {dist_trainer.py:821}] <INFO> [ 137/ 200] loss: (train=1.035, val=0.969, test=1.063, l2=7924.287), acc: (train=0.684, val=0.658, test=0.629), diff=0.00000141, proc(train=24.488sec, eval=11.627sec)
[2022-11-04 20:43:36,365 {dist_trainer.py:770}] <INFO> [ 138/ 200] connecting edge count: 2
[2022-11-04 20:43:50,051 {dist_trainer.py:821}] <INFO> [ 138/ 200] loss: (train=1.033, val=0.971, test=1.073, l2=7918.642), acc: (train=0.673, val=0.662, test=0.629), diff=0.00000106, proc(train=24.071sec, eval=11.831sec)
[2022-11-04 20:44:12,804 {dist_trainer.py:770}] <INFO> [ 139/ 200] connecting edge count: 2
[2022-11-04 20:44:26,433 {dist_trainer.py:821}] <INFO> [ 139/ 200] loss: (train=1.009, val=0.993, test=1.103, l2=7881.824), acc: (train=0.710, val=0.655, test=0.620), diff=0.00000091, proc(train=22.752sec, eval=11.674sec)
[2022-11-04 20:44:48,466 {dist_trainer.py:770}] <INFO> [ 140/ 200] connecting edge count: 2
[2022-11-04 20:45:01,337 {dist_trainer.py:821}] <INFO> [ 140/ 200] loss: (train=1.007, val=1.002, test=1.100, l2=7867.465), acc: (train=0.671, val=0.657, test=0.629), diff=0.00000125, proc(train=22.033sec, eval=11.676sec)
[2022-11-04 20:45:25,253 {dist_trainer.py:770}] <INFO> [ 141/ 200] connecting edge count: 2
[2022-11-04 20:45:38,992 {dist_trainer.py:821}] <INFO> [ 141/ 200] loss: (train=1.003, val=0.904, test=1.026, l2=7846.948), acc: (train=0.672, val=0.686, test=0.647), diff=0.00000115, proc(train=23.916sec, eval=11.870sec)
[2022-11-04 20:46:02,367 {dist_trainer.py:770}] <INFO> [ 142/ 200] connecting edge count: 2
[2022-11-04 20:46:15,430 {dist_trainer.py:821}] <INFO> [ 142/ 200] loss: (train=1.036, val=1.055, test=1.156, l2=7821.869), acc: (train=0.650, val=0.635, test=0.609), diff=0.00000177, proc(train=23.374sec, eval=11.612sec)
[2022-11-04 20:46:39,203 {dist_trainer.py:770}] <INFO> [ 143/ 200] connecting edge count: 2
[2022-11-04 20:46:52,040 {dist_trainer.py:821}] <INFO> [ 143/ 200] loss: (train=1.071, val=1.017, test=1.126, l2=7821.976), acc: (train=0.662, val=0.652, test=0.617), diff=0.00000148, proc(train=23.772sec, eval=11.831sec)
[2022-11-04 20:47:17,451 {dist_trainer.py:770}] <INFO> [ 144/ 200] connecting edge count: 2
[2022-11-04 20:47:31,169 {dist_trainer.py:821}] <INFO> [ 144/ 200] loss: (train=1.003, val=0.965, test=1.097, l2=7783.982), acc: (train=0.683, val=0.666, test=0.630), diff=0.00000097, proc(train=25.410sec, eval=11.699sec)
[2022-11-04 20:47:54,119 {dist_trainer.py:770}] <INFO> [ 145/ 200] connecting edge count: 2
[2022-11-04 20:48:07,247 {dist_trainer.py:821}] <INFO> [ 145/ 200] loss: (train=1.027, val=1.040, test=1.139, l2=7772.182), acc: (train=0.623, val=0.636, test=0.610), diff=0.00000096, proc(train=22.949sec, eval=11.771sec)
[2022-11-04 20:48:32,077 {dist_trainer.py:770}] <INFO> [ 146/ 200] connecting edge count: 2
[2022-11-04 20:48:45,147 {dist_trainer.py:821}] <INFO> [ 146/ 200] loss: (train=0.988, val=0.904, test=1.033, l2=7742.838), acc: (train=0.684, val=0.686, test=0.647), diff=0.00000118, proc(train=24.830sec, eval=11.811sec)
[2022-11-04 20:49:07,124 {dist_trainer.py:770}] <INFO> [ 147/ 200] connecting edge count: 2
[2022-11-04 20:49:21,094 {dist_trainer.py:821}] <INFO> [ 147/ 200] loss: (train=1.003, val=0.949, test=1.065, l2=7731.274), acc: (train=0.699, val=0.670, test=0.633), diff=0.00000140, proc(train=21.976sec, eval=11.782sec)
[2022-11-04 20:49:44,478 {dist_trainer.py:770}] <INFO> [ 148/ 200] connecting edge count: 2
[2022-11-04 20:49:57,420 {dist_trainer.py:821}] <INFO> [ 148/ 200] loss: (train=1.013, val=0.940, test=1.069, l2=7716.100), acc: (train=0.641, val=0.674, test=0.641), diff=0.00000096, proc(train=23.383sec, eval=11.915sec)
[2022-11-04 20:50:20,508 {dist_trainer.py:770}] <INFO> [ 149/ 200] connecting edge count: 2
[2022-11-04 20:50:33,779 {dist_trainer.py:821}] <INFO> [ 149/ 200] loss: (train=0.998, val=0.929, test=1.040, l2=7685.348), acc: (train=0.706, val=0.675, test=0.645), diff=0.00000198, proc(train=23.088sec, eval=11.680sec)
[2022-11-04 20:50:57,606 {dist_trainer.py:770}] <INFO> [ 150/ 200] connecting edge count: 2
[2022-11-04 20:51:11,159 {dist_trainer.py:821}] <INFO> [ 150/ 200] loss: (train=1.017, val=0.915, test=1.023, l2=7676.169), acc: (train=0.718, val=0.681, test=0.646), diff=0.00000107, proc(train=23.826sec, eval=12.028sec)
[2022-11-04 20:51:36,778 {dist_trainer.py:770}] <INFO> [ 151/ 200] connecting edge count: 2
[2022-11-04 20:51:50,436 {dist_trainer.py:821}] <INFO> [ 151/ 200] loss: (train=1.003, val=0.866, test=1.001, l2=7643.211), acc: (train=0.692, val=0.699, test=0.659), diff=0.00000112, proc(train=25.619sec, eval=11.784sec)
[2022-11-04 20:52:13,816 {dist_trainer.py:770}] <INFO> [ 152/ 200] connecting edge count: 2
[2022-11-04 20:52:27,166 {dist_trainer.py:821}] <INFO> [ 152/ 200] loss: (train=1.010, val=1.040, test=1.137, l2=7629.654), acc: (train=0.672, val=0.637, test=0.605), diff=0.00000132, proc(train=23.380sec, eval=11.738sec)
[2022-11-04 20:52:51,272 {dist_trainer.py:770}] <INFO> [ 153/ 200] connecting edge count: 2
[2022-11-04 20:53:04,197 {dist_trainer.py:821}] <INFO> [ 153/ 200] loss: (train=0.973, val=0.849, test=0.982, l2=7606.835), acc: (train=0.717, val=0.707, test=0.668), diff=0.00000105, proc(train=24.106sec, eval=11.913sec)
[2022-11-04 20:53:27,680 {dist_trainer.py:770}] <INFO> [ 154/ 200] connecting edge count: 2
[2022-11-04 20:53:40,929 {dist_trainer.py:821}] <INFO> [ 154/ 200] loss: (train=0.961, val=0.950, test=1.070, l2=7584.147), acc: (train=0.692, val=0.668, test=0.634), diff=0.00000148, proc(train=23.482sec, eval=11.742sec)
[2022-11-04 20:54:04,830 {dist_trainer.py:770}] <INFO> [ 155/ 200] connecting edge count: 2
[2022-11-04 20:54:18,783 {dist_trainer.py:821}] <INFO> [ 155/ 200] loss: (train=0.971, val=0.935, test=1.063, l2=7570.977), acc: (train=0.681, val=0.680, test=0.641), diff=0.00000102, proc(train=23.900sec, eval=12.088sec)
[2022-11-04 20:54:43,250 {dist_trainer.py:770}] <INFO> [ 156/ 200] connecting edge count: 2
[2022-11-04 20:54:56,275 {dist_trainer.py:821}] <INFO> [ 156/ 200] loss: (train=0.939, val=0.897, test=1.010, l2=7541.752), acc: (train=0.706, val=0.688, test=0.651), diff=0.00000160, proc(train=24.467sec, eval=11.787sec)
[2022-11-04 20:55:19,119 {dist_trainer.py:770}] <INFO> [ 157/ 200] connecting edge count: 2
[2022-11-04 20:55:32,559 {dist_trainer.py:821}] <INFO> [ 157/ 200] loss: (train=0.964, val=1.016, test=1.137, l2=7532.305), acc: (train=0.636, val=0.642, test=0.610), diff=0.00000086, proc(train=22.844sec, eval=11.921sec)
[2022-11-04 20:55:55,219 {dist_trainer.py:770}] <INFO> [ 158/ 200] connecting edge count: 2
[2022-11-04 20:56:08,348 {dist_trainer.py:821}] <INFO> [ 158/ 200] loss: (train=0.951, val=0.923, test=1.053, l2=7502.212), acc: (train=0.682, val=0.675, test=0.636), diff=0.00000130, proc(train=22.660sec, eval=11.946sec)
[2022-11-04 20:56:30,538 {dist_trainer.py:770}] <INFO> [ 159/ 200] connecting edge count: 2
[2022-11-04 20:56:44,344 {dist_trainer.py:821}] <INFO> [ 159/ 200] loss: (train=0.978, val=0.925, test=1.051, l2=7493.623), acc: (train=0.661, val=0.674, test=0.632), diff=0.00000160, proc(train=22.190sec, eval=11.710sec)
[2022-11-04 20:57:07,469 {dist_trainer.py:770}] <INFO> [ 160/ 200] connecting edge count: 2
[2022-11-04 20:57:21,533 {dist_trainer.py:821}] <INFO> [ 160/ 200] loss: (train=0.992, val=0.929, test=1.054, l2=7478.896), acc: (train=0.665, val=0.679, test=0.643), diff=0.00000112, proc(train=23.125sec, eval=11.970sec)
[2022-11-04 20:57:45,025 {dist_trainer.py:770}] <INFO> [ 161/ 200] connecting edge count: 2
[2022-11-04 20:57:58,347 {dist_trainer.py:821}] <INFO> [ 161/ 200] loss: (train=0.967, val=0.938, test=1.057, l2=7453.214), acc: (train=0.725, val=0.674, test=0.637), diff=0.00000145, proc(train=23.492sec, eval=11.765sec)
[2022-11-04 20:58:22,409 {dist_trainer.py:770}] <INFO> [ 162/ 200] connecting edge count: 2
[2022-11-04 20:58:35,748 {dist_trainer.py:821}] <INFO> [ 162/ 200] loss: (train=0.994, val=0.888, test=1.041, l2=7448.938), acc: (train=0.715, val=0.696, test=0.651), diff=0.00000149, proc(train=24.061sec, eval=12.108sec)
[2022-11-04 20:58:58,159 {dist_trainer.py:770}] <INFO> [ 163/ 200] connecting edge count: 2
[2022-11-04 20:59:11,698 {dist_trainer.py:821}] <INFO> [ 163/ 200] loss: (train=0.944, val=0.870, test=1.022, l2=7415.962), acc: (train=0.701, val=0.704, test=0.663), diff=0.00000094, proc(train=22.411sec, eval=11.690sec)
[2022-11-04 20:59:34,401 {dist_trainer.py:770}] <INFO> [ 164/ 200] connecting edge count: 2
[2022-11-04 20:59:47,163 {dist_trainer.py:821}] <INFO> [ 164/ 200] loss: (train=0.936, val=0.991, test=1.131, l2=7403.615), acc: (train=0.681, val=0.669, test=0.628), diff=0.00000141, proc(train=22.703sec, eval=11.654sec)
[2022-11-04 21:00:13,277 {dist_trainer.py:770}] <INFO> [ 165/ 200] connecting edge count: 2
[2022-11-04 21:00:27,536 {dist_trainer.py:821}] <INFO> [ 165/ 200] loss: (train=0.953, val=0.875, test=1.012, l2=7380.252), acc: (train=0.695, val=0.698, test=0.655), diff=0.00000101, proc(train=26.114sec, eval=11.934sec)
[2022-11-04 21:00:49,732 {dist_trainer.py:770}] <INFO> [ 166/ 200] connecting edge count: 2
[2022-11-04 21:01:02,734 {dist_trainer.py:821}] <INFO> [ 166/ 200] loss: (train=0.908, val=0.891, test=1.040, l2=7359.266), acc: (train=0.702, val=0.694, test=0.651), diff=0.00000134, proc(train=22.196sec, eval=11.715sec)
[2022-11-04 21:01:26,592 {dist_trainer.py:770}] <INFO> [ 167/ 200] connecting edge count: 2
[2022-11-04 21:01:39,803 {dist_trainer.py:821}] <INFO> [ 167/ 200] loss: (train=0.927, val=0.821, test=0.969, l2=7351.029), acc: (train=0.725, val=0.718, test=0.673), diff=0.00000103, proc(train=23.858sec, eval=12.067sec)
[2022-11-04 21:02:03,331 {dist_trainer.py:770}] <INFO> [ 168/ 200] connecting edge count: 2
[2022-11-04 21:02:17,134 {dist_trainer.py:821}] <INFO> [ 168/ 200] loss: (train=0.933, val=0.995, test=1.130, l2=7321.858), acc: (train=0.654, val=0.663, test=0.625), diff=0.00000134, proc(train=23.528sec, eval=11.764sec)
[2022-11-04 21:02:39,694 {dist_trainer.py:770}] <INFO> [ 169/ 200] connecting edge count: 2
[2022-11-04 21:02:53,427 {dist_trainer.py:821}] <INFO> [ 169/ 200] loss: (train=0.995, val=1.009, test=1.135, l2=7313.709), acc: (train=0.709, val=0.653, test=0.619), diff=0.00000103, proc(train=22.560sec, eval=11.912sec)
[2022-11-04 21:03:18,410 {dist_trainer.py:770}] <INFO> [ 170/ 200] connecting edge count: 2
[2022-11-04 21:03:31,482 {dist_trainer.py:821}] <INFO> [ 170/ 200] loss: (train=0.916, val=0.910, test=1.056, l2=7284.370), acc: (train=0.699, val=0.683, test=0.644), diff=0.00000133, proc(train=24.982sec, eval=11.827sec)
[2022-11-04 21:03:54,632 {dist_trainer.py:770}] <INFO> [ 171/ 200] connecting edge count: 2
[2022-11-04 21:04:07,907 {dist_trainer.py:821}] <INFO> [ 171/ 200] loss: (train=0.946, val=0.826, test=0.966, l2=7275.881), acc: (train=0.746, val=0.715, test=0.669), diff=0.00000142, proc(train=23.149sec, eval=11.733sec)
[2022-11-04 21:04:31,741 {dist_trainer.py:770}] <INFO> [ 172/ 200] connecting edge count: 2
[2022-11-04 21:04:45,508 {dist_trainer.py:821}] <INFO> [ 172/ 200] loss: (train=0.946, val=0.858, test=1.011, l2=7263.625), acc: (train=0.705, val=0.712, test=0.668), diff=0.00000133, proc(train=23.834sec, eval=11.912sec)
[2022-11-04 21:05:08,078 {dist_trainer.py:770}] <INFO> [ 173/ 200] connecting edge count: 2
[2022-11-04 21:05:21,260 {dist_trainer.py:821}] <INFO> [ 173/ 200] loss: (train=0.892, val=0.992, test=1.121, l2=7236.409), acc: (train=0.699, val=0.660, test=0.622), diff=0.00000164, proc(train=22.570sec, eval=11.682sec)
[2022-11-04 21:05:44,987 {dist_trainer.py:770}] <INFO> [ 174/ 200] connecting edge count: 2
[2022-11-04 21:05:58,689 {dist_trainer.py:821}] <INFO> [ 174/ 200] loss: (train=0.931, val=0.814, test=0.973, l2=7234.776), acc: (train=0.721, val=0.720, test=0.674), diff=0.00000138, proc(train=23.726sec, eval=11.870sec)
[2022-11-04 21:06:21,568 {dist_trainer.py:770}] <INFO> [ 175/ 200] connecting edge count: 2
[2022-11-04 21:06:34,648 {dist_trainer.py:821}] <INFO> [ 175/ 200] loss: (train=0.931, val=0.821, test=0.960, l2=7202.644), acc: (train=0.720, val=0.715, test=0.672), diff=0.00000100, proc(train=22.879sec, eval=11.739sec)
[2022-11-04 21:06:57,452 {dist_trainer.py:770}] <INFO> [ 176/ 200] connecting edge count: 2
[2022-11-04 21:07:10,783 {dist_trainer.py:821}] <INFO> [ 176/ 200] loss: (train=0.960, val=0.887, test=1.035, l2=7190.895), acc: (train=0.681, val=0.693, test=0.648), diff=0.00000115, proc(train=22.803sec, eval=11.861sec)
[2022-11-04 21:07:35,467 {dist_trainer.py:770}] <INFO> [ 177/ 200] connecting edge count: 2
[2022-11-04 21:07:48,948 {dist_trainer.py:821}] <INFO> [ 177/ 200] loss: (train=0.894, val=0.865, test=1.000, l2=7165.090), acc: (train=0.696, val=0.698, test=0.661), diff=0.00000114, proc(train=24.683sec, eval=11.891sec)
[2022-11-04 21:08:10,853 {dist_trainer.py:770}] <INFO> [ 178/ 200] connecting edge count: 2
[2022-11-04 21:08:23,971 {dist_trainer.py:821}] <INFO> [ 178/ 200] loss: (train=0.911, val=0.852, test=0.992, l2=7145.167), acc: (train=0.733, val=0.707, test=0.663), diff=0.00000145, proc(train=21.904sec, eval=11.674sec)
[2022-11-04 21:08:47,489 {dist_trainer.py:770}] <INFO> [ 179/ 200] connecting edge count: 2
[2022-11-04 21:09:00,601 {dist_trainer.py:821}] <INFO> [ 179/ 200] loss: (train=0.916, val=0.837, test=0.989, l2=7132.869), acc: (train=0.712, val=0.706, test=0.661), diff=0.00000105, proc(train=23.517sec, eval=11.905sec)
[2022-11-04 21:09:24,195 {dist_trainer.py:770}] <INFO> [ 180/ 200] connecting edge count: 2
[2022-11-04 21:09:37,136 {dist_trainer.py:821}] <INFO> [ 180/ 200] loss: (train=0.869, val=0.804, test=0.963, l2=7106.046), acc: (train=0.727, val=0.723, test=0.671), diff=0.00000131, proc(train=23.593sec, eval=11.689sec)
[2022-11-04 21:10:00,373 {dist_trainer.py:770}] <INFO> [ 181/ 200] connecting edge count: 2
[2022-11-04 21:10:14,758 {dist_trainer.py:821}] <INFO> [ 181/ 200] loss: (train=0.926, val=0.840, test=0.994, l2=7096.999), acc: (train=0.703, val=0.709, test=0.664), diff=0.00000109, proc(train=23.236sec, eval=11.912sec)
[2022-11-04 21:10:39,362 {dist_trainer.py:770}] <INFO> [ 182/ 200] connecting edge count: 2
[2022-11-04 21:10:52,443 {dist_trainer.py:821}] <INFO> [ 182/ 200] loss: (train=0.883, val=0.796, test=0.964, l2=7069.186), acc: (train=0.733, val=0.727, test=0.671), diff=0.00000130, proc(train=24.603sec, eval=11.769sec)
[2022-11-04 21:11:14,127 {dist_trainer.py:770}] <INFO> [ 183/ 200] connecting edge count: 2
[2022-11-04 21:11:27,209 {dist_trainer.py:821}] <INFO> [ 183/ 200] loss: (train=0.917, val=0.836, test=0.984, l2=7060.109), acc: (train=0.711, val=0.710, test=0.667), diff=0.00000158, proc(train=21.684sec, eval=11.746sec)
[2022-11-04 21:11:50,002 {dist_trainer.py:770}] <INFO> [ 184/ 200] connecting edge count: 2
[2022-11-04 21:12:03,258 {dist_trainer.py:821}] <INFO> [ 184/ 200] loss: (train=0.882, val=0.877, test=1.023, l2=7045.282), acc: (train=0.694, val=0.702, test=0.657), diff=0.00000139, proc(train=22.793sec, eval=11.869sec)
[2022-11-04 21:12:26,344 {dist_trainer.py:770}] <INFO> [ 185/ 200] connecting edge count: 2
[2022-11-04 21:12:39,548 {dist_trainer.py:821}] <INFO> [ 185/ 200] loss: (train=0.906, val=0.881, test=1.031, l2=7019.093), acc: (train=0.749, val=0.694, test=0.649), diff=0.00000259, proc(train=23.085sec, eval=11.717sec)
[2022-11-04 21:13:03,998 {dist_trainer.py:770}] <INFO> [ 186/ 200] connecting edge count: 2
[2022-11-04 21:13:18,606 {dist_trainer.py:821}] <INFO> [ 186/ 200] loss: (train=0.905, val=0.836, test=0.993, l2=7012.252), acc: (train=0.718, val=0.714, test=0.669), diff=0.00000140, proc(train=24.449sec, eval=11.988sec)
[2022-11-04 21:13:42,274 {dist_trainer.py:770}] <INFO> [ 187/ 200] connecting edge count: 2
[2022-11-04 21:13:55,518 {dist_trainer.py:821}] <INFO> [ 187/ 200] loss: (train=0.856, val=0.811, test=0.970, l2=6979.178), acc: (train=0.762, val=0.718, test=0.664), diff=0.00000116, proc(train=23.667sec, eval=11.816sec)
[2022-11-04 21:14:18,808 {dist_trainer.py:770}] <INFO> [ 188/ 200] connecting edge count: 2
[2022-11-04 21:14:32,099 {dist_trainer.py:821}] <INFO> [ 188/ 200] loss: (train=0.876, val=0.860, test=1.006, l2=6969.195), acc: (train=0.717, val=0.706, test=0.663), diff=0.00000104, proc(train=23.290sec, eval=11.835sec)
[2022-11-04 21:14:56,618 {dist_trainer.py:770}] <INFO> [ 189/ 200] connecting edge count: 2
[2022-11-04 21:15:10,050 {dist_trainer.py:821}] <INFO> [ 189/ 200] loss: (train=0.874, val=0.868, test=1.030, l2=6943.568), acc: (train=0.712, val=0.699, test=0.654), diff=0.00000128, proc(train=24.519sec, eval=11.847sec)
[2022-11-04 21:15:32,857 {dist_trainer.py:770}] <INFO> [ 190/ 200] connecting edge count: 2
[2022-11-04 21:15:46,353 {dist_trainer.py:821}] <INFO> [ 190/ 200] loss: (train=0.889, val=0.792, test=0.953, l2=6923.895), acc: (train=0.729, val=0.728, test=0.680), diff=0.00000166, proc(train=22.807sec, eval=11.694sec)
[2022-11-04 21:16:09,639 {dist_trainer.py:770}] <INFO> [ 191/ 200] connecting edge count: 2
[2022-11-04 21:16:22,736 {dist_trainer.py:821}] <INFO> [ 191/ 200] loss: (train=0.888, val=0.822, test=0.988, l2=6912.019), acc: (train=0.727, val=0.717, test=0.664), diff=0.00000116, proc(train=23.286sec, eval=11.933sec)
[2022-11-04 21:16:46,870 {dist_trainer.py:770}] <INFO> [ 192/ 200] connecting edge count: 2
[2022-11-04 21:16:59,790 {dist_trainer.py:821}] <INFO> [ 192/ 200] loss: (train=0.850, val=0.887, test=1.021, l2=6885.864), acc: (train=0.699, val=0.693, test=0.649), diff=0.00000154, proc(train=24.133sec, eval=11.681sec)
[2022-11-04 21:17:23,046 {dist_trainer.py:770}] <INFO> [ 193/ 200] connecting edge count: 2
[2022-11-04 21:17:36,718 {dist_trainer.py:821}] <INFO> [ 193/ 200] loss: (train=0.860, val=0.824, test=0.987, l2=6877.160), acc: (train=0.726, val=0.715, test=0.666), diff=0.00000109, proc(train=23.255sec, eval=11.921sec)
[2022-11-04 21:18:00,869 {dist_trainer.py:770}] <INFO> [ 194/ 200] connecting edge count: 2
[2022-11-04 21:18:13,852 {dist_trainer.py:821}] <INFO> [ 194/ 200] loss: (train=0.827, val=0.748, test=0.922, l2=6848.787), acc: (train=0.748, val=0.743, test=0.690), diff=0.00000136, proc(train=24.151sec, eval=11.786sec)
[2022-11-04 21:18:35,339 {dist_trainer.py:770}] <INFO> [ 195/ 200] connecting edge count: 2
[2022-11-04 21:18:48,329 {dist_trainer.py:821}] <INFO> [ 195/ 200] loss: (train=0.893, val=0.905, test=1.053, l2=6842.190), acc: (train=0.709, val=0.685, test=0.642), diff=0.00000184, proc(train=21.487sec, eval=11.726sec)
[2022-11-04 21:19:13,320 {dist_trainer.py:770}] <INFO> [ 196/ 200] connecting edge count: 2
[2022-11-04 21:19:26,620 {dist_trainer.py:821}] <INFO> [ 196/ 200] loss: (train=0.851, val=0.737, test=0.926, l2=6826.584), acc: (train=0.761, val=0.746, test=0.693), diff=0.00000132, proc(train=24.991sec, eval=11.986sec)
[2022-11-04 21:19:49,412 {dist_trainer.py:770}] <INFO> [ 197/ 200] connecting edge count: 2
[2022-11-04 21:20:02,597 {dist_trainer.py:821}] <INFO> [ 197/ 200] loss: (train=0.847, val=0.840, test=1.014, l2=6808.387), acc: (train=0.709, val=0.711, test=0.665), diff=0.00000162, proc(train=22.792sec, eval=11.796sec)
[2022-11-04 21:20:26,946 {dist_trainer.py:770}] <INFO> [ 198/ 200] connecting edge count: 2
[2022-11-04 21:20:40,715 {dist_trainer.py:821}] <INFO> [ 198/ 200] loss: (train=0.856, val=0.760, test=0.954, l2=6804.071), acc: (train=0.759, val=0.742, test=0.683), diff=0.00000140, proc(train=24.349sec, eval=12.027sec)
[2022-11-04 21:21:05,550 {dist_trainer.py:770}] <INFO> [ 199/ 200] connecting edge count: 2
[2022-11-04 21:21:18,481 {dist_trainer.py:821}] <INFO> [ 199/ 200] loss: (train=0.871, val=0.957, test=1.127, l2=6773.962), acc: (train=0.657, val=0.671, test=0.624), diff=0.00000113, proc(train=24.835sec, eval=11.705sec)
[2022-11-04 21:21:42,033 {dist_trainer.py:770}] <INFO> [ 200/ 200] connecting edge count: 2
[2022-11-04 21:21:55,021 {dist_trainer.py:821}] <INFO> [ 200/ 200] loss: (train=0.870, val=0.815, test=0.982, l2=6764.915), acc: (train=0.714, val=0.718, test=0.662), diff=0.00000113, proc(train=23.552sec, eval=11.835sec)
[2022-11-04 21:22:08,658 {dist_trainer.py:899}] <INFO> [EVAL] loss: (train=0.842, val=0.815, test=0.982, l2=6764.910), acc: (train=0.707, val=0.718, test=0.662), proc=13.635sec
[2022-11-04 21:22:08,772 {dist_trainer.py:380}] <INFO> GC: check garbage []
[2022-11-04 21:22:09,077 {main.py:285}] <INFO> GC: check garbage []
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
