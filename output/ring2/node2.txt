[2022-11-02 16:28:57,786 {main.py:127}] <INFO> Namespace(datadir='./data', outdir='./output/ring2', epochs=200, batch_size=100, seed=569, data_init_seed=11, model_init_seed=13, l2_lambda=0.01, model_name='resnet50', dataset_name='cifar10', train_data_length=10000, group_channels=32, drop_rate=0.1, last_drop_rate=0.5, cuda=True, cuda_device_no=2, plot=False, scheduler='StepLR', step_size=410, gamma=0.9, sleep_factor=0.0, loglevel=<LogLevel.INFO: 20>, logfile=None, optimizer='PdmmISVR', nodename='node1', conf='./conf/node_list.json', host='./conf/hosts.json', lr=0.002, use_gcoef=False, piw=1.0, round_step=False, swap_timeout=10)
[2022-11-02 16:28:57,786 {main.py:193}] <INFO> {'nodes': {'node0': {'device': 'cuda', 'round': 10, 'edges': {'node2': 0, 'node1': 4}}, 'node1': {'device': 'cuda', 'round': 10, 'edges': {'node0': 1, 'node2': 5}}, 'node2': {'device': 'cuda', 'round': 10, 'edges': {'node1': 2, 'node0': 6}}}}
[2022-11-02 16:28:57,908 {dist_trainer.py:186}] <INFO> : <class 'model.resnet.ResNet'>
[2022-11-02 16:28:57,908 {dist_trainer.py:186}] <INFO> conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,908 {dist_trainer.py:183}] <INFO> bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-02 16:28:57,908 {dist_trainer.py:186}] <INFO> relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,908 {dist_trainer.py:186}] <INFO> maxpool: <class 'torch.nn.modules.pooling.MaxPool2d'>
[2022-11-02 16:28:57,908 {dist_trainer.py:186}] <INFO> dropout1: <class 'torch.nn.modules.dropout.Dropout2d'>
[2022-11-02 16:28:57,908 {dist_trainer.py:186}] <INFO> layer1: <class 'torch.nn.modules.container.Sequential'>
[2022-11-02 16:28:57,908 {dist_trainer.py:186}] <INFO> layer1.0: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,908 {dist_trainer.py:186}] <INFO> layer1.0.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,908 {dist_trainer.py:183}] <INFO> layer1.0.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-02 16:28:57,908 {dist_trainer.py:186}] <INFO> layer1.0.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,908 {dist_trainer.py:183}] <INFO> layer1.0.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-02 16:28:57,908 {dist_trainer.py:186}] <INFO> layer1.0.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,909 {dist_trainer.py:183}] <INFO> layer1.0.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer1.0.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer1.0.downsample: <class 'torch.nn.modules.container.Sequential'>
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer1.0.downsample.0: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,909 {dist_trainer.py:183}] <INFO> layer1.0.downsample.1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer1.1: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer1.1.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,909 {dist_trainer.py:183}] <INFO> layer1.1.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer1.1.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,909 {dist_trainer.py:183}] <INFO> layer1.1.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer1.1.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,909 {dist_trainer.py:183}] <INFO> layer1.1.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer1.1.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer1.2: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer1.2.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,909 {dist_trainer.py:183}] <INFO> layer1.2.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer1.2.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,909 {dist_trainer.py:183}] <INFO> layer1.2.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer1.2.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,909 {dist_trainer.py:183}] <INFO> layer1.2.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer1.2.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer1.3: <class 'torch.nn.modules.dropout.Dropout2d'>
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer2: <class 'torch.nn.modules.container.Sequential'>
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer2.0: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer2.0.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,909 {dist_trainer.py:183}] <INFO> layer2.0.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer2.0.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,909 {dist_trainer.py:183}] <INFO> layer2.0.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer2.0.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,909 {dist_trainer.py:183}] <INFO> layer2.0.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer2.0.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer2.0.downsample: <class 'torch.nn.modules.container.Sequential'>
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer2.0.downsample.0: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,909 {dist_trainer.py:183}] <INFO> layer2.0.downsample.1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer2.1: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer2.1.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,909 {dist_trainer.py:183}] <INFO> layer2.1.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer2.1.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,909 {dist_trainer.py:183}] <INFO> layer2.1.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-02 16:28:57,909 {dist_trainer.py:186}] <INFO> layer2.1.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,909 {dist_trainer.py:183}] <INFO> layer2.1.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer2.1.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer2.2: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer2.2.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,910 {dist_trainer.py:183}] <INFO> layer2.2.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer2.2.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,910 {dist_trainer.py:183}] <INFO> layer2.2.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer2.2.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,910 {dist_trainer.py:183}] <INFO> layer2.2.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer2.2.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer2.3: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer2.3.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,910 {dist_trainer.py:183}] <INFO> layer2.3.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer2.3.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,910 {dist_trainer.py:183}] <INFO> layer2.3.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer2.3.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,910 {dist_trainer.py:183}] <INFO> layer2.3.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer2.3.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer2.4: <class 'torch.nn.modules.dropout.Dropout2d'>
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer3: <class 'torch.nn.modules.container.Sequential'>
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer3.0: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer3.0.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,910 {dist_trainer.py:183}] <INFO> layer3.0.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer3.0.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,910 {dist_trainer.py:183}] <INFO> layer3.0.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer3.0.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,910 {dist_trainer.py:183}] <INFO> layer3.0.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer3.0.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer3.0.downsample: <class 'torch.nn.modules.container.Sequential'>
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer3.0.downsample.0: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,910 {dist_trainer.py:183}] <INFO> layer3.0.downsample.1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer3.1: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer3.1.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,910 {dist_trainer.py:183}] <INFO> layer3.1.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer3.1.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,910 {dist_trainer.py:183}] <INFO> layer3.1.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer3.1.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,910 {dist_trainer.py:183}] <INFO> layer3.1.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer3.1.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer3.2: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,910 {dist_trainer.py:186}] <INFO> layer3.2.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,910 {dist_trainer.py:183}] <INFO> layer3.2.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer3.2.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,911 {dist_trainer.py:183}] <INFO> layer3.2.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer3.2.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,911 {dist_trainer.py:183}] <INFO> layer3.2.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer3.2.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer3.3: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer3.3.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,911 {dist_trainer.py:183}] <INFO> layer3.3.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer3.3.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,911 {dist_trainer.py:183}] <INFO> layer3.3.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer3.3.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,911 {dist_trainer.py:183}] <INFO> layer3.3.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer3.3.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer3.4: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer3.4.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,911 {dist_trainer.py:183}] <INFO> layer3.4.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer3.4.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,911 {dist_trainer.py:183}] <INFO> layer3.4.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer3.4.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,911 {dist_trainer.py:183}] <INFO> layer3.4.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer3.4.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer3.5: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer3.5.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,911 {dist_trainer.py:183}] <INFO> layer3.5.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer3.5.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,911 {dist_trainer.py:183}] <INFO> layer3.5.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer3.5.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,911 {dist_trainer.py:183}] <INFO> layer3.5.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer3.5.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer3.6: <class 'torch.nn.modules.dropout.Dropout2d'>
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer4: <class 'torch.nn.modules.container.Sequential'>
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer4.0: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer4.0.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,911 {dist_trainer.py:183}] <INFO> layer4.0.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer4.0.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,911 {dist_trainer.py:183}] <INFO> layer4.0.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer4.0.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,911 {dist_trainer.py:183}] <INFO> layer4.0.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 64, channels: 2048, eps: 0.000010, affine: True
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer4.0.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer4.0.downsample: <class 'torch.nn.modules.container.Sequential'>
[2022-11-02 16:28:57,911 {dist_trainer.py:186}] <INFO> layer4.0.downsample.0: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,912 {dist_trainer.py:183}] <INFO> layer4.0.downsample.1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 64, channels: 2048, eps: 0.000010, affine: True
[2022-11-02 16:28:57,912 {dist_trainer.py:186}] <INFO> layer4.1: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,912 {dist_trainer.py:186}] <INFO> layer4.1.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,912 {dist_trainer.py:183}] <INFO> layer4.1.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 16:28:57,912 {dist_trainer.py:186}] <INFO> layer4.1.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,912 {dist_trainer.py:183}] <INFO> layer4.1.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 16:28:57,912 {dist_trainer.py:186}] <INFO> layer4.1.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,912 {dist_trainer.py:183}] <INFO> layer4.1.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 64, channels: 2048, eps: 0.000010, affine: True
[2022-11-02 16:28:57,912 {dist_trainer.py:186}] <INFO> layer4.1.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,912 {dist_trainer.py:186}] <INFO> layer4.2: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,912 {dist_trainer.py:186}] <INFO> layer4.2.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,912 {dist_trainer.py:183}] <INFO> layer4.2.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 16:28:57,912 {dist_trainer.py:186}] <INFO> layer4.2.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,912 {dist_trainer.py:183}] <INFO> layer4.2.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 16:28:57,912 {dist_trainer.py:186}] <INFO> layer4.2.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,912 {dist_trainer.py:183}] <INFO> layer4.2.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 64, channels: 2048, eps: 0.000010, affine: True
[2022-11-02 16:28:57,912 {dist_trainer.py:186}] <INFO> layer4.2.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,912 {dist_trainer.py:186}] <INFO> avgpool: <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>
[2022-11-02 16:28:57,912 {dist_trainer.py:186}] <INFO> dropout_fc: <class 'torch.nn.modules.dropout.Dropout'>
[2022-11-02 16:28:57,912 {dist_trainer.py:186}] <INFO> fc: <class 'torch.nn.modules.linear.Linear'>
[2022-11-02 16:28:57,912 {dist_trainer.py:192}] <INFO> parameter size: conv1.weight 37632B
[2022-11-02 16:28:57,912 {dist_trainer.py:192}] <INFO> parameter size: bn1.weight 256B
[2022-11-02 16:28:57,912 {dist_trainer.py:192}] <INFO> parameter size: bn1.bias 256B
[2022-11-02 16:28:57,912 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.conv1.weight 16384B
[2022-11-02 16:28:57,912 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.bn1.weight 256B
[2022-11-02 16:28:57,912 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.bn1.bias 256B
[2022-11-02 16:28:57,912 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.conv2.weight 147456B
[2022-11-02 16:28:57,912 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.bn2.weight 256B
[2022-11-02 16:28:57,913 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.bn2.bias 256B
[2022-11-02 16:28:57,913 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.conv3.weight 65536B
[2022-11-02 16:28:57,913 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.bn3.weight 1024B
[2022-11-02 16:28:57,913 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.bn3.bias 1024B
[2022-11-02 16:28:57,913 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.downsample.0.weight 65536B
[2022-11-02 16:28:57,913 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.downsample.1.weight 1024B
[2022-11-02 16:28:57,913 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.downsample.1.bias 1024B
[2022-11-02 16:28:57,913 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.conv1.weight 65536B
[2022-11-02 16:28:57,913 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.bn1.weight 256B
[2022-11-02 16:28:57,913 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.bn1.bias 256B
[2022-11-02 16:28:57,913 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.conv2.weight 147456B
[2022-11-02 16:28:57,913 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.bn2.weight 256B
[2022-11-02 16:28:57,913 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.bn2.bias 256B
[2022-11-02 16:28:57,913 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.conv3.weight 65536B
[2022-11-02 16:28:57,913 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.bn3.weight 1024B
[2022-11-02 16:28:57,913 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.bn3.bias 1024B
[2022-11-02 16:28:57,913 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.conv1.weight 65536B
[2022-11-02 16:28:57,913 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.bn1.weight 256B
[2022-11-02 16:28:57,913 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.bn1.bias 256B
[2022-11-02 16:28:57,913 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.conv2.weight 147456B
[2022-11-02 16:28:57,913 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.bn2.weight 256B
[2022-11-02 16:28:57,913 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.bn2.bias 256B
[2022-11-02 16:28:57,913 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.conv3.weight 65536B
[2022-11-02 16:28:57,913 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.bn3.weight 1024B
[2022-11-02 16:28:57,914 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.bn3.bias 1024B
[2022-11-02 16:28:57,914 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.conv1.weight 131072B
[2022-11-02 16:28:57,914 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.bn1.weight 512B
[2022-11-02 16:28:57,914 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.bn1.bias 512B
[2022-11-02 16:28:57,914 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.conv2.weight 589824B
[2022-11-02 16:28:57,914 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.bn2.weight 512B
[2022-11-02 16:28:57,914 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.bn2.bias 512B
[2022-11-02 16:28:57,914 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.conv3.weight 262144B
[2022-11-02 16:28:57,914 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.bn3.weight 2048B
[2022-11-02 16:28:57,914 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.bn3.bias 2048B
[2022-11-02 16:28:57,914 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.downsample.0.weight 524288B
[2022-11-02 16:28:57,914 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.downsample.1.weight 2048B
[2022-11-02 16:28:57,914 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.downsample.1.bias 2048B
[2022-11-02 16:28:57,914 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.conv1.weight 262144B
[2022-11-02 16:28:57,914 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.bn1.weight 512B
[2022-11-02 16:28:57,914 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.bn1.bias 512B
[2022-11-02 16:28:57,914 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.conv2.weight 589824B
[2022-11-02 16:28:57,914 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.bn2.weight 512B
[2022-11-02 16:28:57,914 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.bn2.bias 512B
[2022-11-02 16:28:57,914 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.conv3.weight 262144B
[2022-11-02 16:28:57,914 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.bn3.weight 2048B
[2022-11-02 16:28:57,914 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.bn3.bias 2048B
[2022-11-02 16:28:57,914 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.conv1.weight 262144B
[2022-11-02 16:28:57,914 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.bn1.weight 512B
[2022-11-02 16:28:57,915 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.bn1.bias 512B
[2022-11-02 16:28:57,915 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.conv2.weight 589824B
[2022-11-02 16:28:57,915 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.bn2.weight 512B
[2022-11-02 16:28:57,915 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.bn2.bias 512B
[2022-11-02 16:28:57,915 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.conv3.weight 262144B
[2022-11-02 16:28:57,915 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.bn3.weight 2048B
[2022-11-02 16:28:57,915 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.bn3.bias 2048B
[2022-11-02 16:28:57,915 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.conv1.weight 262144B
[2022-11-02 16:28:57,915 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.bn1.weight 512B
[2022-11-02 16:28:57,915 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.bn1.bias 512B
[2022-11-02 16:28:57,915 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.conv2.weight 589824B
[2022-11-02 16:28:57,915 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.bn2.weight 512B
[2022-11-02 16:28:57,915 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.bn2.bias 512B
[2022-11-02 16:28:57,915 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.conv3.weight 262144B
[2022-11-02 16:28:57,915 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.bn3.weight 2048B
[2022-11-02 16:28:57,915 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.bn3.bias 2048B
[2022-11-02 16:28:57,915 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.conv1.weight 524288B
[2022-11-02 16:28:57,915 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.bn1.weight 1024B
[2022-11-02 16:28:57,915 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.bn1.bias 1024B
[2022-11-02 16:28:57,915 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.conv2.weight 2359296B
[2022-11-02 16:28:57,915 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.bn2.weight 1024B
[2022-11-02 16:28:57,915 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.bn2.bias 1024B
[2022-11-02 16:28:57,915 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.conv3.weight 1048576B
[2022-11-02 16:28:57,915 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.bn3.weight 4096B
[2022-11-02 16:28:57,916 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.bn3.bias 4096B
[2022-11-02 16:28:57,916 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.downsample.0.weight 2097152B
[2022-11-02 16:28:57,916 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.downsample.1.weight 4096B
[2022-11-02 16:28:57,916 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.downsample.1.bias 4096B
[2022-11-02 16:28:57,916 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.conv1.weight 1048576B
[2022-11-02 16:28:57,916 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.bn1.weight 1024B
[2022-11-02 16:28:57,916 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.bn1.bias 1024B
[2022-11-02 16:28:57,916 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.conv2.weight 2359296B
[2022-11-02 16:28:57,916 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.bn2.weight 1024B
[2022-11-02 16:28:57,916 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.bn2.bias 1024B
[2022-11-02 16:28:57,916 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.conv3.weight 1048576B
[2022-11-02 16:28:57,916 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.bn3.weight 4096B
[2022-11-02 16:28:57,916 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.bn3.bias 4096B
[2022-11-02 16:28:57,916 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.conv1.weight 1048576B
[2022-11-02 16:28:57,916 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.bn1.weight 1024B
[2022-11-02 16:28:57,916 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.bn1.bias 1024B
[2022-11-02 16:28:57,916 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.conv2.weight 2359296B
[2022-11-02 16:28:57,916 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.bn2.weight 1024B
[2022-11-02 16:28:57,916 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.bn2.bias 1024B
[2022-11-02 16:28:57,916 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.conv3.weight 1048576B
[2022-11-02 16:28:57,916 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.bn3.weight 4096B
[2022-11-02 16:28:57,919 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.bn3.bias 4096B
[2022-11-02 16:28:57,919 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.conv1.weight 1048576B
[2022-11-02 16:28:57,919 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.bn1.weight 1024B
[2022-11-02 16:28:57,919 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.bn1.bias 1024B
[2022-11-02 16:28:57,919 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.conv2.weight 2359296B
[2022-11-02 16:28:57,919 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.bn2.weight 1024B
[2022-11-02 16:28:57,919 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.bn2.bias 1024B
[2022-11-02 16:28:57,919 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.conv3.weight 1048576B
[2022-11-02 16:28:57,919 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.bn3.weight 4096B
[2022-11-02 16:28:57,920 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.bn3.bias 4096B
[2022-11-02 16:28:57,920 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.conv1.weight 1048576B
[2022-11-02 16:28:57,920 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.bn1.weight 1024B
[2022-11-02 16:28:57,920 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.bn1.bias 1024B
[2022-11-02 16:28:57,920 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.conv2.weight 2359296B
[2022-11-02 16:28:57,920 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.bn2.weight 1024B
[2022-11-02 16:28:57,920 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.bn2.bias 1024B
[2022-11-02 16:28:57,920 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.conv3.weight 1048576B
[2022-11-02 16:28:57,920 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.bn3.weight 4096B
[2022-11-02 16:28:57,920 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.bn3.bias 4096B
[2022-11-02 16:28:57,920 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.conv1.weight 1048576B
[2022-11-02 16:28:57,920 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.bn1.weight 1024B
[2022-11-02 16:28:57,920 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.bn1.bias 1024B
[2022-11-02 16:28:57,920 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.conv2.weight 2359296B
[2022-11-02 16:28:57,920 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.bn2.weight 1024B
[2022-11-02 16:28:57,920 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.bn2.bias 1024B
[2022-11-02 16:28:57,920 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.conv3.weight 1048576B
[2022-11-02 16:28:57,920 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.bn3.weight 4096B
[2022-11-02 16:28:57,920 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.bn3.bias 4096B
[2022-11-02 16:28:57,920 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.conv1.weight 2097152B
[2022-11-02 16:28:57,920 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.bn1.weight 2048B
[2022-11-02 16:28:57,920 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.bn1.bias 2048B
[2022-11-02 16:28:57,920 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.conv2.weight 9437184B
[2022-11-02 16:28:57,921 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.bn2.weight 2048B
[2022-11-02 16:28:57,921 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.bn2.bias 2048B
[2022-11-02 16:28:57,921 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.conv3.weight 4194304B
[2022-11-02 16:28:57,921 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.bn3.weight 8192B
[2022-11-02 16:28:57,921 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.bn3.bias 8192B
[2022-11-02 16:28:57,921 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.downsample.0.weight 8388608B
[2022-11-02 16:28:57,921 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.downsample.1.weight 8192B
[2022-11-02 16:28:57,921 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.downsample.1.bias 8192B
[2022-11-02 16:28:57,921 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.conv1.weight 4194304B
[2022-11-02 16:28:57,921 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.bn1.weight 2048B
[2022-11-02 16:28:57,921 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.bn1.bias 2048B
[2022-11-02 16:28:57,921 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.conv2.weight 9437184B
[2022-11-02 16:28:57,921 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.bn2.weight 2048B
[2022-11-02 16:28:57,921 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.bn2.bias 2048B
[2022-11-02 16:28:57,921 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.conv3.weight 4194304B
[2022-11-02 16:28:57,921 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.bn3.weight 8192B
[2022-11-02 16:28:57,921 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.bn3.bias 8192B
[2022-11-02 16:28:57,921 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.conv1.weight 4194304B
[2022-11-02 16:28:57,921 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.bn1.weight 2048B
[2022-11-02 16:28:57,922 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.bn1.bias 2048B
[2022-11-02 16:28:57,922 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.conv2.weight 9437184B
[2022-11-02 16:28:57,922 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.bn2.weight 2048B
[2022-11-02 16:28:57,922 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.bn2.bias 2048B
[2022-11-02 16:28:57,922 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.conv3.weight 4194304B
[2022-11-02 16:28:57,922 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.bn3.weight 8192B
[2022-11-02 16:28:57,922 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.bn3.bias 8192B
[2022-11-02 16:28:57,922 {dist_trainer.py:192}] <INFO> parameter size: fc.weight 81920B
[2022-11-02 16:28:57,922 {dist_trainer.py:192}] <INFO> parameter size: fc.bias 40B
[2022-11-02 16:28:57,922 {dist_trainer.py:194}] <INFO> Model: resnet50 size: 89.754MiB
[2022-11-02 16:28:59,843 {dist_trainer.py:78}] <INFO> device: cuda:2 0/4, NVIDIA TITAN RTX
[2022-11-02 16:29:01,160 {dist_trainer.py:494}] <INFO> node0: [7,8,2,6,4,5,1,3]
[2022-11-02 16:29:01,160 {dist_trainer.py:494}] <INFO> node1: [4,5,1,3,0,9,7,8]
[2022-11-02 16:29:01,160 {dist_trainer.py:494}] <INFO> node2: [0,9,7,8,2,6,4,5]
[2022-11-02 16:29:01,160 {dist_trainer.py:497}] <INFO> class 0, [node1:0.472,node2:0.528]
[2022-11-02 16:29:01,160 {dist_trainer.py:497}] <INFO> class 1, [node0:0.505,node1:0.495]
[2022-11-02 16:29:01,160 {dist_trainer.py:497}] <INFO> class 2, [node0:0.535,node2:0.465]
[2022-11-02 16:29:01,160 {dist_trainer.py:497}] <INFO> class 3, [node0:0.502,node1:0.498]
[2022-11-02 16:29:01,160 {dist_trainer.py:497}] <INFO> class 4, [node0:0.325,node1:0.361,node2:0.314]
[2022-11-02 16:29:01,160 {dist_trainer.py:497}] <INFO> class 5, [node0:0.327,node1:0.343,node2:0.330]
[2022-11-02 16:29:01,160 {dist_trainer.py:497}] <INFO> class 6, [node0:0.497,node2:0.503]
[2022-11-02 16:29:01,160 {dist_trainer.py:497}] <INFO> class 7, [node0:0.340,node1:0.338,node2:0.322]
[2022-11-02 16:29:01,160 {dist_trainer.py:497}] <INFO> class 8, [node0:0.305,node1:0.352,node2:0.343]
[2022-11-02 16:29:01,161 {dist_trainer.py:497}] <INFO> class 9, [node1:0.475,node2:0.525]
[2022-11-02 16:29:01,162 {dist_trainer.py:527}] <INFO> train data node0: 1:2523,2:2675,3:2509,4:1624,5:1634,6:2484,7:1700,8:1524
[2022-11-02 16:29:01,162 {dist_trainer.py:527}] <INFO> train data node1: 0:2360,1:2477,3:2491,4:1806,5:1714,7:1690,8:1758,9:2375
[2022-11-02 16:29:01,163 {dist_trainer.py:527}] <INFO> train data node2: 0:2640,2:2325,4:1570,5:1652,6:2516,7:1610,8:1718,9:2625
[2022-11-02 16:29:14,062 {dist_trainer.py:531}] <INFO> split_load_datas(END)
[2022-11-02 16:29:14,063 {dist_trainer.py:114}] <INFO> datasets(END)
[2022-11-02 16:29:14,063 {dist_trainer.py:713}] <INFO> build_criterion(1)
[2022-11-02 16:29:14,064 {dist_trainer.py:721}] <INFO> build_criterion(2)
[2022-11-02 16:29:14,074 {contract.py:21}] <INFO> 0
[2022-11-02 16:29:14,075 {contract.py:21}] <INFO> 1
[2022-11-02 16:29:14,075 {contract.py:21}] <INFO> 2
[2022-11-02 16:29:14,075 {gateway.py:80}] <INFO> Gateway(1)
[2022-11-02 16:29:17,005 {distributed_c10d.py:228}] <INFO> Added key: store_based_barrier_key:1 to store for rank: 1
[2022-11-02 16:29:17,005 {distributed_c10d.py:262}] <INFO> Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
[2022-11-02 16:29:17,006 {gateway.py:87}] <INFO> Gateway(2)
[2022-11-02 16:29:17,209 {gateway.py:25}] <INFO> ServerHandler(1)
[2022-11-02 16:29:17,246 {gateway.py:34}] <INFO> ServerHandler(2)
[2022-11-02 16:29:17,248 {contract.py:36}] <INFO> contract(1)
[2022-11-02 16:29:17,296 {gateway.py:62}] <INFO> <SRV> node1 : edge setup.
[2022-11-02 16:29:17,300 {contract.py:44}] <INFO> <CLI> node1 : edge setup.
[2022-11-02 16:29:17,496 {contract.py:59}] <INFO> contract(2)
[2022-11-02 16:29:17,497 {pdmm_isvr.py:22}] <INFO> Optimizer <class 'optimizer.pdmm_isvr.PdmmISVR'> params: {'lr': 0.002, 'round': 10, 'initial_lr': 0.002, 'piw': 1.0, 'use_gcoef': False}
[2022-11-02 16:29:17,497 {dist_trainer.py:725}] <INFO> build_optimizer()
[2022-11-02 16:29:17,497 {dist_trainer.py:736}] <INFO> Setup scheduler: <torch.optim.lr_scheduler.StepLR object at 0x7f3ae01b0310>
[2022-11-02 16:29:45,010 {dist_trainer.py:770}] <INFO> [   1/ 200] connecting edge count: 2
[2022-11-02 16:29:58,901 {dist_trainer.py:821}] <INFO> [   1/ 200] loss: (train=2.486, val=2.330, test=2.330, l2=14517.672), acc: (train=0.199, val=0.145, test=0.145), diff=0.00160024, proc(train=27.511sec, eval=11.665sec)
[2022-11-02 16:30:20,381 {dist_trainer.py:770}] <INFO> [   2/ 200] connecting edge count: 2
[2022-11-02 16:30:34,079 {dist_trainer.py:821}] <INFO> [   2/ 200] loss: (train=2.310, val=2.237, test=2.232, l2=15504.587), acc: (train=0.231, val=0.164, test=0.167), diff=0.00001402, proc(train=21.479sec, eval=11.376sec)
[2022-11-02 16:30:57,744 {dist_trainer.py:770}] <INFO> [   3/ 200] connecting edge count: 2
[2022-11-02 16:31:11,678 {dist_trainer.py:821}] <INFO> [   3/ 200] loss: (train=2.323, val=2.249, test=2.249, l2=15565.440), acc: (train=0.254, val=0.196, test=0.195), diff=0.00000634, proc(train=23.665sec, eval=11.602sec)
[2022-11-02 16:31:36,881 {dist_trainer.py:770}] <INFO> [   4/ 200] connecting edge count: 2
[2022-11-02 16:31:49,967 {dist_trainer.py:821}] <INFO> [   4/ 200] loss: (train=2.228, val=2.240, test=2.232, l2=15527.690), acc: (train=0.227, val=0.151, test=0.152), diff=0.00000076, proc(train=25.203sec, eval=11.342sec)
[2022-11-02 16:32:14,282 {dist_trainer.py:770}] <INFO> [   5/ 200] connecting edge count: 2
[2022-11-02 16:32:27,932 {dist_trainer.py:821}] <INFO> [   5/ 200] loss: (train=2.231, val=2.139, test=2.137, l2=15525.788), acc: (train=0.249, val=0.190, test=0.189), diff=0.00000049, proc(train=24.315sec, eval=11.645sec)
[2022-11-02 16:32:54,559 {dist_trainer.py:770}] <INFO> [   6/ 200] connecting edge count: 2
[2022-11-02 16:33:07,174 {dist_trainer.py:821}] <INFO> [   6/ 200] loss: (train=2.183, val=2.115, test=2.120, l2=15467.611), acc: (train=0.267, val=0.251, test=0.250), diff=0.00000025, proc(train=26.627sec, eval=11.331sec)
[2022-11-02 16:33:29,874 {dist_trainer.py:770}] <INFO> [   7/ 200] connecting edge count: 2
[2022-11-02 16:33:42,678 {dist_trainer.py:821}] <INFO> [   7/ 200] loss: (train=2.116, val=1.995, test=1.992, l2=15453.730), acc: (train=0.319, val=0.257, test=0.267), diff=0.00000037, proc(train=22.699sec, eval=11.588sec)
[2022-11-02 16:34:06,695 {dist_trainer.py:770}] <INFO> [   8/ 200] connecting edge count: 2
[2022-11-02 16:34:20,294 {dist_trainer.py:821}] <INFO> [   8/ 200] loss: (train=2.046, val=1.950, test=1.942, l2=15407.948), acc: (train=0.312, val=0.256, test=0.266), diff=0.00000076, proc(train=24.017sec, eval=11.614sec)
[2022-11-02 16:34:41,715 {dist_trainer.py:770}] <INFO> [   9/ 200] connecting edge count: 2
[2022-11-02 16:34:55,412 {dist_trainer.py:821}] <INFO> [   9/ 200] loss: (train=1.984, val=2.005, test=1.999, l2=15372.202), acc: (train=0.263, val=0.262, test=0.263), diff=0.00000061, proc(train=21.421sec, eval=11.351sec)
[2022-11-02 16:35:19,290 {dist_trainer.py:770}] <INFO> [  10/ 200] connecting edge count: 2
[2022-11-02 16:35:31,877 {dist_trainer.py:821}] <INFO> [  10/ 200] loss: (train=2.000, val=2.015, test=2.008, l2=15377.546), acc: (train=0.322, val=0.227, test=0.231), diff=0.00000064, proc(train=23.878sec, eval=11.688sec)
[2022-11-02 16:35:56,088 {dist_trainer.py:770}] <INFO> [  11/ 200] connecting edge count: 2
[2022-11-02 16:36:08,765 {dist_trainer.py:821}] <INFO> [  11/ 200] loss: (train=1.948, val=1.976, test=1.966, l2=15330.036), acc: (train=0.346, val=0.253, test=0.254), diff=0.00000046, proc(train=24.211sec, eval=11.465sec)
[2022-11-02 16:36:33,230 {dist_trainer.py:770}] <INFO> [  12/ 200] connecting edge count: 2
[2022-11-02 16:36:46,612 {dist_trainer.py:821}] <INFO> [  12/ 200] loss: (train=1.998, val=1.973, test=1.970, l2=15319.670), acc: (train=0.333, val=0.295, test=0.294), diff=0.00000049, proc(train=24.464sec, eval=11.786sec)
[2022-11-02 16:37:13,374 {dist_trainer.py:770}] <INFO> [  13/ 200] connecting edge count: 2
[2022-11-02 16:37:26,258 {dist_trainer.py:821}] <INFO> [  13/ 200] loss: (train=1.947, val=1.777, test=1.769, l2=15268.197), acc: (train=0.371, val=0.349, test=0.357), diff=0.00000040, proc(train=26.762sec, eval=11.565sec)
[2022-11-02 16:37:48,323 {dist_trainer.py:770}] <INFO> [  14/ 200] connecting edge count: 2
[2022-11-02 16:38:01,072 {dist_trainer.py:821}] <INFO> [  14/ 200] loss: (train=1.878, val=1.789, test=1.780, l2=15249.944), acc: (train=0.350, val=0.326, test=0.329), diff=0.00000081, proc(train=22.064sec, eval=11.484sec)
[2022-11-02 16:38:25,563 {dist_trainer.py:770}] <INFO> [  15/ 200] connecting edge count: 2
[2022-11-02 16:38:38,764 {dist_trainer.py:821}] <INFO> [  15/ 200] loss: (train=1.860, val=1.788, test=1.782, l2=15211.562), acc: (train=0.379, val=0.344, test=0.349), diff=0.00000099, proc(train=24.491sec, eval=11.755sec)
