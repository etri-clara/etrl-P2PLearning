[2022-11-02 13:47:26,155 {main.py:127}] <INFO> Namespace(datadir='./data', outdir='./output/ring3', epochs=200, batch_size=100, seed=569, data_init_seed=11, model_init_seed=13, l2_lambda=0.01, model_name='resnet50', dataset_name='cifar10', train_data_length=10000, group_channels=32, drop_rate=0.1, last_drop_rate=0.5, cuda=True, cuda_device_no=3, plot=False, scheduler='StepLR', step_size=410, gamma=0.9, sleep_factor=0.0, loglevel=<LogLevel.INFO: 20>, logfile=None, optimizer='AdmmISVR', nodename='node2', conf='./conf/node_list.json', host='./conf/hosts.json', lr=0.002, use_gcoef=False, piw=1.0, round_step=False, swap_timeout=10)
[2022-11-02 13:47:26,155 {main.py:193}] <INFO> {'nodes': {'node0': {'device': 'cuda', 'round': 10, 'edges': {'node2': 0, 'node1': 4}}, 'node1': {'device': 'cuda', 'round': 10, 'edges': {'node0': 1, 'node2': 5}}, 'node2': {'device': 'cuda', 'round': 10, 'edges': {'node1': 2, 'node0': 6}}}}
[2022-11-02 13:47:26,279 {dist_trainer.py:186}] <INFO> : <class 'model.resnet.ResNet'>
[2022-11-02 13:47:26,279 {dist_trainer.py:186}] <INFO> conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,279 {dist_trainer.py:183}] <INFO> bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-02 13:47:26,279 {dist_trainer.py:186}] <INFO> relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 13:47:26,279 {dist_trainer.py:186}] <INFO> maxpool: <class 'torch.nn.modules.pooling.MaxPool2d'>
[2022-11-02 13:47:26,279 {dist_trainer.py:186}] <INFO> dropout1: <class 'torch.nn.modules.dropout.Dropout2d'>
[2022-11-02 13:47:26,279 {dist_trainer.py:186}] <INFO> layer1: <class 'torch.nn.modules.container.Sequential'>
[2022-11-02 13:47:26,279 {dist_trainer.py:186}] <INFO> layer1.0: <class 'model.resnet.Bottleneck'>
[2022-11-02 13:47:26,279 {dist_trainer.py:186}] <INFO> layer1.0.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,279 {dist_trainer.py:183}] <INFO> layer1.0.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-02 13:47:26,279 {dist_trainer.py:186}] <INFO> layer1.0.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,279 {dist_trainer.py:183}] <INFO> layer1.0.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-02 13:47:26,279 {dist_trainer.py:186}] <INFO> layer1.0.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,279 {dist_trainer.py:183}] <INFO> layer1.0.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 13:47:26,280 {dist_trainer.py:186}] <INFO> layer1.0.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 13:47:26,280 {dist_trainer.py:186}] <INFO> layer1.0.downsample: <class 'torch.nn.modules.container.Sequential'>
[2022-11-02 13:47:26,280 {dist_trainer.py:186}] <INFO> layer1.0.downsample.0: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,280 {dist_trainer.py:183}] <INFO> layer1.0.downsample.1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 13:47:26,280 {dist_trainer.py:186}] <INFO> layer1.1: <class 'model.resnet.Bottleneck'>
[2022-11-02 13:47:26,280 {dist_trainer.py:186}] <INFO> layer1.1.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,280 {dist_trainer.py:183}] <INFO> layer1.1.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-02 13:47:26,280 {dist_trainer.py:186}] <INFO> layer1.1.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,280 {dist_trainer.py:183}] <INFO> layer1.1.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-02 13:47:26,280 {dist_trainer.py:186}] <INFO> layer1.1.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,280 {dist_trainer.py:183}] <INFO> layer1.1.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 13:47:26,280 {dist_trainer.py:186}] <INFO> layer1.1.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 13:47:26,280 {dist_trainer.py:186}] <INFO> layer1.2: <class 'model.resnet.Bottleneck'>
[2022-11-02 13:47:26,280 {dist_trainer.py:186}] <INFO> layer1.2.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,280 {dist_trainer.py:183}] <INFO> layer1.2.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-02 13:47:26,280 {dist_trainer.py:186}] <INFO> layer1.2.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,280 {dist_trainer.py:183}] <INFO> layer1.2.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-02 13:47:26,280 {dist_trainer.py:186}] <INFO> layer1.2.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,280 {dist_trainer.py:183}] <INFO> layer1.2.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 13:47:26,280 {dist_trainer.py:186}] <INFO> layer1.2.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 13:47:26,280 {dist_trainer.py:186}] <INFO> layer1.3: <class 'torch.nn.modules.dropout.Dropout2d'>
[2022-11-02 13:47:26,280 {dist_trainer.py:186}] <INFO> layer2: <class 'torch.nn.modules.container.Sequential'>
[2022-11-02 13:47:26,280 {dist_trainer.py:186}] <INFO> layer2.0: <class 'model.resnet.Bottleneck'>
[2022-11-02 13:47:26,280 {dist_trainer.py:186}] <INFO> layer2.0.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,280 {dist_trainer.py:183}] <INFO> layer2.0.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-02 13:47:26,280 {dist_trainer.py:186}] <INFO> layer2.0.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,280 {dist_trainer.py:183}] <INFO> layer2.0.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-02 13:47:26,280 {dist_trainer.py:186}] <INFO> layer2.0.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,280 {dist_trainer.py:183}] <INFO> layer2.0.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 13:47:26,280 {dist_trainer.py:186}] <INFO> layer2.0.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 13:47:26,280 {dist_trainer.py:186}] <INFO> layer2.0.downsample: <class 'torch.nn.modules.container.Sequential'>
[2022-11-02 13:47:26,280 {dist_trainer.py:186}] <INFO> layer2.0.downsample.0: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,280 {dist_trainer.py:183}] <INFO> layer2.0.downsample.1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 13:47:26,280 {dist_trainer.py:186}] <INFO> layer2.1: <class 'model.resnet.Bottleneck'>
[2022-11-02 13:47:26,280 {dist_trainer.py:186}] <INFO> layer2.1.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,280 {dist_trainer.py:183}] <INFO> layer2.1.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-02 13:47:26,281 {dist_trainer.py:186}] <INFO> layer2.1.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,281 {dist_trainer.py:183}] <INFO> layer2.1.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-02 13:47:26,281 {dist_trainer.py:186}] <INFO> layer2.1.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,281 {dist_trainer.py:183}] <INFO> layer2.1.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 13:47:26,281 {dist_trainer.py:186}] <INFO> layer2.1.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 13:47:26,281 {dist_trainer.py:186}] <INFO> layer2.2: <class 'model.resnet.Bottleneck'>
[2022-11-02 13:47:26,281 {dist_trainer.py:186}] <INFO> layer2.2.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,281 {dist_trainer.py:183}] <INFO> layer2.2.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-02 13:47:26,281 {dist_trainer.py:186}] <INFO> layer2.2.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,281 {dist_trainer.py:183}] <INFO> layer2.2.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-02 13:47:26,281 {dist_trainer.py:186}] <INFO> layer2.2.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,281 {dist_trainer.py:183}] <INFO> layer2.2.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 13:47:26,281 {dist_trainer.py:186}] <INFO> layer2.2.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 13:47:26,281 {dist_trainer.py:186}] <INFO> layer2.3: <class 'model.resnet.Bottleneck'>
[2022-11-02 13:47:26,281 {dist_trainer.py:186}] <INFO> layer2.3.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,281 {dist_trainer.py:183}] <INFO> layer2.3.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-02 13:47:26,281 {dist_trainer.py:186}] <INFO> layer2.3.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,281 {dist_trainer.py:183}] <INFO> layer2.3.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-02 13:47:26,281 {dist_trainer.py:186}] <INFO> layer2.3.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,281 {dist_trainer.py:183}] <INFO> layer2.3.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 13:47:26,281 {dist_trainer.py:186}] <INFO> layer2.3.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 13:47:26,281 {dist_trainer.py:186}] <INFO> layer2.4: <class 'torch.nn.modules.dropout.Dropout2d'>
[2022-11-02 13:47:26,281 {dist_trainer.py:186}] <INFO> layer3: <class 'torch.nn.modules.container.Sequential'>
[2022-11-02 13:47:26,281 {dist_trainer.py:186}] <INFO> layer3.0: <class 'model.resnet.Bottleneck'>
[2022-11-02 13:47:26,281 {dist_trainer.py:186}] <INFO> layer3.0.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,281 {dist_trainer.py:183}] <INFO> layer3.0.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 13:47:26,281 {dist_trainer.py:186}] <INFO> layer3.0.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,281 {dist_trainer.py:183}] <INFO> layer3.0.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 13:47:26,281 {dist_trainer.py:186}] <INFO> layer3.0.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,281 {dist_trainer.py:183}] <INFO> layer3.0.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-02 13:47:26,281 {dist_trainer.py:186}] <INFO> layer3.0.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 13:47:26,281 {dist_trainer.py:186}] <INFO> layer3.0.downsample: <class 'torch.nn.modules.container.Sequential'>
[2022-11-02 13:47:26,281 {dist_trainer.py:186}] <INFO> layer3.0.downsample.0: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,281 {dist_trainer.py:183}] <INFO> layer3.0.downsample.1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-02 13:47:26,281 {dist_trainer.py:186}] <INFO> layer3.1: <class 'model.resnet.Bottleneck'>
[2022-11-02 13:47:26,281 {dist_trainer.py:186}] <INFO> layer3.1.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,282 {dist_trainer.py:183}] <INFO> layer3.1.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 13:47:26,282 {dist_trainer.py:186}] <INFO> layer3.1.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,282 {dist_trainer.py:183}] <INFO> layer3.1.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 13:47:26,282 {dist_trainer.py:186}] <INFO> layer3.1.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,282 {dist_trainer.py:183}] <INFO> layer3.1.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-02 13:47:26,282 {dist_trainer.py:186}] <INFO> layer3.1.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 13:47:26,282 {dist_trainer.py:186}] <INFO> layer3.2: <class 'model.resnet.Bottleneck'>
[2022-11-02 13:47:26,282 {dist_trainer.py:186}] <INFO> layer3.2.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,282 {dist_trainer.py:183}] <INFO> layer3.2.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 13:47:26,282 {dist_trainer.py:186}] <INFO> layer3.2.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,282 {dist_trainer.py:183}] <INFO> layer3.2.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 13:47:26,282 {dist_trainer.py:186}] <INFO> layer3.2.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,282 {dist_trainer.py:183}] <INFO> layer3.2.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-02 13:47:26,282 {dist_trainer.py:186}] <INFO> layer3.2.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 13:47:26,282 {dist_trainer.py:186}] <INFO> layer3.3: <class 'model.resnet.Bottleneck'>
[2022-11-02 13:47:26,282 {dist_trainer.py:186}] <INFO> layer3.3.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,282 {dist_trainer.py:183}] <INFO> layer3.3.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 13:47:26,282 {dist_trainer.py:186}] <INFO> layer3.3.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,282 {dist_trainer.py:183}] <INFO> layer3.3.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 13:47:26,282 {dist_trainer.py:186}] <INFO> layer3.3.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,282 {dist_trainer.py:183}] <INFO> layer3.3.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-02 13:47:26,282 {dist_trainer.py:186}] <INFO> layer3.3.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 13:47:26,282 {dist_trainer.py:186}] <INFO> layer3.4: <class 'model.resnet.Bottleneck'>
[2022-11-02 13:47:26,282 {dist_trainer.py:186}] <INFO> layer3.4.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,282 {dist_trainer.py:183}] <INFO> layer3.4.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 13:47:26,282 {dist_trainer.py:186}] <INFO> layer3.4.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,282 {dist_trainer.py:183}] <INFO> layer3.4.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 13:47:26,282 {dist_trainer.py:186}] <INFO> layer3.4.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,282 {dist_trainer.py:183}] <INFO> layer3.4.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-02 13:47:26,282 {dist_trainer.py:186}] <INFO> layer3.4.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 13:47:26,282 {dist_trainer.py:186}] <INFO> layer3.5: <class 'model.resnet.Bottleneck'>
[2022-11-02 13:47:26,282 {dist_trainer.py:186}] <INFO> layer3.5.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,282 {dist_trainer.py:183}] <INFO> layer3.5.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 13:47:26,282 {dist_trainer.py:186}] <INFO> layer3.5.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,282 {dist_trainer.py:183}] <INFO> layer3.5.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 13:47:26,282 {dist_trainer.py:186}] <INFO> layer3.5.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,283 {dist_trainer.py:183}] <INFO> layer3.5.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-02 13:47:26,283 {dist_trainer.py:186}] <INFO> layer3.5.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 13:47:26,283 {dist_trainer.py:186}] <INFO> layer3.6: <class 'torch.nn.modules.dropout.Dropout2d'>
[2022-11-02 13:47:26,283 {dist_trainer.py:186}] <INFO> layer4: <class 'torch.nn.modules.container.Sequential'>
[2022-11-02 13:47:26,283 {dist_trainer.py:186}] <INFO> layer4.0: <class 'model.resnet.Bottleneck'>
[2022-11-02 13:47:26,283 {dist_trainer.py:186}] <INFO> layer4.0.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,283 {dist_trainer.py:183}] <INFO> layer4.0.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 13:47:26,283 {dist_trainer.py:186}] <INFO> layer4.0.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,283 {dist_trainer.py:183}] <INFO> layer4.0.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 13:47:26,283 {dist_trainer.py:186}] <INFO> layer4.0.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,283 {dist_trainer.py:183}] <INFO> layer4.0.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 64, channels: 2048, eps: 0.000010, affine: True
[2022-11-02 13:47:26,283 {dist_trainer.py:186}] <INFO> layer4.0.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 13:47:26,283 {dist_trainer.py:186}] <INFO> layer4.0.downsample: <class 'torch.nn.modules.container.Sequential'>
[2022-11-02 13:47:26,283 {dist_trainer.py:186}] <INFO> layer4.0.downsample.0: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,283 {dist_trainer.py:183}] <INFO> layer4.0.downsample.1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 64, channels: 2048, eps: 0.000010, affine: True
[2022-11-02 13:47:26,283 {dist_trainer.py:186}] <INFO> layer4.1: <class 'model.resnet.Bottleneck'>
[2022-11-02 13:47:26,283 {dist_trainer.py:186}] <INFO> layer4.1.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,283 {dist_trainer.py:183}] <INFO> layer4.1.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 13:47:26,283 {dist_trainer.py:186}] <INFO> layer4.1.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,283 {dist_trainer.py:183}] <INFO> layer4.1.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 13:47:26,283 {dist_trainer.py:186}] <INFO> layer4.1.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,283 {dist_trainer.py:183}] <INFO> layer4.1.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 64, channels: 2048, eps: 0.000010, affine: True
[2022-11-02 13:47:26,283 {dist_trainer.py:186}] <INFO> layer4.1.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 13:47:26,283 {dist_trainer.py:186}] <INFO> layer4.2: <class 'model.resnet.Bottleneck'>
[2022-11-02 13:47:26,283 {dist_trainer.py:186}] <INFO> layer4.2.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,283 {dist_trainer.py:183}] <INFO> layer4.2.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 13:47:26,283 {dist_trainer.py:186}] <INFO> layer4.2.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,283 {dist_trainer.py:183}] <INFO> layer4.2.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 13:47:26,283 {dist_trainer.py:186}] <INFO> layer4.2.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 13:47:26,283 {dist_trainer.py:183}] <INFO> layer4.2.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 64, channels: 2048, eps: 0.000010, affine: True
[2022-11-02 13:47:26,283 {dist_trainer.py:186}] <INFO> layer4.2.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 13:47:26,283 {dist_trainer.py:186}] <INFO> avgpool: <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>
[2022-11-02 13:47:26,283 {dist_trainer.py:186}] <INFO> dropout_fc: <class 'torch.nn.modules.dropout.Dropout'>
[2022-11-02 13:47:26,283 {dist_trainer.py:186}] <INFO> fc: <class 'torch.nn.modules.linear.Linear'>
[2022-11-02 13:47:26,284 {dist_trainer.py:192}] <INFO> parameter size: conv1.weight 37632B
[2022-11-02 13:47:26,284 {dist_trainer.py:192}] <INFO> parameter size: bn1.weight 256B
[2022-11-02 13:47:26,284 {dist_trainer.py:192}] <INFO> parameter size: bn1.bias 256B
[2022-11-02 13:47:26,284 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.conv1.weight 16384B
[2022-11-02 13:47:26,284 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.bn1.weight 256B
[2022-11-02 13:47:26,284 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.bn1.bias 256B
[2022-11-02 13:47:26,284 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.conv2.weight 147456B
[2022-11-02 13:47:26,284 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.bn2.weight 256B
[2022-11-02 13:47:26,284 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.bn2.bias 256B
[2022-11-02 13:47:26,284 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.conv3.weight 65536B
[2022-11-02 13:47:26,284 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.bn3.weight 1024B
[2022-11-02 13:47:26,284 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.bn3.bias 1024B
[2022-11-02 13:47:26,284 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.downsample.0.weight 65536B
[2022-11-02 13:47:26,284 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.downsample.1.weight 1024B
[2022-11-02 13:47:26,284 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.downsample.1.bias 1024B
[2022-11-02 13:47:26,284 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.conv1.weight 65536B
[2022-11-02 13:47:26,284 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.bn1.weight 256B
[2022-11-02 13:47:26,284 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.bn1.bias 256B
[2022-11-02 13:47:26,284 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.conv2.weight 147456B
[2022-11-02 13:47:26,285 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.bn2.weight 256B
[2022-11-02 13:47:26,285 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.bn2.bias 256B
[2022-11-02 13:47:26,285 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.conv3.weight 65536B
[2022-11-02 13:47:26,285 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.bn3.weight 1024B
[2022-11-02 13:47:26,285 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.bn3.bias 1024B
[2022-11-02 13:47:26,285 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.conv1.weight 65536B
[2022-11-02 13:47:26,285 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.bn1.weight 256B
[2022-11-02 13:47:26,285 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.bn1.bias 256B
[2022-11-02 13:47:26,285 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.conv2.weight 147456B
[2022-11-02 13:47:26,285 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.bn2.weight 256B
[2022-11-02 13:47:26,285 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.bn2.bias 256B
[2022-11-02 13:47:26,285 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.conv3.weight 65536B
[2022-11-02 13:47:26,285 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.bn3.weight 1024B
[2022-11-02 13:47:26,285 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.bn3.bias 1024B
[2022-11-02 13:47:26,285 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.conv1.weight 131072B
[2022-11-02 13:47:26,285 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.bn1.weight 512B
[2022-11-02 13:47:26,285 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.bn1.bias 512B
[2022-11-02 13:47:26,285 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.conv2.weight 589824B
[2022-11-02 13:47:26,285 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.bn2.weight 512B
[2022-11-02 13:47:26,285 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.bn2.bias 512B
[2022-11-02 13:47:26,286 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.conv3.weight 262144B
[2022-11-02 13:47:26,286 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.bn3.weight 2048B
[2022-11-02 13:47:26,286 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.bn3.bias 2048B
[2022-11-02 13:47:26,286 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.downsample.0.weight 524288B
[2022-11-02 13:47:26,286 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.downsample.1.weight 2048B
[2022-11-02 13:47:26,286 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.downsample.1.bias 2048B
[2022-11-02 13:47:26,286 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.conv1.weight 262144B
[2022-11-02 13:47:26,286 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.bn1.weight 512B
[2022-11-02 13:47:26,286 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.bn1.bias 512B
[2022-11-02 13:47:26,286 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.conv2.weight 589824B
[2022-11-02 13:47:26,286 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.bn2.weight 512B
[2022-11-02 13:47:26,286 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.bn2.bias 512B
[2022-11-02 13:47:26,286 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.conv3.weight 262144B
[2022-11-02 13:47:26,286 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.bn3.weight 2048B
[2022-11-02 13:47:26,286 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.bn3.bias 2048B
[2022-11-02 13:47:26,286 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.conv1.weight 262144B
[2022-11-02 13:47:26,286 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.bn1.weight 512B
[2022-11-02 13:47:26,286 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.bn1.bias 512B
[2022-11-02 13:47:26,286 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.conv2.weight 589824B
[2022-11-02 13:47:26,287 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.bn2.weight 512B
[2022-11-02 13:47:26,287 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.bn2.bias 512B
[2022-11-02 13:47:26,287 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.conv3.weight 262144B
[2022-11-02 13:47:26,287 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.bn3.weight 2048B
[2022-11-02 13:47:26,287 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.bn3.bias 2048B
[2022-11-02 13:47:26,287 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.conv1.weight 262144B
[2022-11-02 13:47:26,287 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.bn1.weight 512B
[2022-11-02 13:47:26,287 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.bn1.bias 512B
[2022-11-02 13:47:26,287 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.conv2.weight 589824B
[2022-11-02 13:47:26,287 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.bn2.weight 512B
[2022-11-02 13:47:26,287 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.bn2.bias 512B
[2022-11-02 13:47:26,287 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.conv3.weight 262144B
[2022-11-02 13:47:26,287 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.bn3.weight 2048B
[2022-11-02 13:47:26,287 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.bn3.bias 2048B
[2022-11-02 13:47:26,287 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.conv1.weight 524288B
[2022-11-02 13:47:26,287 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.bn1.weight 1024B
[2022-11-02 13:47:26,287 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.bn1.bias 1024B
[2022-11-02 13:47:26,287 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.conv2.weight 2359296B
[2022-11-02 13:47:26,287 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.bn2.weight 1024B
[2022-11-02 13:47:26,287 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.bn2.bias 1024B
[2022-11-02 13:47:26,288 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.conv3.weight 1048576B
[2022-11-02 13:47:26,288 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.bn3.weight 4096B
[2022-11-02 13:47:26,288 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.bn3.bias 4096B
[2022-11-02 13:47:26,288 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.downsample.0.weight 2097152B
[2022-11-02 13:47:26,288 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.downsample.1.weight 4096B
[2022-11-02 13:47:26,288 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.downsample.1.bias 4096B
[2022-11-02 13:47:26,288 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.conv1.weight 1048576B
[2022-11-02 13:47:26,288 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.bn1.weight 1024B
[2022-11-02 13:47:26,288 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.bn1.bias 1024B
[2022-11-02 13:47:26,288 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.conv2.weight 2359296B
[2022-11-02 13:47:26,288 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.bn2.weight 1024B
[2022-11-02 13:47:26,288 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.bn2.bias 1024B
[2022-11-02 13:47:26,288 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.conv3.weight 1048576B
[2022-11-02 13:47:26,288 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.bn3.weight 4096B
[2022-11-02 13:47:26,288 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.bn3.bias 4096B
[2022-11-02 13:47:26,288 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.conv1.weight 1048576B
[2022-11-02 13:47:26,288 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.bn1.weight 1024B
[2022-11-02 13:47:26,288 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.bn1.bias 1024B
[2022-11-02 13:47:26,288 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.conv2.weight 2359296B
[2022-11-02 13:47:26,288 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.bn2.weight 1024B
[2022-11-02 13:47:26,289 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.bn2.bias 1024B
[2022-11-02 13:47:26,289 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.conv3.weight 1048576B
[2022-11-02 13:47:26,289 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.bn3.weight 4096B
[2022-11-02 13:47:26,289 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.bn3.bias 4096B
[2022-11-02 13:47:26,289 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.conv1.weight 1048576B
[2022-11-02 13:47:26,289 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.bn1.weight 1024B
[2022-11-02 13:47:26,289 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.bn1.bias 1024B
[2022-11-02 13:47:26,289 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.conv2.weight 2359296B
[2022-11-02 13:47:26,289 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.bn2.weight 1024B
[2022-11-02 13:47:26,289 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.bn2.bias 1024B
[2022-11-02 13:47:26,289 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.conv3.weight 1048576B
[2022-11-02 13:47:26,289 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.bn3.weight 4096B
[2022-11-02 13:47:26,289 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.bn3.bias 4096B
[2022-11-02 13:47:26,289 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.conv1.weight 1048576B
[2022-11-02 13:47:26,289 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.bn1.weight 1024B
[2022-11-02 13:47:26,289 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.bn1.bias 1024B
[2022-11-02 13:47:26,289 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.conv2.weight 2359296B
[2022-11-02 13:47:26,289 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.bn2.weight 1024B
[2022-11-02 13:47:26,289 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.bn2.bias 1024B
[2022-11-02 13:47:26,289 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.conv3.weight 1048576B
[2022-11-02 13:47:26,289 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.bn3.weight 4096B
[2022-11-02 13:47:26,290 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.bn3.bias 4096B
[2022-11-02 13:47:26,290 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.conv1.weight 1048576B
[2022-11-02 13:47:26,290 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.bn1.weight 1024B
[2022-11-02 13:47:26,290 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.bn1.bias 1024B
[2022-11-02 13:47:26,290 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.conv2.weight 2359296B
[2022-11-02 13:47:26,290 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.bn2.weight 1024B
[2022-11-02 13:47:26,290 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.bn2.bias 1024B
[2022-11-02 13:47:26,290 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.conv3.weight 1048576B
[2022-11-02 13:47:26,290 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.bn3.weight 4096B
[2022-11-02 13:47:26,290 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.bn3.bias 4096B
[2022-11-02 13:47:26,290 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.conv1.weight 2097152B
[2022-11-02 13:47:26,290 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.bn1.weight 2048B
[2022-11-02 13:47:26,290 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.bn1.bias 2048B
[2022-11-02 13:47:26,290 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.conv2.weight 9437184B
[2022-11-02 13:47:26,290 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.bn2.weight 2048B
[2022-11-02 13:47:26,290 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.bn2.bias 2048B
[2022-11-02 13:47:26,290 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.conv3.weight 4194304B
[2022-11-02 13:47:26,290 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.bn3.weight 8192B
[2022-11-02 13:47:26,290 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.bn3.bias 8192B
[2022-11-02 13:47:26,290 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.downsample.0.weight 8388608B
[2022-11-02 13:47:26,291 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.downsample.1.weight 8192B
[2022-11-02 13:47:26,291 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.downsample.1.bias 8192B
[2022-11-02 13:47:26,291 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.conv1.weight 4194304B
[2022-11-02 13:47:26,291 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.bn1.weight 2048B
[2022-11-02 13:47:26,291 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.bn1.bias 2048B
[2022-11-02 13:47:26,291 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.conv2.weight 9437184B
[2022-11-02 13:47:26,291 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.bn2.weight 2048B
[2022-11-02 13:47:26,291 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.bn2.bias 2048B
[2022-11-02 13:47:26,291 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.conv3.weight 4194304B
[2022-11-02 13:47:26,291 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.bn3.weight 8192B
[2022-11-02 13:47:26,291 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.bn3.bias 8192B
[2022-11-02 13:47:26,291 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.conv1.weight 4194304B
[2022-11-02 13:47:26,291 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.bn1.weight 2048B
[2022-11-02 13:47:26,291 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.bn1.bias 2048B
[2022-11-02 13:47:26,291 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.conv2.weight 9437184B
[2022-11-02 13:47:26,291 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.bn2.weight 2048B
[2022-11-02 13:47:26,294 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.bn2.bias 2048B
[2022-11-02 13:47:26,294 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.conv3.weight 4194304B
[2022-11-02 13:47:26,294 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.bn3.weight 8192B
[2022-11-02 13:47:26,294 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.bn3.bias 8192B
[2022-11-02 13:47:26,294 {dist_trainer.py:192}] <INFO> parameter size: fc.weight 81920B
[2022-11-02 13:47:26,294 {dist_trainer.py:192}] <INFO> parameter size: fc.bias 40B
[2022-11-02 13:47:26,294 {dist_trainer.py:194}] <INFO> Model: resnet50 size: 89.754MiB
[2022-11-02 13:47:31,159 {dist_trainer.py:78}] <INFO> device: cuda:3 0/4, NVIDIA TITAN RTX
[2022-11-02 13:47:32,468 {dist_trainer.py:494}] <INFO> node0: [7,8,2,6,4,5,1,3]
[2022-11-02 13:47:32,468 {dist_trainer.py:494}] <INFO> node1: [4,5,1,3,0,9,7,8]
[2022-11-02 13:47:32,468 {dist_trainer.py:494}] <INFO> node2: [0,9,7,8,2,6,4,5]
[2022-11-02 13:47:32,468 {dist_trainer.py:497}] <INFO> class 0, [node1:0.472,node2:0.528]
[2022-11-02 13:47:32,468 {dist_trainer.py:497}] <INFO> class 1, [node0:0.505,node1:0.495]
[2022-11-02 13:47:32,468 {dist_trainer.py:497}] <INFO> class 2, [node0:0.535,node2:0.465]
[2022-11-02 13:47:32,468 {dist_trainer.py:497}] <INFO> class 3, [node0:0.502,node1:0.498]
[2022-11-02 13:47:32,468 {dist_trainer.py:497}] <INFO> class 4, [node0:0.325,node1:0.361,node2:0.314]
[2022-11-02 13:47:32,468 {dist_trainer.py:497}] <INFO> class 5, [node0:0.327,node1:0.343,node2:0.330]
[2022-11-02 13:47:32,468 {dist_trainer.py:497}] <INFO> class 6, [node0:0.497,node2:0.503]
[2022-11-02 13:47:32,468 {dist_trainer.py:497}] <INFO> class 7, [node0:0.340,node1:0.338,node2:0.322]
[2022-11-02 13:47:32,468 {dist_trainer.py:497}] <INFO> class 8, [node0:0.305,node1:0.352,node2:0.343]
[2022-11-02 13:47:32,468 {dist_trainer.py:497}] <INFO> class 9, [node1:0.475,node2:0.525]
[2022-11-02 13:47:32,470 {dist_trainer.py:527}] <INFO> train data node0: 1:2523,2:2675,3:2509,4:1624,5:1634,6:2484,7:1700,8:1524
[2022-11-02 13:47:32,470 {dist_trainer.py:527}] <INFO> train data node1: 0:2360,1:2477,3:2491,4:1806,5:1714,7:1690,8:1758,9:2375
[2022-11-02 13:47:32,470 {dist_trainer.py:527}] <INFO> train data node2: 0:2640,2:2325,4:1570,5:1652,6:2516,7:1610,8:1718,9:2625
[2022-11-02 13:47:45,561 {dist_trainer.py:531}] <INFO> split_load_datas(END)
[2022-11-02 13:47:45,562 {dist_trainer.py:114}] <INFO> datasets(END)
[2022-11-02 13:47:45,562 {dist_trainer.py:713}] <INFO> build_criterion(1)
[2022-11-02 13:47:45,563 {dist_trainer.py:721}] <INFO> build_criterion(2)
[2022-11-02 13:47:45,573 {contract.py:21}] <INFO> 0
[2022-11-02 13:47:45,573 {contract.py:21}] <INFO> 1
[2022-11-02 13:47:45,574 {contract.py:21}] <INFO> 2
[2022-11-02 13:47:45,574 {gateway.py:80}] <INFO> Gateway(1)
[2022-11-02 13:47:45,637 {distributed_c10d.py:228}] <INFO> Added key: store_based_barrier_key:1 to store for rank: 2
[2022-11-02 13:47:45,637 {distributed_c10d.py:262}] <INFO> Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
[2022-11-02 13:47:45,638 {gateway.py:87}] <INFO> Gateway(2)
[2022-11-02 13:47:45,861 {gateway.py:25}] <INFO> ServerHandler(1)
[2022-11-02 13:47:45,862 {gateway.py:34}] <INFO> ServerHandler(2)
[2022-11-02 13:47:45,867 {contract.py:36}] <INFO> contract(1)
[2022-11-02 13:47:45,915 {contract.py:44}] <INFO> <CLI> node2 : edge setup.
[2022-11-02 13:47:46,009 {gateway.py:62}] <INFO> <SRV> node2 : edge setup.
[2022-11-02 13:47:46,698 {contract.py:59}] <INFO> contract(2)
[2022-11-02 13:47:46,699 {admm_isvr.py:22}] <INFO> Optimizer <class 'optimizer.admm_isvr.AdmmISVR'> params: {'lr': 0.002, 'round': 10, 'initial_lr': 0.002, 'piw': 1.0, 'use_gcoef': False}
[2022-11-02 13:47:46,699 {dist_trainer.py:725}] <INFO> build_optimizer()
[2022-11-02 13:47:46,699 {dist_trainer.py:736}] <INFO> Setup scheduler: <torch.optim.lr_scheduler.StepLR object at 0x7f21f53c3310>
[2022-11-02 13:48:24,977 {dist_trainer.py:770}] <INFO> [   1/ 200] connecting edge count: 2
[2022-11-02 13:49:19,689 {dist_trainer.py:821}] <INFO> [   1/ 200] loss: (train=2.371, val=2.586, test=2.589, l2=12362.547), acc: (train=0.159, val=0.101, test=0.101), diff=0.00000727, proc(train=38.277sec, eval=53.241sec)
[2022-11-02 13:49:57,700 {dist_trainer.py:770}] <INFO> [   2/ 200] connecting edge count: 2
[2022-11-02 13:50:45,942 {dist_trainer.py:821}] <INFO> [   2/ 200] loss: (train=2.207, val=2.267, test=2.254, l2=12335.560), acc: (train=0.255, val=0.185, test=0.187), diff=0.00000137, proc(train=38.011sec, eval=46.974sec)
[2022-11-02 13:51:23,775 {dist_trainer.py:770}] <INFO> [   3/ 200] connecting edge count: 2
[2022-11-02 13:52:11,018 {dist_trainer.py:821}] <INFO> [   3/ 200] loss: (train=2.030, val=1.988, test=1.986, l2=12272.700), acc: (train=0.305, val=0.241, test=0.247), diff=0.00000131, proc(train=37.832sec, eval=45.200sec)
[2022-11-02 13:52:47,179 {dist_trainer.py:770}] <INFO> [   4/ 200] connecting edge count: 2
[2022-11-02 13:53:42,546 {dist_trainer.py:821}] <INFO> [   4/ 200] loss: (train=1.933, val=1.993, test=1.989, l2=12221.673), acc: (train=0.353, val=0.269, test=0.271), diff=0.00000189, proc(train=36.160sec, eval=53.691sec)
[2022-11-02 13:54:20,083 {dist_trainer.py:770}] <INFO> [   5/ 200] connecting edge count: 2
[2022-11-02 13:55:07,200 {dist_trainer.py:821}] <INFO> [   5/ 200] loss: (train=1.873, val=1.867, test=1.858, l2=12164.001), acc: (train=0.430, val=0.315, test=0.316), diff=0.00000157, proc(train=37.536sec, eval=45.946sec)
[2022-11-02 13:55:44,991 {dist_trainer.py:770}] <INFO> [   6/ 200] connecting edge count: 2
[2022-11-02 13:56:30,136 {dist_trainer.py:821}] <INFO> [   6/ 200] loss: (train=1.803, val=1.902, test=1.897, l2=12110.129), acc: (train=0.430, val=0.330, test=0.328), diff=0.00000173, proc(train=37.790sec, eval=43.922sec)
[2022-11-02 13:57:07,509 {dist_trainer.py:770}] <INFO> [   7/ 200] connecting edge count: 2
[2022-11-02 13:57:59,935 {dist_trainer.py:821}] <INFO> [   7/ 200] loss: (train=1.770, val=1.770, test=1.773, l2=12049.456), acc: (train=0.429, val=0.356, test=0.357), diff=0.00000128, proc(train=37.373sec, eval=50.582sec)
[2022-11-02 13:58:36,976 {dist_trainer.py:770}] <INFO> [   8/ 200] connecting edge count: 2
[2022-11-02 13:59:29,922 {dist_trainer.py:821}] <INFO> [   8/ 200] loss: (train=1.700, val=1.707, test=1.710, l2=11998.258), acc: (train=0.477, val=0.377, test=0.373), diff=0.00000118, proc(train=37.040sec, eval=51.670sec)
[2022-11-02 14:00:08,775 {dist_trainer.py:770}] <INFO> [   9/ 200] connecting edge count: 2
[2022-11-02 14:00:53,733 {dist_trainer.py:821}] <INFO> [   9/ 200] loss: (train=1.689, val=1.701, test=1.701, l2=11949.419), acc: (train=0.500, val=0.390, test=0.390), diff=0.00000129, proc(train=38.853sec, eval=43.631sec)
[2022-11-02 14:01:32,412 {dist_trainer.py:770}] <INFO> [  10/ 200] connecting edge count: 2
[2022-11-02 14:02:22,722 {dist_trainer.py:821}] <INFO> [  10/ 200] loss: (train=1.669, val=1.777, test=1.779, l2=11888.962), acc: (train=0.443, val=0.336, test=0.336), diff=0.00000136, proc(train=38.678sec, eval=48.844sec)
[2022-11-02 14:02:59,366 {dist_trainer.py:770}] <INFO> [  11/ 200] connecting edge count: 2
[2022-11-02 14:03:52,875 {dist_trainer.py:821}] <INFO> [  11/ 200] loss: (train=1.593, val=1.637, test=1.643, l2=11844.429), acc: (train=0.512, val=0.410, test=0.407), diff=0.00000129, proc(train=36.644sec, eval=51.661sec)
[2022-11-02 14:04:29,762 {dist_trainer.py:770}] <INFO> [  12/ 200] connecting edge count: 2
[2022-11-02 14:05:16,020 {dist_trainer.py:821}] <INFO> [  12/ 200] loss: (train=1.586, val=1.650, test=1.655, l2=11800.424), acc: (train=0.494, val=0.406, test=0.403), diff=0.00000110, proc(train=36.887sec, eval=45.036sec)
[2022-11-02 14:05:53,777 {dist_trainer.py:770}] <INFO> [  13/ 200] connecting edge count: 2
[2022-11-02 14:06:44,262 {dist_trainer.py:821}] <INFO> [  13/ 200] loss: (train=1.536, val=1.573, test=1.578, l2=11746.227), acc: (train=0.472, val=0.428, test=0.422), diff=0.00000134, proc(train=37.756sec, eval=48.668sec)
[2022-11-02 14:07:20,942 {dist_trainer.py:770}] <INFO> [  14/ 200] connecting edge count: 2
[2022-11-02 14:08:13,878 {dist_trainer.py:821}] <INFO> [  14/ 200] loss: (train=1.532, val=1.570, test=1.582, l2=11699.479), acc: (train=0.490, val=0.436, test=0.431), diff=0.00000134, proc(train=36.680sec, eval=51.809sec)
[2022-11-02 14:08:51,095 {dist_trainer.py:770}] <INFO> [  15/ 200] connecting edge count: 2
[2022-11-02 14:09:40,296 {dist_trainer.py:821}] <INFO> [  15/ 200] loss: (train=1.490, val=1.554, test=1.570, l2=11651.277), acc: (train=0.526, val=0.432, test=0.423), diff=0.00000134, proc(train=37.217sec, eval=47.541sec)
[2022-11-02 14:10:19,061 {dist_trainer.py:770}] <INFO> [  16/ 200] connecting edge count: 2
[2022-11-02 14:11:10,537 {dist_trainer.py:821}] <INFO> [  16/ 200] loss: (train=1.518, val=1.627, test=1.639, l2=11601.902), acc: (train=0.483, val=0.409, test=0.406), diff=0.00000126, proc(train=38.764sec, eval=49.952sec)
[2022-11-02 14:11:49,247 {dist_trainer.py:770}] <INFO> [  17/ 200] connecting edge count: 2
[2022-11-02 14:12:39,247 {dist_trainer.py:821}] <INFO> [  17/ 200] loss: (train=1.509, val=1.605, test=1.610, l2=11554.753), acc: (train=0.538, val=0.431, test=0.424), diff=0.00000165, proc(train=38.710sec, eval=48.567sec)
[2022-11-02 14:13:16,784 {dist_trainer.py:770}] <INFO> [  18/ 200] connecting edge count: 2
[2022-11-02 14:14:06,115 {dist_trainer.py:821}] <INFO> [  18/ 200] loss: (train=1.455, val=1.503, test=1.525, l2=11505.899), acc: (train=0.529, val=0.458, test=0.451), diff=0.00000112, proc(train=37.537sec, eval=47.754sec)
[2022-11-02 14:14:43,337 {dist_trainer.py:770}] <INFO> [  19/ 200] connecting edge count: 2
[2022-11-02 14:15:32,920 {dist_trainer.py:821}] <INFO> [  19/ 200] loss: (train=1.490, val=1.448, test=1.467, l2=11470.840), acc: (train=0.525, val=0.476, test=0.467), diff=0.00000172, proc(train=37.222sec, eval=48.375sec)
[2022-11-02 14:16:10,118 {dist_trainer.py:770}] <INFO> [  20/ 200] connecting edge count: 2
[2022-11-02 14:17:02,450 {dist_trainer.py:821}] <INFO> [  20/ 200] loss: (train=1.463, val=1.526, test=1.546, l2=11426.514), acc: (train=0.566, val=0.462, test=0.455), diff=0.00000161, proc(train=37.198sec, eval=50.862sec)
[2022-11-02 14:17:39,107 {dist_trainer.py:770}] <INFO> [  21/ 200] connecting edge count: 2
[2022-11-02 14:18:28,231 {dist_trainer.py:821}] <INFO> [  21/ 200] loss: (train=1.425, val=1.372, test=1.399, l2=11380.901), acc: (train=0.527, val=0.510, test=0.494), diff=0.00000147, proc(train=36.657sec, eval=47.741sec)
[2022-11-02 14:19:06,233 {dist_trainer.py:770}] <INFO> [  22/ 200] connecting edge count: 2
[2022-11-02 14:19:58,931 {dist_trainer.py:821}] <INFO> [  22/ 200] loss: (train=1.403, val=1.358, test=1.387, l2=11325.687), acc: (train=0.568, val=0.509, test=0.496), diff=0.00000125, proc(train=38.001sec, eval=51.064sec)
[2022-11-02 14:20:37,355 {dist_trainer.py:770}] <INFO> [  23/ 200] connecting edge count: 2
[2022-11-02 14:21:26,505 {dist_trainer.py:821}] <INFO> [  23/ 200] loss: (train=1.405, val=1.334, test=1.362, l2=11279.030), acc: (train=0.554, val=0.520, test=0.511), diff=0.00000130, proc(train=38.423sec, eval=47.478sec)
[2022-11-02 14:22:02,935 {dist_trainer.py:770}] <INFO> [  24/ 200] connecting edge count: 2
[2022-11-02 14:22:55,887 {dist_trainer.py:821}] <INFO> [  24/ 200] loss: (train=1.372, val=1.327, test=1.362, l2=11231.130), acc: (train=0.562, val=0.522, test=0.509), diff=0.00000155, proc(train=36.429sec, eval=51.430sec)
[2022-11-02 14:23:33,330 {dist_trainer.py:770}] <INFO> [  25/ 200] connecting edge count: 2
[2022-11-02 14:24:22,095 {dist_trainer.py:821}] <INFO> [  25/ 200] loss: (train=1.326, val=1.361, test=1.394, l2=11187.833), acc: (train=0.567, val=0.520, test=0.511), diff=0.00000158, proc(train=37.443sec, eval=47.590sec)
[2022-11-02 14:24:59,765 {dist_trainer.py:770}] <INFO> [  26/ 200] connecting edge count: 2
[2022-11-02 14:25:50,823 {dist_trainer.py:821}] <INFO> [  26/ 200] loss: (train=1.330, val=1.337, test=1.374, l2=11135.157), acc: (train=0.602, val=0.520, test=0.508), diff=0.00000138, proc(train=37.670sec, eval=49.163sec)
[2022-11-02 14:26:27,348 {dist_trainer.py:770}] <INFO> [  27/ 200] connecting edge count: 2
[2022-11-02 14:27:18,918 {dist_trainer.py:821}] <INFO> [  27/ 200] loss: (train=1.296, val=1.372, test=1.406, l2=11090.453), acc: (train=0.599, val=0.506, test=0.493), diff=0.00000213, proc(train=36.524sec, eval=50.325sec)
[2022-11-02 14:27:56,685 {dist_trainer.py:770}] <INFO> [  28/ 200] connecting edge count: 2
[2022-11-02 14:28:45,365 {dist_trainer.py:821}] <INFO> [  28/ 200] loss: (train=1.308, val=1.303, test=1.341, l2=11037.793), acc: (train=0.582, val=0.537, test=0.526), diff=0.00000194, proc(train=37.766sec, eval=47.117sec)
[2022-11-02 14:29:24,386 {dist_trainer.py:770}] <INFO> [  29/ 200] connecting edge count: 2
[2022-11-02 14:30:18,373 {dist_trainer.py:821}] <INFO> [  29/ 200] loss: (train=1.293, val=1.299, test=1.337, l2=10984.640), acc: (train=0.599, val=0.540, test=0.532), diff=0.00000130, proc(train=39.021sec, eval=52.510sec)
[2022-11-02 14:30:54,884 {dist_trainer.py:770}] <INFO> [  30/ 200] connecting edge count: 2
[2022-11-02 14:31:44,354 {dist_trainer.py:821}] <INFO> [  30/ 200] loss: (train=1.262, val=1.345, test=1.384, l2=10941.351), acc: (train=0.603, val=0.514, test=0.503), diff=0.00000147, proc(train=36.510sec, eval=48.086sec)
[2022-11-02 14:32:22,894 {dist_trainer.py:770}] <INFO> [  31/ 200] connecting edge count: 2
[2022-11-02 14:33:16,360 {dist_trainer.py:821}] <INFO> [  31/ 200] loss: (train=1.275, val=1.352, test=1.392, l2=10893.647), acc: (train=0.613, val=0.513, test=0.502), diff=0.00000156, proc(train=38.540sec, eval=51.752sec)
[2022-11-02 14:33:53,160 {dist_trainer.py:770}] <INFO> [  32/ 200] connecting edge count: 2
[2022-11-02 14:34:41,311 {dist_trainer.py:821}] <INFO> [  32/ 200] loss: (train=1.242, val=1.295, test=1.351, l2=10851.522), acc: (train=0.634, val=0.546, test=0.533), diff=0.00000129, proc(train=36.800sec, eval=46.694sec)
[2022-11-02 14:35:18,558 {dist_trainer.py:770}] <INFO> [  33/ 200] connecting edge count: 2
[2022-11-02 14:36:10,691 {dist_trainer.py:821}] <INFO> [  33/ 200] loss: (train=1.233, val=1.359, test=1.422, l2=10803.079), acc: (train=0.588, val=0.518, test=0.499), diff=0.00000171, proc(train=37.247sec, eval=49.998sec)
[2022-11-02 14:36:48,767 {dist_trainer.py:770}] <INFO> [  34/ 200] connecting edge count: 2
[2022-11-02 14:37:37,758 {dist_trainer.py:821}] <INFO> [  34/ 200] loss: (train=1.243, val=1.246, test=1.300, l2=10746.312), acc: (train=0.625, val=0.560, test=0.548), diff=0.00000152, proc(train=38.076sec, eval=47.751sec)
[2022-11-02 14:38:14,651 {dist_trainer.py:770}] <INFO> [  35/ 200] connecting edge count: 2
[2022-11-02 14:39:03,447 {dist_trainer.py:821}] <INFO> [  35/ 200] loss: (train=1.213, val=1.231, test=1.293, l2=10818.535), acc: (train=0.653, val=0.557, test=0.543), diff=0.00052879, proc(train=36.893sec, eval=47.235sec)
[2022-11-02 14:39:40,134 {dist_trainer.py:770}] <INFO> [  36/ 200] connecting edge count: 2
[2022-11-02 14:40:33,986 {dist_trainer.py:821}] <INFO> [  36/ 200] loss: (train=1.225, val=1.355, test=1.409, l2=10416.511), acc: (train=0.586, val=0.540, test=0.531), diff=0.00001174, proc(train=36.687sec, eval=52.287sec)
[2022-11-02 14:41:10,954 {dist_trainer.py:770}] <INFO> [  37/ 200] connecting edge count: 2
[2022-11-02 14:42:00,164 {dist_trainer.py:821}] <INFO> [  37/ 200] loss: (train=1.206, val=1.146, test=1.215, l2=10354.714), acc: (train=0.648, val=0.595, test=0.574), diff=0.00000159, proc(train=36.968sec, eval=47.634sec)
[2022-11-02 14:42:38,042 {dist_trainer.py:770}] <INFO> [  38/ 200] connecting edge count: 2
[2022-11-02 14:43:29,530 {dist_trainer.py:821}] <INFO> [  38/ 200] loss: (train=1.187, val=1.195, test=1.259, l2=10304.194), acc: (train=0.645, val=0.577, test=0.560), diff=0.00000104, proc(train=37.877sec, eval=49.776sec)
[2022-11-02 14:44:07,873 {dist_trainer.py:770}] <INFO> [  39/ 200] connecting edge count: 2
[2022-11-02 14:44:59,910 {dist_trainer.py:821}] <INFO> [  39/ 200] loss: (train=1.169, val=1.181, test=1.241, l2=10261.070), acc: (train=0.640, val=0.583, test=0.570), diff=0.00000130, proc(train=38.342sec, eval=50.566sec)
[2022-11-02 14:45:35,510 {dist_trainer.py:770}] <INFO> [  40/ 200] connecting edge count: 2
[2022-11-02 14:46:24,387 {dist_trainer.py:821}] <INFO> [  40/ 200] loss: (train=1.198, val=1.209, test=1.277, l2=10218.290), acc: (train=0.613, val=0.580, test=0.562), diff=0.00000179, proc(train=35.600sec, eval=47.562sec)
[2022-11-02 14:47:00,593 {dist_trainer.py:770}] <INFO> [  41/ 200] connecting edge count: 2
[2022-11-02 14:47:55,577 {dist_trainer.py:821}] <INFO> [  41/ 200] loss: (train=1.169, val=1.180, test=1.253, l2=10170.592), acc: (train=0.652, val=0.582, test=0.564), diff=0.00000124, proc(train=36.206sec, eval=53.215sec)
[2022-11-02 14:48:32,281 {dist_trainer.py:770}] <INFO> [  42/ 200] connecting edge count: 2
[2022-11-02 14:49:23,281 {dist_trainer.py:821}] <INFO> [  42/ 200] loss: (train=1.163, val=1.145, test=1.232, l2=10128.136), acc: (train=0.661, val=0.598, test=0.579), diff=0.00000115, proc(train=36.704sec, eval=49.377sec)
[2022-11-02 14:50:00,340 {dist_trainer.py:770}] <INFO> [  43/ 200] connecting edge count: 2
[2022-11-02 14:50:49,044 {dist_trainer.py:821}] <INFO> [  43/ 200] loss: (train=1.140, val=1.163, test=1.241, l2=10083.417), acc: (train=0.661, val=0.585, test=0.564), diff=0.00000129, proc(train=37.059sec, eval=47.151sec)
[2022-11-02 14:51:26,880 {dist_trainer.py:770}] <INFO> [  44/ 200] connecting edge count: 2
[2022-11-02 14:52:21,619 {dist_trainer.py:821}] <INFO> [  44/ 200] loss: (train=1.149, val=1.103, test=1.185, l2=10043.672), acc: (train=0.663, val=0.610, test=0.584), diff=0.00000156, proc(train=37.836sec, eval=53.170sec)
[2022-11-02 14:53:00,770 {dist_trainer.py:770}] <INFO> [  45/ 200] connecting edge count: 2
[2022-11-02 14:53:48,750 {dist_trainer.py:821}] <INFO> [  45/ 200] loss: (train=1.117, val=1.100, test=1.191, l2=10004.599), acc: (train=0.680, val=0.613, test=0.594), diff=0.00000137, proc(train=39.150sec, eval=46.648sec)
[2022-11-02 14:54:25,839 {dist_trainer.py:770}] <INFO> [  46/ 200] connecting edge count: 2
[2022-11-02 14:55:19,039 {dist_trainer.py:821}] <INFO> [  46/ 200] loss: (train=1.098, val=1.208, test=1.284, l2=9955.973), acc: (train=0.636, val=0.581, test=0.557), diff=0.00000107, proc(train=37.088sec, eval=51.524sec)
[2022-11-02 14:55:58,207 {dist_trainer.py:770}] <INFO> [  47/ 200] connecting edge count: 2
[2022-11-02 14:56:49,136 {dist_trainer.py:821}] <INFO> [  47/ 200] loss: (train=1.070, val=1.184, test=1.279, l2=9913.221), acc: (train=0.711, val=0.596, test=0.567), diff=0.00000135, proc(train=39.168sec, eval=49.405sec)
[2022-11-02 14:57:26,837 {dist_trainer.py:770}] <INFO> [  48/ 200] connecting edge count: 2
[2022-11-02 14:58:14,069 {dist_trainer.py:821}] <INFO> [  48/ 200] loss: (train=1.096, val=1.088, test=1.182, l2=9861.889), acc: (train=0.680, val=0.616, test=0.587), diff=0.00000131, proc(train=37.700sec, eval=45.632sec)
[2022-11-02 14:58:50,530 {dist_trainer.py:770}] <INFO> [  49/ 200] connecting edge count: 2
[2022-11-02 14:59:46,945 {dist_trainer.py:821}] <INFO> [  49/ 200] loss: (train=1.096, val=1.024, test=1.122, l2=9821.376), acc: (train=0.684, val=0.640, test=0.611), diff=0.00000177, proc(train=36.461sec, eval=54.613sec)
[2022-11-02 15:00:23,071 {dist_trainer.py:770}] <INFO> [  50/ 200] connecting edge count: 2
[2022-11-02 15:01:11,144 {dist_trainer.py:821}] <INFO> [  50/ 200] loss: (train=1.062, val=1.109, test=1.218, l2=9777.526), acc: (train=0.683, val=0.612, test=0.582), diff=0.00000148, proc(train=36.126sec, eval=46.779sec)
[2022-11-02 15:01:48,926 {dist_trainer.py:770}] <INFO> [  51/ 200] connecting edge count: 2
[2022-11-02 15:02:41,547 {dist_trainer.py:821}] <INFO> [  51/ 200] loss: (train=1.094, val=1.019, test=1.124, l2=9727.591), acc: (train=0.685, val=0.642, test=0.607), diff=0.00000115, proc(train=37.781sec, eval=50.931sec)
[2022-11-02 15:03:17,421 {dist_trainer.py:770}] <INFO> [  52/ 200] connecting edge count: 2
[2022-11-02 15:04:11,253 {dist_trainer.py:821}] <INFO> [  52/ 200] loss: (train=1.048, val=1.020, test=1.134, l2=9687.046), acc: (train=0.691, val=0.647, test=0.613), diff=0.00000118, proc(train=35.874sec, eval=52.562sec)
[2022-11-02 15:04:49,122 {dist_trainer.py:770}] <INFO> [  53/ 200] connecting edge count: 2
[2022-11-02 15:05:35,551 {dist_trainer.py:821}] <INFO> [  53/ 200] loss: (train=1.046, val=1.089, test=1.202, l2=9649.476), acc: (train=0.653, val=0.625, test=0.590), diff=0.00000149, proc(train=37.869sec, eval=45.171sec)
[2022-11-02 15:06:13,061 {dist_trainer.py:770}] <INFO> [  54/ 200] connecting edge count: 2
[2022-11-02 15:07:06,300 {dist_trainer.py:821}] <INFO> [  54/ 200] loss: (train=1.042, val=1.019, test=1.135, l2=9601.072), acc: (train=0.630, val=0.646, test=0.611), diff=0.00000114, proc(train=37.510sec, eval=51.400sec)
[2022-11-02 15:07:42,492 {dist_trainer.py:770}] <INFO> [  55/ 200] connecting edge count: 2
[2022-11-02 15:08:34,982 {dist_trainer.py:821}] <INFO> [  55/ 200] loss: (train=1.059, val=0.981, test=1.097, l2=9561.109), acc: (train=0.696, val=0.659, test=0.623), diff=0.00000137, proc(train=36.192sec, eval=51.362sec)
[2022-11-02 15:09:12,902 {dist_trainer.py:770}] <INFO> [  56/ 200] connecting edge count: 2
[2022-11-02 15:10:00,369 {dist_trainer.py:821}] <INFO> [  56/ 200] loss: (train=1.025, val=1.147, test=1.272, l2=9516.217), acc: (train=0.658, val=0.617, test=0.584), diff=0.00000095, proc(train=37.920sec, eval=45.762sec)
[2022-11-02 15:10:35,460 {dist_trainer.py:770}] <INFO> [  57/ 200] connecting edge count: 2
[2022-11-02 15:11:29,160 {dist_trainer.py:821}] <INFO> [  57/ 200] loss: (train=1.039, val=1.088, test=1.209, l2=9471.573), acc: (train=0.696, val=0.615, test=0.576), diff=0.00000136, proc(train=35.091sec, eval=52.012sec)
[2022-11-02 15:12:07,040 {dist_trainer.py:770}] <INFO> [  58/ 200] connecting edge count: 2
[2022-11-02 15:12:56,927 {dist_trainer.py:821}] <INFO> [  58/ 200] loss: (train=1.013, val=0.952, test=1.080, l2=9436.704), acc: (train=0.694, val=0.667, test=0.626), diff=0.00000140, proc(train=37.879sec, eval=48.773sec)
[2022-11-02 15:13:34,633 {dist_trainer.py:770}] <INFO> [  59/ 200] connecting edge count: 2
[2022-11-02 15:14:21,739 {dist_trainer.py:821}] <INFO> [  59/ 200] loss: (train=0.957, val=0.966, test=1.109, l2=9386.899), acc: (train=0.722, val=0.666, test=0.626), diff=0.00000092, proc(train=37.706sec, eval=45.701sec)
[2022-11-02 15:14:57,632 {dist_trainer.py:770}] <INFO> [  60/ 200] connecting edge count: 2
[2022-11-02 15:15:52,285 {dist_trainer.py:821}] <INFO> [  60/ 200] loss: (train=0.937, val=1.017, test=1.139, l2=9352.448), acc: (train=0.737, val=0.647, test=0.610), diff=0.00000174, proc(train=35.892sec, eval=53.007sec)
[2022-11-02 15:16:29,774 {dist_trainer.py:770}] <INFO> [  61/ 200] connecting edge count: 2
[2022-11-02 15:17:17,781 {dist_trainer.py:821}] <INFO> [  61/ 200] loss: (train=1.002, val=0.887, test=1.029, l2=9314.456), acc: (train=0.710, val=0.692, test=0.650), diff=0.00000138, proc(train=37.489sec, eval=46.697sec)
[2022-11-02 15:17:55,393 {dist_trainer.py:770}] <INFO> [  62/ 200] connecting edge count: 2
[2022-11-02 15:18:45,302 {dist_trainer.py:821}] <INFO> [  62/ 200] loss: (train=1.020, val=1.015, test=1.145, l2=9264.270), acc: (train=0.680, val=0.646, test=0.610), diff=0.00000097, proc(train=37.612sec, eval=48.074sec)
[2022-11-02 15:19:22,907 {dist_trainer.py:770}] <INFO> [  63/ 200] connecting edge count: 2
[2022-11-02 15:20:15,667 {dist_trainer.py:821}] <INFO> [  63/ 200] loss: (train=1.017, val=0.897, test=1.054, l2=9226.337), acc: (train=0.722, val=0.688, test=0.646), diff=0.00000146, proc(train=37.605sec, eval=51.587sec)
[2022-11-02 15:20:53,673 {dist_trainer.py:770}] <INFO> [  64/ 200] connecting edge count: 2
[2022-11-02 15:21:40,937 {dist_trainer.py:821}] <INFO> [  64/ 200] loss: (train=1.007, val=0.979, test=1.123, l2=9190.439), acc: (train=0.695, val=0.667, test=0.629), diff=0.00000135, proc(train=38.005sec, eval=45.897sec)
[2022-11-02 15:22:17,516 {dist_trainer.py:770}] <INFO> [  65/ 200] connecting edge count: 2
[2022-11-02 15:23:11,417 {dist_trainer.py:821}] <INFO> [  65/ 200] loss: (train=0.973, val=0.940, test=1.094, l2=9146.848), acc: (train=0.726, val=0.667, test=0.622), diff=0.00000119, proc(train=36.578sec, eval=52.328sec)
[2022-11-02 15:23:47,669 {dist_trainer.py:770}] <INFO> [  66/ 200] connecting edge count: 2
[2022-11-02 15:24:38,474 {dist_trainer.py:821}] <INFO> [  66/ 200] loss: (train=0.986, val=0.913, test=1.067, l2=9108.638), acc: (train=0.718, val=0.682, test=0.638), diff=0.00000122, proc(train=36.252sec, eval=49.295sec)
[2022-11-02 15:25:16,779 {dist_trainer.py:770}] <INFO> [  67/ 200] connecting edge count: 2
[2022-11-02 15:26:04,576 {dist_trainer.py:821}] <INFO> [  67/ 200] loss: (train=0.933, val=0.896, test=1.056, l2=9061.195), acc: (train=0.709, val=0.690, test=0.643), diff=0.00000129, proc(train=38.304sec, eval=46.030sec)
[2022-11-02 15:26:40,715 {dist_trainer.py:770}] <INFO> [  68/ 200] connecting edge count: 2
[2022-11-02 15:27:35,370 {dist_trainer.py:821}] <INFO> [  68/ 200] loss: (train=0.953, val=0.938, test=1.095, l2=9029.307), acc: (train=0.724, val=0.675, test=0.629), diff=0.00000131, proc(train=36.139sec, eval=52.896sec)
[2022-11-02 15:28:13,011 {dist_trainer.py:770}] <INFO> [  69/ 200] connecting edge count: 2
[2022-11-02 15:28:59,986 {dist_trainer.py:821}] <INFO> [  69/ 200] loss: (train=0.926, val=0.872, test=1.042, l2=8997.842), acc: (train=0.732, val=0.696, test=0.643), diff=0.00000136, proc(train=37.640sec, eval=45.752sec)
[2022-11-02 15:29:37,924 {dist_trainer.py:770}] <INFO> [  70/ 200] connecting edge count: 2
[2022-11-02 15:30:29,477 {dist_trainer.py:821}] <INFO> [  70/ 200] loss: (train=0.928, val=0.875, test=1.038, l2=8952.101), acc: (train=0.733, val=0.695, test=0.646), diff=0.00000087, proc(train=37.937sec, eval=49.532sec)
[2022-11-02 15:31:05,494 {dist_trainer.py:770}] <INFO> [  71/ 200] connecting edge count: 2
[2022-11-02 15:31:58,817 {dist_trainer.py:821}] <INFO> [  71/ 200] loss: (train=0.923, val=0.821, test=1.003, l2=8915.539), acc: (train=0.746, val=0.716, test=0.661), diff=0.00000115, proc(train=36.016sec, eval=51.756sec)
[2022-11-02 15:32:36,098 {dist_trainer.py:770}] <INFO> [  72/ 200] connecting edge count: 2
[2022-11-02 15:33:22,042 {dist_trainer.py:821}] <INFO> [  72/ 200] loss: (train=0.878, val=0.823, test=1.003, l2=8882.131), acc: (train=0.738, val=0.715, test=0.660), diff=0.00000115, proc(train=37.281sec, eval=44.692sec)
[2022-11-02 15:33:58,561 {dist_trainer.py:770}] <INFO> [  73/ 200] connecting edge count: 2
[2022-11-02 15:34:47,975 {dist_trainer.py:821}] <INFO> [  73/ 200] loss: (train=0.908, val=0.892, test=1.057, l2=8841.554), acc: (train=0.711, val=0.688, test=0.637), diff=0.00000094, proc(train=36.519sec, eval=47.664sec)
[2022-11-02 15:35:23,523 {dist_trainer.py:770}] <INFO> [  74/ 200] connecting edge count: 2
[2022-11-02 15:36:16,577 {dist_trainer.py:821}] <INFO> [  74/ 200] loss: (train=0.889, val=0.999, test=1.180, l2=8804.288), acc: (train=0.741, val=0.659, test=0.616), diff=0.00000243, proc(train=35.548sec, eval=51.472sec)
[2022-11-02 15:36:53,083 {dist_trainer.py:770}] <INFO> [  75/ 200] connecting edge count: 2
[2022-11-02 15:37:48,825 {dist_trainer.py:821}] <INFO> [  75/ 200] loss: (train=0.850, val=0.819, test=1.008, l2=8763.139), acc: (train=0.764, val=0.717, test=0.656), diff=0.00000152, proc(train=36.505sec, eval=54.370sec)
[2022-11-02 15:38:30,358 {dist_trainer.py:770}] <INFO> [  76/ 200] connecting edge count: 2
[2022-11-02 15:39:24,080 {dist_trainer.py:821}] <INFO> [  76/ 200] loss: (train=0.843, val=0.909, test=1.106, l2=8719.172), acc: (train=0.737, val=0.690, test=0.642), diff=0.00000165, proc(train=41.532sec, eval=51.930sec)
[2022-11-02 15:40:04,959 {dist_trainer.py:770}] <INFO> [  77/ 200] connecting edge count: 2
[2022-11-02 15:41:05,029 {dist_trainer.py:821}] <INFO> [  77/ 200] loss: (train=0.874, val=0.832, test=1.021, l2=8683.863), acc: (train=0.743, val=0.711, test=0.653), diff=0.00000114, proc(train=40.879sec, eval=58.055sec)
[2022-11-02 15:41:46,606 {dist_trainer.py:770}] <INFO> [  78/ 200] connecting edge count: 2
[2022-11-02 15:42:41,777 {dist_trainer.py:821}] <INFO> [  78/ 200] loss: (train=0.846, val=0.795, test=1.008, l2=8648.354), acc: (train=0.756, val=0.726, test=0.662), diff=0.00000114, proc(train=41.577sec, eval=53.475sec)
[2022-11-02 15:43:23,271 {dist_trainer.py:770}] <INFO> [  79/ 200] connecting edge count: 2
[2022-11-02 15:44:19,444 {dist_trainer.py:821}] <INFO> [  79/ 200] loss: (train=0.815, val=0.797, test=0.997, l2=8610.996), acc: (train=0.756, val=0.727, test=0.661), diff=0.00000105, proc(train=41.494sec, eval=54.412sec)
[2022-11-02 15:45:01,182 {dist_trainer.py:770}] <INFO> [  80/ 200] connecting edge count: 2
[2022-11-02 15:46:00,334 {dist_trainer.py:821}] <INFO> [  80/ 200] loss: (train=0.851, val=0.819, test=1.031, l2=8572.483), acc: (train=0.769, val=0.714, test=0.652), diff=0.00000113, proc(train=41.738sec, eval=57.551sec)
[2022-11-02 15:46:41,352 {dist_trainer.py:770}] <INFO> [  81/ 200] connecting edge count: 2
[2022-11-02 15:47:40,337 {dist_trainer.py:821}] <INFO> [  81/ 200] loss: (train=0.822, val=0.827, test=1.029, l2=8537.045), acc: (train=0.767, val=0.714, test=0.651), diff=0.00000128, proc(train=41.017sec, eval=56.937sec)
[2022-11-02 15:48:22,758 {dist_trainer.py:770}] <INFO> [  82/ 200] connecting edge count: 2
[2022-11-02 15:49:21,395 {dist_trainer.py:821}] <INFO> [  82/ 200] loss: (train=0.808, val=0.844, test=1.056, l2=8500.246), acc: (train=0.782, val=0.705, test=0.643), diff=0.00000098, proc(train=42.421sec, eval=56.948sec)
[2022-11-02 15:50:04,965 {dist_trainer.py:770}] <INFO> [  83/ 200] connecting edge count: 2
[2022-11-02 15:51:04,658 {dist_trainer.py:821}] <INFO> [  83/ 200] loss: (train=0.816, val=0.819, test=1.026, l2=8463.064), acc: (train=0.732, val=0.716, test=0.656), diff=0.00000134, proc(train=43.570sec, eval=57.767sec)
[2022-11-02 15:51:47,700 {dist_trainer.py:770}] <INFO> [  84/ 200] connecting edge count: 2
[2022-11-02 15:52:43,618 {dist_trainer.py:821}] <INFO> [  84/ 200] loss: (train=0.802, val=0.803, test=1.036, l2=8427.519), acc: (train=0.781, val=0.723, test=0.653), diff=0.00000123, proc(train=43.042sec, eval=45.234sec)
[2022-11-02 15:52:44,192 {contract.py:84}] <INFO>  => node2 : edge disconnect.
[2022-11-02 15:53:12,549 {dist_trainer.py:770}] <INFO> [  85/ 200] connecting edge count: 1
[2022-11-02 15:53:56,603 {dist_trainer.py:821}] <INFO> [  85/ 200] loss: (train=1.776, val=1.225, test=1.278, l2=3653.852), acc: (train=0.641, val=0.562, test=0.547), diff=0.00000532, proc(train=28.931sec, eval=34.021sec)
[2022-11-02 15:53:56,603 {dist_trainer.py:836}] <INFO> [  85/ 200] found edge disconnection: 2 -> 1. finished train.
[2022-11-02 15:54:32,748 {dist_trainer.py:899}] <INFO> [EVAL] loss: (train=1.108, val=1.225, test=1.278, l2=3652.659), acc: (train=0.637, val=0.562, test=0.547), proc=36.143sec
[2022-11-02 15:54:32,851 {dist_trainer.py:380}] <INFO> GC: check garbage []
[2022-11-02 15:54:33,144 {main.py:231}] <INFO> GC: check garbage []
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
