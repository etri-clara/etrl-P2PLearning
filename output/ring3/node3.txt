[2022-11-02 16:28:57,796 {main.py:127}] <INFO> Namespace(datadir='./data', outdir='./output/ring3', epochs=200, batch_size=100, seed=569, data_init_seed=11, model_init_seed=13, l2_lambda=0.01, model_name='resnet50', dataset_name='cifar10', train_data_length=10000, group_channels=32, drop_rate=0.1, last_drop_rate=0.5, cuda=True, cuda_device_no=3, plot=False, scheduler='StepLR', step_size=410, gamma=0.9, sleep_factor=0.0, loglevel=<LogLevel.INFO: 20>, logfile=None, optimizer='PdmmISVR', nodename='node2', conf='./conf/node_list.json', host='./conf/hosts.json', lr=0.002, use_gcoef=False, piw=1.0, round_step=False, swap_timeout=10)
[2022-11-02 16:28:57,796 {main.py:193}] <INFO> {'nodes': {'node0': {'device': 'cuda', 'round': 10, 'edges': {'node2': 0, 'node1': 4}}, 'node1': {'device': 'cuda', 'round': 10, 'edges': {'node0': 1, 'node2': 5}}, 'node2': {'device': 'cuda', 'round': 10, 'edges': {'node1': 2, 'node0': 6}}}}
[2022-11-02 16:28:57,924 {dist_trainer.py:186}] <INFO> : <class 'model.resnet.ResNet'>
[2022-11-02 16:28:57,925 {dist_trainer.py:186}] <INFO> conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,925 {dist_trainer.py:183}] <INFO> bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-02 16:28:57,925 {dist_trainer.py:186}] <INFO> relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,925 {dist_trainer.py:186}] <INFO> maxpool: <class 'torch.nn.modules.pooling.MaxPool2d'>
[2022-11-02 16:28:57,925 {dist_trainer.py:186}] <INFO> dropout1: <class 'torch.nn.modules.dropout.Dropout2d'>
[2022-11-02 16:28:57,925 {dist_trainer.py:186}] <INFO> layer1: <class 'torch.nn.modules.container.Sequential'>
[2022-11-02 16:28:57,925 {dist_trainer.py:186}] <INFO> layer1.0: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,925 {dist_trainer.py:186}] <INFO> layer1.0.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,925 {dist_trainer.py:183}] <INFO> layer1.0.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-02 16:28:57,925 {dist_trainer.py:186}] <INFO> layer1.0.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,925 {dist_trainer.py:183}] <INFO> layer1.0.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-02 16:28:57,925 {dist_trainer.py:186}] <INFO> layer1.0.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,925 {dist_trainer.py:183}] <INFO> layer1.0.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,925 {dist_trainer.py:186}] <INFO> layer1.0.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,925 {dist_trainer.py:186}] <INFO> layer1.0.downsample: <class 'torch.nn.modules.container.Sequential'>
[2022-11-02 16:28:57,925 {dist_trainer.py:186}] <INFO> layer1.0.downsample.0: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,925 {dist_trainer.py:183}] <INFO> layer1.0.downsample.1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,925 {dist_trainer.py:186}] <INFO> layer1.1: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,925 {dist_trainer.py:186}] <INFO> layer1.1.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,925 {dist_trainer.py:183}] <INFO> layer1.1.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-02 16:28:57,925 {dist_trainer.py:186}] <INFO> layer1.1.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,925 {dist_trainer.py:183}] <INFO> layer1.1.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-02 16:28:57,925 {dist_trainer.py:186}] <INFO> layer1.1.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,925 {dist_trainer.py:183}] <INFO> layer1.1.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,925 {dist_trainer.py:186}] <INFO> layer1.1.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,925 {dist_trainer.py:186}] <INFO> layer1.2: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,925 {dist_trainer.py:186}] <INFO> layer1.2.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,925 {dist_trainer.py:183}] <INFO> layer1.2.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-02 16:28:57,925 {dist_trainer.py:186}] <INFO> layer1.2.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,925 {dist_trainer.py:183}] <INFO> layer1.2.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-02 16:28:57,925 {dist_trainer.py:186}] <INFO> layer1.2.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,925 {dist_trainer.py:183}] <INFO> layer1.2.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,925 {dist_trainer.py:186}] <INFO> layer1.2.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,925 {dist_trainer.py:186}] <INFO> layer1.3: <class 'torch.nn.modules.dropout.Dropout2d'>
[2022-11-02 16:28:57,925 {dist_trainer.py:186}] <INFO> layer2: <class 'torch.nn.modules.container.Sequential'>
[2022-11-02 16:28:57,925 {dist_trainer.py:186}] <INFO> layer2.0: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,925 {dist_trainer.py:186}] <INFO> layer2.0.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,925 {dist_trainer.py:183}] <INFO> layer2.0.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-02 16:28:57,925 {dist_trainer.py:186}] <INFO> layer2.0.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,925 {dist_trainer.py:183}] <INFO> layer2.0.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-02 16:28:57,926 {dist_trainer.py:186}] <INFO> layer2.0.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,926 {dist_trainer.py:183}] <INFO> layer2.0.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 16:28:57,926 {dist_trainer.py:186}] <INFO> layer2.0.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,926 {dist_trainer.py:186}] <INFO> layer2.0.downsample: <class 'torch.nn.modules.container.Sequential'>
[2022-11-02 16:28:57,926 {dist_trainer.py:186}] <INFO> layer2.0.downsample.0: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,926 {dist_trainer.py:183}] <INFO> layer2.0.downsample.1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 16:28:57,926 {dist_trainer.py:186}] <INFO> layer2.1: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,926 {dist_trainer.py:186}] <INFO> layer2.1.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,926 {dist_trainer.py:183}] <INFO> layer2.1.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-02 16:28:57,926 {dist_trainer.py:186}] <INFO> layer2.1.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,926 {dist_trainer.py:183}] <INFO> layer2.1.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-02 16:28:57,926 {dist_trainer.py:186}] <INFO> layer2.1.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,926 {dist_trainer.py:183}] <INFO> layer2.1.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 16:28:57,926 {dist_trainer.py:186}] <INFO> layer2.1.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,926 {dist_trainer.py:186}] <INFO> layer2.2: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,926 {dist_trainer.py:186}] <INFO> layer2.2.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,926 {dist_trainer.py:183}] <INFO> layer2.2.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-02 16:28:57,926 {dist_trainer.py:186}] <INFO> layer2.2.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,926 {dist_trainer.py:183}] <INFO> layer2.2.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-02 16:28:57,926 {dist_trainer.py:186}] <INFO> layer2.2.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,926 {dist_trainer.py:183}] <INFO> layer2.2.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 16:28:57,926 {dist_trainer.py:186}] <INFO> layer2.2.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,926 {dist_trainer.py:186}] <INFO> layer2.3: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,926 {dist_trainer.py:186}] <INFO> layer2.3.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,926 {dist_trainer.py:183}] <INFO> layer2.3.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-02 16:28:57,926 {dist_trainer.py:186}] <INFO> layer2.3.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,926 {dist_trainer.py:183}] <INFO> layer2.3.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-02 16:28:57,926 {dist_trainer.py:186}] <INFO> layer2.3.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,926 {dist_trainer.py:183}] <INFO> layer2.3.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 16:28:57,926 {dist_trainer.py:186}] <INFO> layer2.3.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,926 {dist_trainer.py:186}] <INFO> layer2.4: <class 'torch.nn.modules.dropout.Dropout2d'>
[2022-11-02 16:28:57,926 {dist_trainer.py:186}] <INFO> layer3: <class 'torch.nn.modules.container.Sequential'>
[2022-11-02 16:28:57,926 {dist_trainer.py:186}] <INFO> layer3.0: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,926 {dist_trainer.py:186}] <INFO> layer3.0.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,926 {dist_trainer.py:183}] <INFO> layer3.0.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,926 {dist_trainer.py:186}] <INFO> layer3.0.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,926 {dist_trainer.py:183}] <INFO> layer3.0.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,926 {dist_trainer.py:186}] <INFO> layer3.0.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,926 {dist_trainer.py:183}] <INFO> layer3.0.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-02 16:28:57,926 {dist_trainer.py:186}] <INFO> layer3.0.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,926 {dist_trainer.py:186}] <INFO> layer3.0.downsample: <class 'torch.nn.modules.container.Sequential'>
[2022-11-02 16:28:57,926 {dist_trainer.py:186}] <INFO> layer3.0.downsample.0: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,927 {dist_trainer.py:183}] <INFO> layer3.0.downsample.1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-02 16:28:57,927 {dist_trainer.py:186}] <INFO> layer3.1: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,927 {dist_trainer.py:186}] <INFO> layer3.1.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,927 {dist_trainer.py:183}] <INFO> layer3.1.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,927 {dist_trainer.py:186}] <INFO> layer3.1.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,927 {dist_trainer.py:183}] <INFO> layer3.1.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,927 {dist_trainer.py:186}] <INFO> layer3.1.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,927 {dist_trainer.py:183}] <INFO> layer3.1.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-02 16:28:57,927 {dist_trainer.py:186}] <INFO> layer3.1.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,927 {dist_trainer.py:186}] <INFO> layer3.2: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,927 {dist_trainer.py:186}] <INFO> layer3.2.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,927 {dist_trainer.py:183}] <INFO> layer3.2.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,927 {dist_trainer.py:186}] <INFO> layer3.2.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,927 {dist_trainer.py:183}] <INFO> layer3.2.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,927 {dist_trainer.py:186}] <INFO> layer3.2.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,927 {dist_trainer.py:183}] <INFO> layer3.2.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-02 16:28:57,927 {dist_trainer.py:186}] <INFO> layer3.2.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,927 {dist_trainer.py:186}] <INFO> layer3.3: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,927 {dist_trainer.py:186}] <INFO> layer3.3.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,927 {dist_trainer.py:183}] <INFO> layer3.3.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,927 {dist_trainer.py:186}] <INFO> layer3.3.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,927 {dist_trainer.py:183}] <INFO> layer3.3.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,927 {dist_trainer.py:186}] <INFO> layer3.3.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,927 {dist_trainer.py:183}] <INFO> layer3.3.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-02 16:28:57,927 {dist_trainer.py:186}] <INFO> layer3.3.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,927 {dist_trainer.py:186}] <INFO> layer3.4: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,927 {dist_trainer.py:186}] <INFO> layer3.4.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,927 {dist_trainer.py:183}] <INFO> layer3.4.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,927 {dist_trainer.py:186}] <INFO> layer3.4.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,927 {dist_trainer.py:183}] <INFO> layer3.4.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,927 {dist_trainer.py:186}] <INFO> layer3.4.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,927 {dist_trainer.py:183}] <INFO> layer3.4.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-02 16:28:57,927 {dist_trainer.py:186}] <INFO> layer3.4.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,927 {dist_trainer.py:186}] <INFO> layer3.5: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,927 {dist_trainer.py:186}] <INFO> layer3.5.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,927 {dist_trainer.py:183}] <INFO> layer3.5.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,927 {dist_trainer.py:186}] <INFO> layer3.5.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,927 {dist_trainer.py:183}] <INFO> layer3.5.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,927 {dist_trainer.py:186}] <INFO> layer3.5.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,927 {dist_trainer.py:183}] <INFO> layer3.5.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-02 16:28:57,927 {dist_trainer.py:186}] <INFO> layer3.5.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,927 {dist_trainer.py:186}] <INFO> layer3.6: <class 'torch.nn.modules.dropout.Dropout2d'>
[2022-11-02 16:28:57,927 {dist_trainer.py:186}] <INFO> layer4: <class 'torch.nn.modules.container.Sequential'>
[2022-11-02 16:28:57,927 {dist_trainer.py:186}] <INFO> layer4.0: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,928 {dist_trainer.py:186}] <INFO> layer4.0.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,928 {dist_trainer.py:183}] <INFO> layer4.0.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 16:28:57,928 {dist_trainer.py:186}] <INFO> layer4.0.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,928 {dist_trainer.py:183}] <INFO> layer4.0.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 16:28:57,928 {dist_trainer.py:186}] <INFO> layer4.0.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,928 {dist_trainer.py:183}] <INFO> layer4.0.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 64, channels: 2048, eps: 0.000010, affine: True
[2022-11-02 16:28:57,928 {dist_trainer.py:186}] <INFO> layer4.0.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,928 {dist_trainer.py:186}] <INFO> layer4.0.downsample: <class 'torch.nn.modules.container.Sequential'>
[2022-11-02 16:28:57,928 {dist_trainer.py:186}] <INFO> layer4.0.downsample.0: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,928 {dist_trainer.py:183}] <INFO> layer4.0.downsample.1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 64, channels: 2048, eps: 0.000010, affine: True
[2022-11-02 16:28:57,928 {dist_trainer.py:186}] <INFO> layer4.1: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,928 {dist_trainer.py:186}] <INFO> layer4.1.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,928 {dist_trainer.py:183}] <INFO> layer4.1.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 16:28:57,928 {dist_trainer.py:186}] <INFO> layer4.1.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,928 {dist_trainer.py:183}] <INFO> layer4.1.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 16:28:57,928 {dist_trainer.py:186}] <INFO> layer4.1.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,928 {dist_trainer.py:183}] <INFO> layer4.1.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 64, channels: 2048, eps: 0.000010, affine: True
[2022-11-02 16:28:57,928 {dist_trainer.py:186}] <INFO> layer4.1.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,928 {dist_trainer.py:186}] <INFO> layer4.2: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,928 {dist_trainer.py:186}] <INFO> layer4.2.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,928 {dist_trainer.py:183}] <INFO> layer4.2.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 16:28:57,928 {dist_trainer.py:186}] <INFO> layer4.2.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,928 {dist_trainer.py:183}] <INFO> layer4.2.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 16:28:57,928 {dist_trainer.py:186}] <INFO> layer4.2.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,928 {dist_trainer.py:183}] <INFO> layer4.2.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 64, channels: 2048, eps: 0.000010, affine: True
[2022-11-02 16:28:57,928 {dist_trainer.py:186}] <INFO> layer4.2.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,928 {dist_trainer.py:186}] <INFO> avgpool: <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>
[2022-11-02 16:28:57,928 {dist_trainer.py:186}] <INFO> dropout_fc: <class 'torch.nn.modules.dropout.Dropout'>
[2022-11-02 16:28:57,928 {dist_trainer.py:186}] <INFO> fc: <class 'torch.nn.modules.linear.Linear'>
[2022-11-02 16:28:57,928 {dist_trainer.py:192}] <INFO> parameter size: conv1.weight 37632B
[2022-11-02 16:28:57,928 {dist_trainer.py:192}] <INFO> parameter size: bn1.weight 256B
[2022-11-02 16:28:57,928 {dist_trainer.py:192}] <INFO> parameter size: bn1.bias 256B
[2022-11-02 16:28:57,928 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.conv1.weight 16384B
[2022-11-02 16:28:57,928 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.bn1.weight 256B
[2022-11-02 16:28:57,929 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.bn1.bias 256B
[2022-11-02 16:28:57,929 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.conv2.weight 147456B
[2022-11-02 16:28:57,929 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.bn2.weight 256B
[2022-11-02 16:28:57,929 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.bn2.bias 256B
[2022-11-02 16:28:57,929 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.conv3.weight 65536B
[2022-11-02 16:28:57,929 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.bn3.weight 1024B
[2022-11-02 16:28:57,929 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.bn3.bias 1024B
[2022-11-02 16:28:57,929 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.downsample.0.weight 65536B
[2022-11-02 16:28:57,929 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.downsample.1.weight 1024B
[2022-11-02 16:28:57,929 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.downsample.1.bias 1024B
[2022-11-02 16:28:57,929 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.conv1.weight 65536B
[2022-11-02 16:28:57,929 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.bn1.weight 256B
[2022-11-02 16:28:57,929 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.bn1.bias 256B
[2022-11-02 16:28:57,929 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.conv2.weight 147456B
[2022-11-02 16:28:57,929 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.bn2.weight 256B
[2022-11-02 16:28:57,929 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.bn2.bias 256B
[2022-11-02 16:28:57,929 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.conv3.weight 65536B
[2022-11-02 16:28:57,929 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.bn3.weight 1024B
[2022-11-02 16:28:57,929 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.bn3.bias 1024B
[2022-11-02 16:28:57,929 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.conv1.weight 65536B
[2022-11-02 16:28:57,929 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.bn1.weight 256B
[2022-11-02 16:28:57,929 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.bn1.bias 256B
[2022-11-02 16:28:57,929 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.conv2.weight 147456B
[2022-11-02 16:28:57,929 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.bn2.weight 256B
[2022-11-02 16:28:57,929 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.bn2.bias 256B
[2022-11-02 16:28:57,930 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.conv3.weight 65536B
[2022-11-02 16:28:57,930 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.bn3.weight 1024B
[2022-11-02 16:28:57,930 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.bn3.bias 1024B
[2022-11-02 16:28:57,930 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.conv1.weight 131072B
[2022-11-02 16:28:57,930 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.bn1.weight 512B
[2022-11-02 16:28:57,930 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.bn1.bias 512B
[2022-11-02 16:28:57,930 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.conv2.weight 589824B
[2022-11-02 16:28:57,930 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.bn2.weight 512B
[2022-11-02 16:28:57,930 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.bn2.bias 512B
[2022-11-02 16:28:57,930 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.conv3.weight 262144B
[2022-11-02 16:28:57,930 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.bn3.weight 2048B
[2022-11-02 16:28:57,930 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.bn3.bias 2048B
[2022-11-02 16:28:57,930 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.downsample.0.weight 524288B
[2022-11-02 16:28:57,930 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.downsample.1.weight 2048B
[2022-11-02 16:28:57,930 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.downsample.1.bias 2048B
[2022-11-02 16:28:57,930 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.conv1.weight 262144B
[2022-11-02 16:28:57,930 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.bn1.weight 512B
[2022-11-02 16:28:57,930 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.bn1.bias 512B
[2022-11-02 16:28:57,930 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.conv2.weight 589824B
[2022-11-02 16:28:57,930 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.bn2.weight 512B
[2022-11-02 16:28:57,930 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.bn2.bias 512B
[2022-11-02 16:28:57,930 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.conv3.weight 262144B
[2022-11-02 16:28:57,930 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.bn3.weight 2048B
[2022-11-02 16:28:57,930 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.bn3.bias 2048B
[2022-11-02 16:28:57,930 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.conv1.weight 262144B
[2022-11-02 16:28:57,931 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.bn1.weight 512B
[2022-11-02 16:28:57,931 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.bn1.bias 512B
[2022-11-02 16:28:57,931 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.conv2.weight 589824B
[2022-11-02 16:28:57,931 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.bn2.weight 512B
[2022-11-02 16:28:57,931 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.bn2.bias 512B
[2022-11-02 16:28:57,931 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.conv3.weight 262144B
[2022-11-02 16:28:57,931 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.bn3.weight 2048B
[2022-11-02 16:28:57,931 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.bn3.bias 2048B
[2022-11-02 16:28:57,931 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.conv1.weight 262144B
[2022-11-02 16:28:57,931 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.bn1.weight 512B
[2022-11-02 16:28:57,931 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.bn1.bias 512B
[2022-11-02 16:28:57,931 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.conv2.weight 589824B
[2022-11-02 16:28:57,931 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.bn2.weight 512B
[2022-11-02 16:28:57,931 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.bn2.bias 512B
[2022-11-02 16:28:57,931 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.conv3.weight 262144B
[2022-11-02 16:28:57,931 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.bn3.weight 2048B
[2022-11-02 16:28:57,931 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.bn3.bias 2048B
[2022-11-02 16:28:57,931 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.conv1.weight 524288B
[2022-11-02 16:28:57,931 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.bn1.weight 1024B
[2022-11-02 16:28:57,931 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.bn1.bias 1024B
[2022-11-02 16:28:57,931 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.conv2.weight 2359296B
[2022-11-02 16:28:57,931 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.bn2.weight 1024B
[2022-11-02 16:28:57,931 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.bn2.bias 1024B
[2022-11-02 16:28:57,931 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.conv3.weight 1048576B
[2022-11-02 16:28:57,932 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.bn3.weight 4096B
[2022-11-02 16:28:57,932 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.bn3.bias 4096B
[2022-11-02 16:28:57,932 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.downsample.0.weight 2097152B
[2022-11-02 16:28:57,932 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.downsample.1.weight 4096B
[2022-11-02 16:28:57,932 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.downsample.1.bias 4096B
[2022-11-02 16:28:57,932 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.conv1.weight 1048576B
[2022-11-02 16:28:57,932 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.bn1.weight 1024B
[2022-11-02 16:28:57,932 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.bn1.bias 1024B
[2022-11-02 16:28:57,932 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.conv2.weight 2359296B
[2022-11-02 16:28:57,932 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.bn2.weight 1024B
[2022-11-02 16:28:57,932 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.bn2.bias 1024B
[2022-11-02 16:28:57,932 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.conv3.weight 1048576B
[2022-11-02 16:28:57,932 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.bn3.weight 4096B
[2022-11-02 16:28:57,932 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.bn3.bias 4096B
[2022-11-02 16:28:57,932 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.conv1.weight 1048576B
[2022-11-02 16:28:57,932 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.bn1.weight 1024B
[2022-11-02 16:28:57,932 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.bn1.bias 1024B
[2022-11-02 16:28:57,932 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.conv2.weight 2359296B
[2022-11-02 16:28:57,932 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.bn2.weight 1024B
[2022-11-02 16:28:57,932 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.bn2.bias 1024B
[2022-11-02 16:28:57,932 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.conv3.weight 1048576B
[2022-11-02 16:28:57,932 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.bn3.weight 4096B
[2022-11-02 16:28:57,932 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.bn3.bias 4096B
[2022-11-02 16:28:57,932 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.conv1.weight 1048576B
[2022-11-02 16:28:57,932 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.bn1.weight 1024B
[2022-11-02 16:28:57,933 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.bn1.bias 1024B
[2022-11-02 16:28:57,933 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.conv2.weight 2359296B
[2022-11-02 16:28:57,933 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.bn2.weight 1024B
[2022-11-02 16:28:57,933 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.bn2.bias 1024B
[2022-11-02 16:28:57,933 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.conv3.weight 1048576B
[2022-11-02 16:28:57,933 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.bn3.weight 4096B
[2022-11-02 16:28:57,933 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.bn3.bias 4096B
[2022-11-02 16:28:57,933 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.conv1.weight 1048576B
[2022-11-02 16:28:57,933 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.bn1.weight 1024B
[2022-11-02 16:28:57,933 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.bn1.bias 1024B
[2022-11-02 16:28:57,933 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.conv2.weight 2359296B
[2022-11-02 16:28:57,933 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.bn2.weight 1024B
[2022-11-02 16:28:57,933 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.bn2.bias 1024B
[2022-11-02 16:28:57,933 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.conv3.weight 1048576B
[2022-11-02 16:28:57,933 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.bn3.weight 4096B
[2022-11-02 16:28:57,933 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.bn3.bias 4096B
[2022-11-02 16:28:57,933 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.conv1.weight 1048576B
[2022-11-02 16:28:57,933 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.bn1.weight 1024B
[2022-11-02 16:28:57,933 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.bn1.bias 1024B
[2022-11-02 16:28:57,933 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.conv2.weight 2359296B
[2022-11-02 16:28:57,933 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.bn2.weight 1024B
[2022-11-02 16:28:57,933 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.bn2.bias 1024B
[2022-11-02 16:28:57,933 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.conv3.weight 1048576B
[2022-11-02 16:28:57,934 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.bn3.weight 4096B
[2022-11-02 16:28:57,934 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.bn3.bias 4096B
[2022-11-02 16:28:57,934 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.conv1.weight 2097152B
[2022-11-02 16:28:57,934 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.bn1.weight 2048B
[2022-11-02 16:28:57,934 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.bn1.bias 2048B
[2022-11-02 16:28:57,934 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.conv2.weight 9437184B
[2022-11-02 16:28:57,934 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.bn2.weight 2048B
[2022-11-02 16:28:57,934 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.bn2.bias 2048B
[2022-11-02 16:28:57,934 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.conv3.weight 4194304B
[2022-11-02 16:28:57,934 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.bn3.weight 8192B
[2022-11-02 16:28:57,934 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.bn3.bias 8192B
[2022-11-02 16:28:57,934 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.downsample.0.weight 8388608B
[2022-11-02 16:28:57,934 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.downsample.1.weight 8192B
[2022-11-02 16:28:57,934 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.downsample.1.bias 8192B
[2022-11-02 16:28:57,934 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.conv1.weight 4194304B
[2022-11-02 16:28:57,934 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.bn1.weight 2048B
[2022-11-02 16:28:57,934 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.bn1.bias 2048B
[2022-11-02 16:28:57,934 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.conv2.weight 9437184B
[2022-11-02 16:28:57,934 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.bn2.weight 2048B
[2022-11-02 16:28:57,934 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.bn2.bias 2048B
[2022-11-02 16:28:57,934 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.conv3.weight 4194304B
[2022-11-02 16:28:57,934 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.bn3.weight 8192B
[2022-11-02 16:28:57,934 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.bn3.bias 8192B
[2022-11-02 16:28:57,935 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.conv1.weight 4194304B
[2022-11-02 16:28:57,935 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.bn1.weight 2048B
[2022-11-02 16:28:57,935 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.bn1.bias 2048B
[2022-11-02 16:28:57,935 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.conv2.weight 9437184B
[2022-11-02 16:28:57,935 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.bn2.weight 2048B
[2022-11-02 16:28:57,935 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.bn2.bias 2048B
[2022-11-02 16:28:57,935 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.conv3.weight 4194304B
[2022-11-02 16:28:57,935 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.bn3.weight 8192B
[2022-11-02 16:28:57,935 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.bn3.bias 8192B
[2022-11-02 16:28:57,935 {dist_trainer.py:192}] <INFO> parameter size: fc.weight 81920B
[2022-11-02 16:28:57,935 {dist_trainer.py:192}] <INFO> parameter size: fc.bias 40B
[2022-11-02 16:28:57,935 {dist_trainer.py:194}] <INFO> Model: resnet50 size: 89.754MiB
[2022-11-02 16:29:02,726 {dist_trainer.py:78}] <INFO> device: cuda:3 0/4, NVIDIA TITAN RTX
[2022-11-02 16:29:04,033 {dist_trainer.py:494}] <INFO> node0: [7,8,2,6,4,5,1,3]
[2022-11-02 16:29:04,033 {dist_trainer.py:494}] <INFO> node1: [4,5,1,3,0,9,7,8]
[2022-11-02 16:29:04,033 {dist_trainer.py:494}] <INFO> node2: [0,9,7,8,2,6,4,5]
[2022-11-02 16:29:04,033 {dist_trainer.py:497}] <INFO> class 0, [node1:0.472,node2:0.528]
[2022-11-02 16:29:04,033 {dist_trainer.py:497}] <INFO> class 1, [node0:0.505,node1:0.495]
[2022-11-02 16:29:04,033 {dist_trainer.py:497}] <INFO> class 2, [node0:0.535,node2:0.465]
[2022-11-02 16:29:04,033 {dist_trainer.py:497}] <INFO> class 3, [node0:0.502,node1:0.498]
[2022-11-02 16:29:04,033 {dist_trainer.py:497}] <INFO> class 4, [node0:0.325,node1:0.361,node2:0.314]
[2022-11-02 16:29:04,033 {dist_trainer.py:497}] <INFO> class 5, [node0:0.327,node1:0.343,node2:0.330]
[2022-11-02 16:29:04,033 {dist_trainer.py:497}] <INFO> class 6, [node0:0.497,node2:0.503]
[2022-11-02 16:29:04,033 {dist_trainer.py:497}] <INFO> class 7, [node0:0.340,node1:0.338,node2:0.322]
[2022-11-02 16:29:04,033 {dist_trainer.py:497}] <INFO> class 8, [node0:0.305,node1:0.352,node2:0.343]
[2022-11-02 16:29:04,033 {dist_trainer.py:497}] <INFO> class 9, [node1:0.475,node2:0.525]
[2022-11-02 16:29:04,035 {dist_trainer.py:527}] <INFO> train data node0: 1:2523,2:2675,3:2509,4:1624,5:1634,6:2484,7:1700,8:1524
[2022-11-02 16:29:04,035 {dist_trainer.py:527}] <INFO> train data node1: 0:2360,1:2477,3:2491,4:1806,5:1714,7:1690,8:1758,9:2375
[2022-11-02 16:29:04,035 {dist_trainer.py:527}] <INFO> train data node2: 0:2640,2:2325,4:1570,5:1652,6:2516,7:1610,8:1718,9:2625
[2022-11-02 16:29:16,945 {dist_trainer.py:531}] <INFO> split_load_datas(END)
[2022-11-02 16:29:16,946 {dist_trainer.py:114}] <INFO> datasets(END)
[2022-11-02 16:29:16,947 {dist_trainer.py:713}] <INFO> build_criterion(1)
[2022-11-02 16:29:16,947 {dist_trainer.py:721}] <INFO> build_criterion(2)
[2022-11-02 16:29:16,958 {contract.py:21}] <INFO> 0
[2022-11-02 16:29:16,958 {contract.py:21}] <INFO> 1
[2022-11-02 16:29:16,958 {contract.py:21}] <INFO> 2
[2022-11-02 16:29:16,959 {gateway.py:80}] <INFO> Gateway(1)
[2022-11-02 16:29:17,005 {distributed_c10d.py:228}] <INFO> Added key: store_based_barrier_key:1 to store for rank: 2
[2022-11-02 16:29:17,006 {distributed_c10d.py:262}] <INFO> Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
[2022-11-02 16:29:17,006 {gateway.py:87}] <INFO> Gateway(2)
[2022-11-02 16:29:17,171 {gateway.py:25}] <INFO> ServerHandler(1)
[2022-11-02 16:29:17,172 {gateway.py:34}] <INFO> ServerHandler(2)
[2022-11-02 16:29:17,181 {contract.py:36}] <INFO> contract(1)
[2022-11-02 16:29:17,278 {gateway.py:62}] <INFO> <SRV> node2 : edge setup.
[2022-11-02 16:29:17,297 {contract.py:44}] <INFO> <CLI> node2 : edge setup.
[2022-11-02 16:29:18,047 {contract.py:59}] <INFO> contract(2)
[2022-11-02 16:29:18,047 {pdmm_isvr.py:22}] <INFO> Optimizer <class 'optimizer.pdmm_isvr.PdmmISVR'> params: {'lr': 0.002, 'round': 10, 'initial_lr': 0.002, 'piw': 1.0, 'use_gcoef': False}
[2022-11-02 16:29:18,047 {dist_trainer.py:725}] <INFO> build_optimizer()
[2022-11-02 16:29:18,047 {dist_trainer.py:736}] <INFO> Setup scheduler: <torch.optim.lr_scheduler.StepLR object at 0x7f95757c0310>
[2022-11-02 16:29:56,055 {dist_trainer.py:770}] <INFO> [   1/ 200] connecting edge count: 2
[2022-11-02 16:30:50,476 {dist_trainer.py:821}] <INFO> [   1/ 200] loss: (train=2.446, val=2.492, test=2.494, l2=15608.347), acc: (train=0.217, val=0.138, test=0.139), diff=0.00002281, proc(train=38.008sec, eval=52.613sec)
[2022-11-02 16:31:27,559 {dist_trainer.py:770}] <INFO> [   2/ 200] connecting edge count: 2
[2022-11-02 16:32:17,496 {dist_trainer.py:821}] <INFO> [   2/ 200] loss: (train=2.253, val=2.276, test=2.263, l2=15538.979), acc: (train=0.244, val=0.176, test=0.178), diff=0.00000317, proc(train=37.082sec, eval=48.800sec)
[2022-11-02 16:32:55,161 {dist_trainer.py:770}] <INFO> [   3/ 200] connecting edge count: 2
[2022-11-02 16:33:40,200 {dist_trainer.py:821}] <INFO> [   3/ 200] loss: (train=2.079, val=1.999, test=1.995, l2=15465.932), acc: (train=0.311, val=0.256, test=0.258), diff=0.00000146, proc(train=37.664sec, eval=43.768sec)
[2022-11-02 16:34:18,299 {dist_trainer.py:770}] <INFO> [   4/ 200] connecting edge count: 2
[2022-11-02 16:35:12,812 {dist_trainer.py:821}] <INFO> [   4/ 200] loss: (train=1.974, val=1.986, test=1.977, l2=15395.426), acc: (train=0.327, val=0.263, test=0.262), diff=0.00000122, proc(train=38.099sec, eval=52.868sec)
[2022-11-02 16:35:49,314 {dist_trainer.py:770}] <INFO> [   5/ 200] connecting edge count: 2
[2022-11-02 16:36:38,749 {dist_trainer.py:821}] <INFO> [   5/ 200] loss: (train=1.914, val=1.866, test=1.859, l2=15338.425), acc: (train=0.428, val=0.315, test=0.315), diff=0.00000169, proc(train=36.501sec, eval=48.187sec)
[2022-11-02 16:37:16,539 {dist_trainer.py:770}] <INFO> [   6/ 200] connecting edge count: 2
[2022-11-02 16:38:01,924 {dist_trainer.py:821}] <INFO> [   6/ 200] loss: (train=1.844, val=2.090, test=2.089, l2=15263.454), acc: (train=0.419, val=0.307, test=0.303), diff=0.00000151, proc(train=37.790sec, eval=43.787sec)
[2022-11-02 16:38:39,773 {dist_trainer.py:770}] <INFO> [   7/ 200] connecting edge count: 2
[2022-11-02 16:39:34,813 {dist_trainer.py:821}] <INFO> [   7/ 200] loss: (train=1.779, val=1.784, test=1.781, l2=15196.881), acc: (train=0.422, val=0.352, test=0.351), diff=0.00000126, proc(train=37.849sec, eval=53.124sec)
[2022-11-02 16:40:11,515 {dist_trainer.py:770}] <INFO> [   8/ 200] connecting edge count: 2
[2022-11-02 16:40:59,900 {dist_trainer.py:821}] <INFO> [   8/ 200] loss: (train=1.734, val=1.790, test=1.791, l2=15130.016), acc: (train=0.434, val=0.350, test=0.353), diff=0.00000162, proc(train=36.701sec, eval=47.062sec)
[2022-11-02 16:41:37,476 {dist_trainer.py:770}] <INFO> [   9/ 200] connecting edge count: 2
[2022-11-02 16:42:26,392 {dist_trainer.py:821}] <INFO> [   9/ 200] loss: (train=1.736, val=1.762, test=1.759, l2=15061.164), acc: (train=0.474, val=0.364, test=0.368), diff=0.00000166, proc(train=37.576sec, eval=47.192sec)
[2022-11-02 16:43:03,584 {dist_trainer.py:770}] <INFO> [  10/ 200] connecting edge count: 2
[2022-11-02 16:43:54,459 {dist_trainer.py:821}] <INFO> [  10/ 200] loss: (train=1.688, val=1.811, test=1.807, l2=14986.586), acc: (train=0.457, val=0.340, test=0.339), diff=0.00000108, proc(train=37.191sec, eval=49.555sec)
[2022-11-02 16:44:30,271 {dist_trainer.py:770}] <INFO> [  11/ 200] connecting edge count: 2
[2022-11-02 16:45:19,947 {dist_trainer.py:821}] <INFO> [  11/ 200] loss: (train=1.658, val=1.641, test=1.650, l2=14935.093), acc: (train=0.495, val=0.409, test=0.407), diff=0.00000180, proc(train=35.812sec, eval=48.499sec)
[2022-11-02 16:45:56,716 {dist_trainer.py:770}] <INFO> [  12/ 200] connecting edge count: 2
[2022-11-02 16:46:46,123 {dist_trainer.py:821}] <INFO> [  12/ 200] loss: (train=1.599, val=1.767, test=1.764, l2=14875.857), acc: (train=0.472, val=0.377, test=0.372), diff=0.00000104, proc(train=36.768sec, eval=47.647sec)
[2022-11-02 16:47:21,397 {dist_trainer.py:770}] <INFO> [  13/ 200] connecting edge count: 2
[2022-11-02 16:48:10,608 {dist_trainer.py:821}] <INFO> [  13/ 200] loss: (train=1.613, val=1.594, test=1.601, l2=14833.999), acc: (train=0.467, val=0.411, test=0.412), diff=0.00000192, proc(train=35.274sec, eval=47.786sec)
[2022-11-02 16:48:46,970 {dist_trainer.py:770}] <INFO> [  14/ 200] connecting edge count: 2
[2022-11-02 16:49:38,239 {dist_trainer.py:821}] <INFO> [  14/ 200] loss: (train=1.616, val=1.662, test=1.666, l2=11586.860), acc: (train=0.456, val=0.398, test=0.394), diff=0.00021967, proc(train=36.362sec, eval=49.790sec)
[2022-11-02 16:50:17,498 {dist_trainer.py:770}] <INFO> [  15/ 200] connecting edge count: 2
[2022-11-02 16:51:04,711 {dist_trainer.py:821}] <INFO> [  15/ 200] loss: (train=1.526, val=1.592, test=1.599, l2=11697.157), acc: (train=0.499, val=0.415, test=0.409), diff=0.00000158, proc(train=39.259sec, eval=45.877sec)
[2022-11-02 16:51:41,718 {dist_trainer.py:770}] <INFO> [  16/ 200] connecting edge count: 2
[2022-11-02 16:52:34,781 {dist_trainer.py:821}] <INFO> [  16/ 200] loss: (train=1.506, val=1.648, test=1.655, l2=11643.240), acc: (train=0.493, val=0.400, test=0.398), diff=0.00000136, proc(train=37.007sec, eval=51.729sec)
[2022-11-02 16:53:11,404 {dist_trainer.py:770}] <INFO> [  17/ 200] connecting edge count: 2
[2022-11-02 16:53:58,952 {dist_trainer.py:821}] <INFO> [  17/ 200] loss: (train=1.515, val=1.617, test=1.627, l2=11598.852), acc: (train=0.535, val=0.420, test=0.415), diff=0.00000191, proc(train=36.623sec, eval=46.208sec)
[2022-11-02 16:54:35,862 {dist_trainer.py:770}] <INFO> [  18/ 200] connecting edge count: 2
[2022-11-02 16:55:26,727 {dist_trainer.py:821}] <INFO> [  18/ 200] loss: (train=1.482, val=1.609, test=1.618, l2=11545.476), acc: (train=0.522, val=0.422, test=0.418), diff=0.00000179, proc(train=36.910sec, eval=49.334sec)
[2022-11-02 16:56:05,809 {dist_trainer.py:770}] <INFO> [  19/ 200] connecting edge count: 2
[2022-11-02 16:56:55,362 {dist_trainer.py:821}] <INFO> [  19/ 200] loss: (train=1.484, val=1.444, test=1.460, l2=11498.197), acc: (train=0.522, val=0.477, test=0.468), diff=0.00000173, proc(train=39.082sec, eval=48.069sec)
[2022-11-02 16:57:31,058 {dist_trainer.py:770}] <INFO> [  20/ 200] connecting edge count: 2
[2022-11-02 16:58:18,998 {dist_trainer.py:821}] <INFO> [  20/ 200] loss: (train=1.480, val=1.499, test=1.510, l2=11451.426), acc: (train=0.524, val=0.474, test=0.470), diff=0.00000159, proc(train=35.696sec, eval=46.647sec)
[2022-11-02 16:58:54,980 {dist_trainer.py:770}] <INFO> [  21/ 200] connecting edge count: 2
[2022-11-02 16:59:46,412 {dist_trainer.py:821}] <INFO> [  21/ 200] loss: (train=1.472, val=1.414, test=1.431, l2=11401.898), acc: (train=0.502, val=0.493, test=0.485), diff=0.00000134, proc(train=35.982sec, eval=50.052sec)
[2022-11-02 17:00:23,624 {dist_trainer.py:770}] <INFO> [  22/ 200] connecting edge count: 2
[2022-11-02 17:01:12,880 {dist_trainer.py:821}] <INFO> [  22/ 200] loss: (train=1.455, val=1.372, test=1.393, l2=11351.066), acc: (train=0.530, val=0.509, test=0.500), diff=0.00000148, proc(train=37.212sec, eval=48.029sec)
[2022-11-02 17:01:48,799 {dist_trainer.py:770}] <INFO> [  23/ 200] connecting edge count: 2
[2022-11-02 17:02:34,770 {dist_trainer.py:821}] <INFO> [  23/ 200] loss: (train=1.413, val=1.400, test=1.425, l2=11297.133), acc: (train=0.516, val=0.500, test=0.494), diff=0.00000110, proc(train=35.919sec, eval=44.507sec)
[2022-11-02 17:03:11,966 {dist_trainer.py:770}] <INFO> [  24/ 200] connecting edge count: 2
[2022-11-02 17:04:05,867 {dist_trainer.py:821}] <INFO> [  24/ 200] loss: (train=1.387, val=1.374, test=1.398, l2=11253.257), acc: (train=0.560, val=0.504, test=0.495), diff=0.00000195, proc(train=37.195sec, eval=52.235sec)
[2022-11-02 17:04:43,456 {dist_trainer.py:770}] <INFO> [  25/ 200] connecting edge count: 2
[2022-11-02 17:05:29,969 {dist_trainer.py:821}] <INFO> [  25/ 200] loss: (train=1.357, val=1.329, test=1.364, l2=11206.389), acc: (train=0.557, val=0.526, test=0.519), diff=0.00000170, proc(train=37.589sec, eval=45.336sec)
[2022-11-02 17:06:06,179 {dist_trainer.py:770}] <INFO> [  26/ 200] connecting edge count: 2
[2022-11-02 17:06:56,824 {dist_trainer.py:821}] <INFO> [  26/ 200] loss: (train=1.384, val=1.323, test=1.350, l2=11152.019), acc: (train=0.578, val=0.518, test=0.510), diff=0.00000180, proc(train=36.210sec, eval=49.082sec)
[2022-11-02 17:07:31,619 {dist_trainer.py:770}] <INFO> [  27/ 200] connecting edge count: 2
[2022-11-02 17:08:22,116 {dist_trainer.py:821}] <INFO> [  27/ 200] loss: (train=1.341, val=1.323, test=1.353, l2=11102.408), acc: (train=0.597, val=0.518, test=0.504), diff=0.00000160, proc(train=34.795sec, eval=48.966sec)
[2022-11-02 17:08:59,352 {dist_trainer.py:770}] <INFO> [  28/ 200] connecting edge count: 2
[2022-11-02 17:09:45,887 {dist_trainer.py:821}] <INFO> [  28/ 200] loss: (train=1.328, val=1.292, test=1.329, l2=11047.292), acc: (train=0.562, val=0.537, test=0.526), diff=0.00000139, proc(train=37.235sec, eval=44.923sec)
[2022-11-02 17:10:22,510 {dist_trainer.py:770}] <INFO> [  29/ 200] connecting edge count: 2
[2022-11-02 17:11:15,785 {dist_trainer.py:821}] <INFO> [  29/ 200] loss: (train=1.329, val=1.335, test=1.381, l2=10998.804), acc: (train=0.550, val=0.527, test=0.515), diff=0.00000176, proc(train=36.623sec, eval=51.565sec)
[2022-11-02 17:11:52,290 {dist_trainer.py:770}] <INFO> [  30/ 200] connecting edge count: 2
[2022-11-02 17:12:40,227 {dist_trainer.py:821}] <INFO> [  30/ 200] loss: (train=1.294, val=1.314, test=1.354, l2=10951.210), acc: (train=0.615, val=0.524, test=0.514), diff=0.00000147, proc(train=36.504sec, eval=46.806sec)
[2022-11-02 17:13:17,011 {dist_trainer.py:770}] <INFO> [  31/ 200] connecting edge count: 2
[2022-11-02 17:14:03,810 {dist_trainer.py:821}] <INFO> [  31/ 200] loss: (train=1.305, val=1.315, test=1.355, l2=10894.765), acc: (train=0.581, val=0.537, test=0.523), diff=0.00000122, proc(train=36.784sec, eval=45.326sec)
[2022-11-02 17:14:39,452 {dist_trainer.py:770}] <INFO> [  32/ 200] connecting edge count: 2
[2022-11-02 17:15:33,864 {dist_trainer.py:821}] <INFO> [  32/ 200] loss: (train=1.330, val=1.228, test=1.268, l2=10848.203), acc: (train=0.595, val=0.562, test=0.544), diff=0.00000185, proc(train=35.642sec, eval=52.795sec)
[2022-11-02 17:16:10,059 {dist_trainer.py:770}] <INFO> [  33/ 200] connecting edge count: 2
[2022-11-02 17:16:58,142 {dist_trainer.py:821}] <INFO> [  33/ 200] loss: (train=1.257, val=1.328, test=1.386, l2=10806.401), acc: (train=0.619, val=0.530, test=0.515), diff=0.00000150, proc(train=36.195sec, eval=46.935sec)
[2022-11-02 17:17:35,239 {dist_trainer.py:770}] <INFO> [  34/ 200] connecting edge count: 2
[2022-11-02 17:18:23,059 {dist_trainer.py:821}] <INFO> [  34/ 200] loss: (train=1.255, val=1.257, test=1.303, l2=10752.411), acc: (train=0.610, val=0.554, test=0.542), diff=0.00000140, proc(train=37.097sec, eval=46.021sec)
[2022-11-02 17:18:58,653 {dist_trainer.py:770}] <INFO> [  35/ 200] connecting edge count: 2
[2022-11-02 17:19:53,217 {dist_trainer.py:821}] <INFO> [  35/ 200] loss: (train=1.250, val=1.185, test=1.235, l2=10710.359), acc: (train=0.618, val=0.575, test=0.558), diff=0.00000172, proc(train=35.594sec, eval=53.104sec)
[2022-11-02 17:20:30,743 {dist_trainer.py:770}] <INFO> [  36/ 200] connecting edge count: 2
[2022-11-02 17:21:16,256 {dist_trainer.py:821}] <INFO> [  36/ 200] loss: (train=1.271, val=1.300, test=1.359, l2=10669.319), acc: (train=0.580, val=0.560, test=0.540), diff=0.00000139, proc(train=37.526sec, eval=44.245sec)
[2022-11-02 17:21:53,439 {dist_trainer.py:770}] <INFO> [  37/ 200] connecting edge count: 2
[2022-11-02 17:22:46,154 {dist_trainer.py:821}] <INFO> [  37/ 200] loss: (train=1.223, val=1.214, test=1.264, l2=10614.799), acc: (train=0.632, val=0.564, test=0.547), diff=0.00000109, proc(train=37.182sec, eval=51.031sec)
[2022-11-02 17:23:22,791 {dist_trainer.py:770}] <INFO> [  38/ 200] connecting edge count: 2
[2022-11-02 17:24:12,208 {dist_trainer.py:821}] <INFO> [  38/ 200] loss: (train=1.229, val=1.152, test=1.219, l2=10572.521), acc: (train=0.626, val=0.590, test=0.573), diff=0.00000142, proc(train=36.637sec, eval=48.192sec)
[2022-11-02 17:24:48,874 {dist_trainer.py:770}] <INFO> [  39/ 200] connecting edge count: 2
[2022-11-02 17:25:35,421 {dist_trainer.py:821}] <INFO> [  39/ 200] loss: (train=1.203, val=1.176, test=1.240, l2=10521.429), acc: (train=0.620, val=0.586, test=0.568), diff=0.00000149, proc(train=36.666sec, eval=45.017sec)
[2022-11-02 17:26:13,237 {dist_trainer.py:770}] <INFO> [  40/ 200] connecting edge count: 2
[2022-11-02 17:27:07,276 {dist_trainer.py:821}] <INFO> [  40/ 200] loss: (train=1.235, val=1.231, test=1.292, l2=10476.885), acc: (train=0.604, val=0.570, test=0.553), diff=0.00000226, proc(train=37.816sec, eval=52.273sec)
[2022-11-02 17:27:43,457 {dist_trainer.py:770}] <INFO> [  41/ 200] connecting edge count: 2
[2022-11-02 17:28:31,308 {dist_trainer.py:821}] <INFO> [  41/ 200] loss: (train=1.202, val=1.123, test=1.198, l2=10431.838), acc: (train=0.645, val=0.604, test=0.584), diff=0.00000165, proc(train=36.180sec, eval=46.597sec)
[2022-11-02 17:29:08,033 {dist_trainer.py:770}] <INFO> [  42/ 200] connecting edge count: 2
[2022-11-02 17:29:57,300 {dist_trainer.py:821}] <INFO> [  42/ 200] loss: (train=1.204, val=1.162, test=1.229, l2=10377.549), acc: (train=0.644, val=0.585, test=0.568), diff=0.00000119, proc(train=36.725sec, eval=47.734sec)
[2022-11-02 17:30:34,140 {dist_trainer.py:770}] <INFO> [  43/ 200] connecting edge count: 2
[2022-11-02 17:31:26,457 {dist_trainer.py:821}] <INFO> [  43/ 200] loss: (train=1.159, val=1.169, test=1.243, l2=10335.146), acc: (train=0.669, val=0.581, test=0.561), diff=0.00000165, proc(train=36.840sec, eval=50.994sec)
[2022-11-02 17:32:04,493 {dist_trainer.py:770}] <INFO> [  44/ 200] connecting edge count: 2
[2022-11-02 17:32:50,395 {dist_trainer.py:821}] <INFO> [  44/ 200] loss: (train=1.171, val=1.120, test=1.196, l2=10292.634), acc: (train=0.649, val=0.600, test=0.572), diff=0.00000111, proc(train=38.036sec, eval=44.317sec)
[2022-11-02 17:33:26,889 {dist_trainer.py:770}] <INFO> [  45/ 200] connecting edge count: 2
[2022-11-02 17:34:19,460 {dist_trainer.py:821}] <INFO> [  45/ 200] loss: (train=1.141, val=1.100, test=1.189, l2=10245.193), acc: (train=0.648, val=0.611, test=0.587), diff=0.00000094, proc(train=36.494sec, eval=51.113sec)
[2022-11-02 17:34:54,475 {dist_trainer.py:770}] <INFO> [  46/ 200] connecting edge count: 2
[2022-11-02 17:35:45,554 {dist_trainer.py:821}] <INFO> [  46/ 200] loss: (train=1.128, val=1.217, test=1.296, l2=10204.113), acc: (train=0.623, val=0.572, test=0.549), diff=0.00000102, proc(train=35.015sec, eval=49.496sec)
[2022-11-02 17:36:22,725 {dist_trainer.py:770}] <INFO> [  47/ 200] connecting edge count: 2
[2022-11-02 17:37:07,743 {dist_trainer.py:821}] <INFO> [  47/ 200] loss: (train=1.092, val=1.092, test=1.177, l2=10151.664), acc: (train=0.666, val=0.617, test=0.590), diff=0.00000090, proc(train=37.170sec, eval=43.577sec)
[2022-11-02 17:37:43,690 {dist_trainer.py:770}] <INFO> [  48/ 200] connecting edge count: 2
[2022-11-02 17:38:37,848 {dist_trainer.py:821}] <INFO> [  48/ 200] loss: (train=1.124, val=1.081, test=1.173, l2=10102.908), acc: (train=0.690, val=0.614, test=0.584), diff=0.00000134, proc(train=35.947sec, eval=52.278sec)
[2022-11-02 17:39:12,568 {dist_trainer.py:770}] <INFO> [  49/ 200] connecting edge count: 2
[2022-11-02 17:40:02,657 {dist_trainer.py:821}] <INFO> [  49/ 200] loss: (train=1.122, val=1.014, test=1.112, l2=10068.386), acc: (train=0.676, val=0.641, test=0.616), diff=0.00000140, proc(train=34.719sec, eval=48.961sec)
[2022-11-02 17:40:40,298 {dist_trainer.py:770}] <INFO> [  50/ 200] connecting edge count: 2
[2022-11-02 17:41:26,234 {dist_trainer.py:821}] <INFO> [  50/ 200] loss: (train=1.079, val=1.111, test=1.202, l2=10020.048), acc: (train=0.669, val=0.608, test=0.584), diff=0.00000112, proc(train=37.641sec, eval=44.617sec)
[2022-11-02 17:42:03,474 {dist_trainer.py:770}] <INFO> [  51/ 200] connecting edge count: 2
[2022-11-02 17:42:57,839 {dist_trainer.py:821}] <INFO> [  51/ 200] loss: (train=1.119, val=0.993, test=1.099, l2=9979.010), acc: (train=0.674, val=0.650, test=0.619), diff=0.00000180, proc(train=37.240sec, eval=52.588sec)
[2022-11-02 17:43:34,726 {dist_trainer.py:770}] <INFO> [  52/ 200] connecting edge count: 2
[2022-11-02 17:44:20,761 {dist_trainer.py:821}] <INFO> [  52/ 200] loss: (train=1.091, val=1.091, test=1.193, l2=9935.991), acc: (train=0.646, val=0.625, test=0.596), diff=0.00000105, proc(train=36.886sec, eval=44.797sec)
[2022-11-02 17:44:57,355 {dist_trainer.py:770}] <INFO> [  53/ 200] connecting edge count: 2
[2022-11-02 17:45:45,392 {dist_trainer.py:821}] <INFO> [  53/ 200] loss: (train=1.080, val=1.110, test=1.211, l2=9883.707), acc: (train=0.646, val=0.612, test=0.586), diff=0.00000129, proc(train=36.593sec, eval=46.341sec)
[2022-11-02 17:46:21,449 {dist_trainer.py:770}] <INFO> [  54/ 200] connecting edge count: 2
[2022-11-02 17:47:14,374 {dist_trainer.py:821}] <INFO> [  54/ 200] loss: (train=1.083, val=1.080, test=1.192, l2=9846.632), acc: (train=0.616, val=0.630, test=0.599), diff=0.00000141, proc(train=36.056sec, eval=51.292sec)
[2022-11-02 17:47:51,665 {dist_trainer.py:770}] <INFO> [  55/ 200] connecting edge count: 2
[2022-11-02 17:48:38,445 {dist_trainer.py:821}] <INFO> [  55/ 200] loss: (train=1.090, val=1.013, test=1.126, l2=9802.261), acc: (train=0.694, val=0.646, test=0.618), diff=0.00000103, proc(train=37.290sec, eval=45.547sec)
[2022-11-02 17:49:15,609 {dist_trainer.py:770}] <INFO> [  56/ 200] connecting edge count: 2
[2022-11-02 17:50:00,618 {dist_trainer.py:821}] <INFO> [  56/ 200] loss: (train=1.047, val=1.126, test=1.241, l2=9758.628), acc: (train=0.662, val=0.617, test=0.590), diff=0.00000103, proc(train=37.164sec, eval=43.448sec)
[2022-11-02 17:50:36,606 {dist_trainer.py:770}] <INFO> [  57/ 200] connecting edge count: 2
[2022-11-02 17:51:29,044 {dist_trainer.py:821}] <INFO> [  57/ 200] loss: (train=1.073, val=1.054, test=1.165, l2=9716.689), acc: (train=0.672, val=0.631, test=0.598), diff=0.00000107, proc(train=35.987sec, eval=50.821sec)
[2022-11-02 17:52:04,233 {dist_trainer.py:770}] <INFO> [  58/ 200] connecting edge count: 2
[2022-11-02 17:52:53,517 {dist_trainer.py:821}] <INFO> [  58/ 200] loss: (train=1.049, val=1.016, test=1.130, l2=9681.581), acc: (train=0.666, val=0.645, test=0.608), diff=0.00000124, proc(train=35.188sec, eval=48.195sec)
[2022-11-02 17:53:30,640 {dist_trainer.py:770}] <INFO> [  59/ 200] connecting edge count: 2
[2022-11-02 17:54:16,016 {dist_trainer.py:821}] <INFO> [  59/ 200] loss: (train=1.044, val=0.913, test=1.049, l2=9631.263), acc: (train=0.707, val=0.681, test=0.641), diff=0.00000107, proc(train=37.123sec, eval=43.708sec)
[2022-11-02 17:54:52,341 {dist_trainer.py:770}] <INFO> [  60/ 200] connecting edge count: 2
[2022-11-02 17:55:44,826 {dist_trainer.py:821}] <INFO> [  60/ 200] loss: (train=1.026, val=1.018, test=1.130, l2=9586.882), acc: (train=0.709, val=0.638, test=0.609), diff=0.00000114, proc(train=36.325sec, eval=50.969sec)
[2022-11-02 17:56:21,917 {dist_trainer.py:770}] <INFO> [  61/ 200] connecting edge count: 2
[2022-11-02 17:57:10,628 {dist_trainer.py:821}] <INFO> [  61/ 200] loss: (train=1.025, val=0.935, test=1.065, l2=9547.210), acc: (train=0.706, val=0.672, test=0.636), diff=0.00000120, proc(train=37.090sec, eval=47.613sec)
[2022-11-02 17:57:46,803 {dist_trainer.py:770}] <INFO> [  62/ 200] connecting edge count: 2
[2022-11-02 17:58:32,369 {dist_trainer.py:821}] <INFO> [  62/ 200] loss: (train=1.004, val=1.089, test=1.212, l2=9745.429), acc: (train=0.693, val=0.625, test=0.594), diff=0.00061761, proc(train=36.175sec, eval=44.054sec)
[2022-11-02 17:59:09,650 {dist_trainer.py:770}] <INFO> [  63/ 200] connecting edge count: 2
[2022-11-02 18:00:02,835 {dist_trainer.py:821}] <INFO> [  63/ 200] loss: (train=0.978, val=1.003, test=1.133, l2=10217.915), acc: (train=0.713, val=0.647, test=0.615), diff=0.00000133, proc(train=37.281sec, eval=51.405sec)
[2022-11-02 18:00:37,910 {dist_trainer.py:770}] <INFO> [  64/ 200] connecting edge count: 2
[2022-11-02 18:01:27,349 {dist_trainer.py:821}] <INFO> [  64/ 200] loss: (train=0.973, val=1.034, test=1.180, l2=10175.874), acc: (train=0.688, val=0.648, test=0.614), diff=0.00000127, proc(train=35.075sec, eval=48.174sec)
[2022-11-02 18:02:04,343 {dist_trainer.py:770}] <INFO> [  65/ 200] connecting edge count: 2
[2022-11-02 18:02:50,760 {dist_trainer.py:821}] <INFO> [  65/ 200] loss: (train=0.965, val=0.969, test=1.117, l2=10127.062), acc: (train=0.709, val=0.668, test=0.629), diff=0.00000095, proc(train=36.994sec, eval=44.791sec)
[2022-11-02 18:03:27,115 {dist_trainer.py:770}] <INFO> [  66/ 200] connecting edge count: 2
[2022-11-02 18:04:20,785 {dist_trainer.py:821}] <INFO> [  66/ 200] loss: (train=0.973, val=0.912, test=1.056, l2=10090.000), acc: (train=0.710, val=0.683, test=0.640), diff=0.00000131, proc(train=36.354sec, eval=52.164sec)
[2022-11-02 18:04:58,332 {dist_trainer.py:770}] <INFO> [  67/ 200] connecting edge count: 2
[2022-11-02 18:05:44,952 {dist_trainer.py:821}] <INFO> [  67/ 200] loss: (train=0.939, val=0.910, test=1.065, l2=10053.531), acc: (train=0.721, val=0.683, test=0.639), diff=0.00000105, proc(train=37.547sec, eval=45.450sec)
[2022-11-02 18:06:21,851 {dist_trainer.py:770}] <INFO> [  68/ 200] connecting edge count: 2
[2022-11-02 18:07:09,635 {dist_trainer.py:821}] <INFO> [  68/ 200] loss: (train=0.975, val=0.867, test=1.020, l2=10003.036), acc: (train=0.729, val=0.697, test=0.652), diff=0.00000094, proc(train=36.898sec, eval=45.925sec)
[2022-11-02 18:07:46,168 {dist_trainer.py:770}] <INFO> [  69/ 200] connecting edge count: 2
[2022-11-02 18:08:39,594 {dist_trainer.py:821}] <INFO> [  69/ 200] loss: (train=0.955, val=0.908, test=1.073, l2=9967.688), acc: (train=0.718, val=0.684, test=0.639), diff=0.00000136, proc(train=36.533sec, eval=51.699sec)
[2022-11-02 18:09:18,428 {dist_trainer.py:770}] <INFO> [  70/ 200] connecting edge count: 2
[2022-11-02 18:10:03,371 {dist_trainer.py:821}] <INFO> [  70/ 200] loss: (train=0.946, val=0.864, test=1.025, l2=9920.963), acc: (train=0.726, val=0.697, test=0.650), diff=0.00000100, proc(train=38.833sec, eval=43.698sec)
[2022-11-02 18:10:39,973 {dist_trainer.py:770}] <INFO> [  71/ 200] connecting edge count: 2
[2022-11-02 18:11:28,837 {dist_trainer.py:821}] <INFO> [  71/ 200] loss: (train=0.945, val=0.869, test=1.035, l2=9874.237), acc: (train=0.738, val=0.699, test=0.653), diff=0.00000126, proc(train=36.602sec, eval=47.336sec)
[2022-11-02 18:12:06,442 {dist_trainer.py:770}] <INFO> [  72/ 200] connecting edge count: 2
[2022-11-02 18:12:58,107 {dist_trainer.py:821}] <INFO> [  72/ 200] loss: (train=0.929, val=0.857, test=1.018, l2=9835.735), acc: (train=0.730, val=0.701, test=0.652), diff=0.00000116, proc(train=37.604sec, eval=50.431sec)
[2022-11-02 18:13:34,057 {dist_trainer.py:770}] <INFO> [  73/ 200] connecting edge count: 2
[2022-11-02 18:14:19,882 {dist_trainer.py:821}] <INFO> [  73/ 200] loss: (train=0.905, val=0.830, test=1.008, l2=9796.291), acc: (train=0.733, val=0.711, test=0.658), diff=0.00000128, proc(train=35.949sec, eval=44.653sec)
[2022-11-02 18:14:57,028 {dist_trainer.py:770}] <INFO> [  74/ 200] connecting edge count: 2
[2022-11-02 18:15:49,647 {dist_trainer.py:821}] <INFO> [  74/ 200] loss: (train=0.921, val=0.911, test=1.070, l2=9753.686), acc: (train=0.731, val=0.682, test=0.642), diff=0.00000109, proc(train=37.145sec, eval=51.099sec)
[2022-11-02 18:16:25,128 {dist_trainer.py:770}] <INFO> [  75/ 200] connecting edge count: 2
[2022-11-02 18:17:16,054 {dist_trainer.py:821}] <INFO> [  75/ 200] loss: (train=0.914, val=0.830, test=1.008, l2=9713.769), acc: (train=0.746, val=0.712, test=0.660), diff=0.00000112, proc(train=35.481sec, eval=49.709sec)
[2022-11-02 18:17:52,411 {dist_trainer.py:770}] <INFO> [  76/ 200] connecting edge count: 2
[2022-11-02 18:18:37,691 {dist_trainer.py:821}] <INFO> [  76/ 200] loss: (train=0.870, val=0.888, test=1.084, l2=9669.128), acc: (train=0.740, val=0.691, test=0.638), diff=0.00000106, proc(train=36.357sec, eval=44.100sec)
[2022-11-02 18:19:13,901 {dist_trainer.py:770}] <INFO> [  77/ 200] connecting edge count: 2
[2022-11-02 18:20:06,477 {dist_trainer.py:821}] <INFO> [  77/ 200] loss: (train=0.886, val=0.856, test=1.034, l2=9623.704), acc: (train=0.731, val=0.699, test=0.648), diff=0.00000094, proc(train=36.210sec, eval=51.061sec)
[2022-11-02 18:20:43,319 {dist_trainer.py:770}] <INFO> [  78/ 200] connecting edge count: 2
[2022-11-02 18:21:32,882 {dist_trainer.py:821}] <INFO> [  78/ 200] loss: (train=0.883, val=0.886, test=1.082, l2=9589.855), acc: (train=0.720, val=0.693, test=0.641), diff=0.00000122, proc(train=36.842sec, eval=48.340sec)
[2022-11-02 18:22:09,705 {dist_trainer.py:770}] <INFO> [  79/ 200] connecting edge count: 2
[2022-11-02 18:22:54,802 {dist_trainer.py:821}] <INFO> [  79/ 200] loss: (train=0.850, val=0.785, test=0.986, l2=9540.702), acc: (train=0.740, val=0.728, test=0.669), diff=0.00000116, proc(train=36.822sec, eval=43.438sec)
[2022-11-02 18:23:31,498 {dist_trainer.py:770}] <INFO> [  80/ 200] connecting edge count: 2
[2022-11-02 18:24:25,041 {dist_trainer.py:821}] <INFO> [  80/ 200] loss: (train=0.851, val=0.850, test=1.054, l2=9497.027), acc: (train=0.764, val=0.703, test=0.644), diff=0.00000098, proc(train=36.696sec, eval=51.638sec)
[2022-11-02 18:25:02,362 {dist_trainer.py:770}] <INFO> [  81/ 200] connecting edge count: 2
[2022-11-02 18:25:50,866 {dist_trainer.py:821}] <INFO> [  81/ 200] loss: (train=0.846, val=0.824, test=1.028, l2=9461.684), acc: (train=0.767, val=0.713, test=0.651), diff=0.00000118, proc(train=37.320sec, eval=47.270sec)
[2022-11-02 18:26:28,225 {dist_trainer.py:770}] <INFO> [  82/ 200] connecting edge count: 2
[2022-11-02 18:27:14,219 {dist_trainer.py:821}] <INFO> [  82/ 200] loss: (train=0.820, val=0.838, test=1.038, l2=9421.271), acc: (train=0.768, val=0.707, test=0.651), diff=0.00000102, proc(train=37.358sec, eval=44.358sec)
[2022-11-02 18:27:50,823 {dist_trainer.py:770}] <INFO> [  83/ 200] connecting edge count: 2
[2022-11-02 18:28:43,786 {dist_trainer.py:821}] <INFO> [  83/ 200] loss: (train=0.868, val=0.813, test=1.007, l2=9379.240), acc: (train=0.739, val=0.717, test=0.655), diff=0.00000088, proc(train=36.603sec, eval=51.396sec)
[2022-11-02 18:29:20,351 {dist_trainer.py:770}] <INFO> [  84/ 200] connecting edge count: 2
[2022-11-02 18:30:10,257 {dist_trainer.py:821}] <INFO> [  84/ 200] loss: (train=0.854, val=0.781, test=1.011, l2=9344.214), acc: (train=0.763, val=0.729, test=0.667), diff=0.00000120, proc(train=36.564sec, eval=48.723sec)
[2022-11-02 18:30:47,101 {dist_trainer.py:770}] <INFO> [  85/ 200] connecting edge count: 2
[2022-11-02 18:31:33,829 {dist_trainer.py:821}] <INFO> [  85/ 200] loss: (train=0.828, val=0.803, test=1.025, l2=9297.143), acc: (train=0.745, val=0.721, test=0.663), diff=0.19747105, proc(train=36.843sec, eval=36.107sec)
[2022-11-02 18:31:34,354 {contract.py:84}] <INFO>  => node2 : edge disconnect.
[2022-11-02 18:32:04,641 {contract.py:84}] <INFO>  => node2 : edge disconnect.
[2022-11-02 18:32:05,109 {dist_trainer.py:770}] <INFO> [  86/ 200] connecting edge count: 0
[2022-11-02 18:32:35,380 {dist_trainer.py:821}] <INFO> [  86/ 200] loss: (train=1.110, val=1.457, test=1.547, l2=24999.346), acc: (train=0.680, val=0.539, test=0.518), diff=0.00000000, proc(train=31.279sec, eval=30.271sec)
[2022-11-02 18:32:35,380 {dist_trainer.py:836}] <INFO> [  86/ 200] found edge disconnection: 2 -> 0. finished train.
[2022-11-02 18:33:09,231 {dist_trainer.py:899}] <INFO> [EVAL] loss: (train=0.936, val=1.457, test=1.547, l2=24998.346), acc: (train=0.691, val=0.539, test=0.518), proc=33.850sec
[2022-11-02 18:33:09,338 {dist_trainer.py:380}] <INFO> GC: check garbage []
[2022-11-02 18:33:09,631 {main.py:231}] <INFO> GC: check garbage []
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
