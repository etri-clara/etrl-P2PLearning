[2022-11-04 19:18:08,327 {main.py:152}] <INFO> Namespace(datadir='./data', outdir='./output/ring3', epochs=200, batch_size=100, seed=569, data_init_seed=11, model_init_seed=13, l2_lambda=0.01, model_name='resnet50', dataset_name='cifar10', train_data_length=10000, group_channels=32, drop_rate=0.1, last_drop_rate=0.5, cuda=True, cuda_device_no=3, plot=False, scheduler='StepLR', step_size=410, gamma=0.9, sleep_factor=0.0, loglevel=<LogLevel.INFO: 20>, logfile=None, optimizer='AdmmSGD', nodename='node2', conf='./conf/node_list.json', host='./conf/hosts.json', lr=0.002, mu=200, eta=1.0, rho=0.1, round_step=False, swap_timeout=10)
[2022-11-04 19:18:08,327 {main.py:247}] <INFO> {'nodes': {'node0': {'device': 'cuda', 'round': 10, 'edges': {'node2': 0, 'node1': 4}}, 'node1': {'device': 'cuda', 'round': 10, 'edges': {'node0': 1, 'node2': 5}}, 'node2': {'device': 'cuda', 'round': 10, 'edges': {'node1': 2, 'node0': 6}}}}
[2022-11-04 19:18:08,453 {dist_trainer.py:186}] <INFO> : <class 'model.resnet.ResNet'>
[2022-11-04 19:18:08,453 {dist_trainer.py:186}] <INFO> conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,453 {dist_trainer.py:183}] <INFO> bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-04 19:18:08,453 {dist_trainer.py:186}] <INFO> relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,453 {dist_trainer.py:186}] <INFO> maxpool: <class 'torch.nn.modules.pooling.MaxPool2d'>
[2022-11-04 19:18:08,453 {dist_trainer.py:186}] <INFO> dropout1: <class 'torch.nn.modules.dropout.Dropout2d'>
[2022-11-04 19:18:08,453 {dist_trainer.py:186}] <INFO> layer1: <class 'torch.nn.modules.container.Sequential'>
[2022-11-04 19:18:08,453 {dist_trainer.py:186}] <INFO> layer1.0: <class 'model.resnet.Bottleneck'>
[2022-11-04 19:18:08,453 {dist_trainer.py:186}] <INFO> layer1.0.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,453 {dist_trainer.py:183}] <INFO> layer1.0.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-04 19:18:08,453 {dist_trainer.py:186}] <INFO> layer1.0.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,453 {dist_trainer.py:183}] <INFO> layer1.0.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-04 19:18:08,453 {dist_trainer.py:186}] <INFO> layer1.0.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,454 {dist_trainer.py:183}] <INFO> layer1.0.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-04 19:18:08,454 {dist_trainer.py:186}] <INFO> layer1.0.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,454 {dist_trainer.py:186}] <INFO> layer1.0.downsample: <class 'torch.nn.modules.container.Sequential'>
[2022-11-04 19:18:08,454 {dist_trainer.py:186}] <INFO> layer1.0.downsample.0: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,454 {dist_trainer.py:183}] <INFO> layer1.0.downsample.1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-04 19:18:08,454 {dist_trainer.py:186}] <INFO> layer1.1: <class 'model.resnet.Bottleneck'>
[2022-11-04 19:18:08,454 {dist_trainer.py:186}] <INFO> layer1.1.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,454 {dist_trainer.py:183}] <INFO> layer1.1.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-04 19:18:08,454 {dist_trainer.py:186}] <INFO> layer1.1.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,454 {dist_trainer.py:183}] <INFO> layer1.1.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-04 19:18:08,454 {dist_trainer.py:186}] <INFO> layer1.1.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,454 {dist_trainer.py:183}] <INFO> layer1.1.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-04 19:18:08,454 {dist_trainer.py:186}] <INFO> layer1.1.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,454 {dist_trainer.py:186}] <INFO> layer1.2: <class 'model.resnet.Bottleneck'>
[2022-11-04 19:18:08,454 {dist_trainer.py:186}] <INFO> layer1.2.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,454 {dist_trainer.py:183}] <INFO> layer1.2.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-04 19:18:08,454 {dist_trainer.py:186}] <INFO> layer1.2.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,454 {dist_trainer.py:183}] <INFO> layer1.2.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-04 19:18:08,454 {dist_trainer.py:186}] <INFO> layer1.2.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,454 {dist_trainer.py:183}] <INFO> layer1.2.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-04 19:18:08,454 {dist_trainer.py:186}] <INFO> layer1.2.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,454 {dist_trainer.py:186}] <INFO> layer1.3: <class 'torch.nn.modules.dropout.Dropout2d'>
[2022-11-04 19:18:08,454 {dist_trainer.py:186}] <INFO> layer2: <class 'torch.nn.modules.container.Sequential'>
[2022-11-04 19:18:08,454 {dist_trainer.py:186}] <INFO> layer2.0: <class 'model.resnet.Bottleneck'>
[2022-11-04 19:18:08,454 {dist_trainer.py:186}] <INFO> layer2.0.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,454 {dist_trainer.py:183}] <INFO> layer2.0.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-04 19:18:08,454 {dist_trainer.py:186}] <INFO> layer2.0.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,454 {dist_trainer.py:183}] <INFO> layer2.0.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-04 19:18:08,454 {dist_trainer.py:186}] <INFO> layer2.0.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,454 {dist_trainer.py:183}] <INFO> layer2.0.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-04 19:18:08,454 {dist_trainer.py:186}] <INFO> layer2.0.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,454 {dist_trainer.py:186}] <INFO> layer2.0.downsample: <class 'torch.nn.modules.container.Sequential'>
[2022-11-04 19:18:08,454 {dist_trainer.py:186}] <INFO> layer2.0.downsample.0: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,454 {dist_trainer.py:183}] <INFO> layer2.0.downsample.1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-04 19:18:08,454 {dist_trainer.py:186}] <INFO> layer2.1: <class 'model.resnet.Bottleneck'>
[2022-11-04 19:18:08,454 {dist_trainer.py:186}] <INFO> layer2.1.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,454 {dist_trainer.py:183}] <INFO> layer2.1.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-04 19:18:08,455 {dist_trainer.py:186}] <INFO> layer2.1.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,455 {dist_trainer.py:183}] <INFO> layer2.1.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-04 19:18:08,455 {dist_trainer.py:186}] <INFO> layer2.1.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,455 {dist_trainer.py:183}] <INFO> layer2.1.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-04 19:18:08,455 {dist_trainer.py:186}] <INFO> layer2.1.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,455 {dist_trainer.py:186}] <INFO> layer2.2: <class 'model.resnet.Bottleneck'>
[2022-11-04 19:18:08,455 {dist_trainer.py:186}] <INFO> layer2.2.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,455 {dist_trainer.py:183}] <INFO> layer2.2.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-04 19:18:08,455 {dist_trainer.py:186}] <INFO> layer2.2.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,455 {dist_trainer.py:183}] <INFO> layer2.2.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-04 19:18:08,455 {dist_trainer.py:186}] <INFO> layer2.2.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,455 {dist_trainer.py:183}] <INFO> layer2.2.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-04 19:18:08,455 {dist_trainer.py:186}] <INFO> layer2.2.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,455 {dist_trainer.py:186}] <INFO> layer2.3: <class 'model.resnet.Bottleneck'>
[2022-11-04 19:18:08,455 {dist_trainer.py:186}] <INFO> layer2.3.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,455 {dist_trainer.py:183}] <INFO> layer2.3.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-04 19:18:08,455 {dist_trainer.py:186}] <INFO> layer2.3.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,455 {dist_trainer.py:183}] <INFO> layer2.3.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-04 19:18:08,455 {dist_trainer.py:186}] <INFO> layer2.3.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,455 {dist_trainer.py:183}] <INFO> layer2.3.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-04 19:18:08,455 {dist_trainer.py:186}] <INFO> layer2.3.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,455 {dist_trainer.py:186}] <INFO> layer2.4: <class 'torch.nn.modules.dropout.Dropout2d'>
[2022-11-04 19:18:08,455 {dist_trainer.py:186}] <INFO> layer3: <class 'torch.nn.modules.container.Sequential'>
[2022-11-04 19:18:08,455 {dist_trainer.py:186}] <INFO> layer3.0: <class 'model.resnet.Bottleneck'>
[2022-11-04 19:18:08,455 {dist_trainer.py:186}] <INFO> layer3.0.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,455 {dist_trainer.py:183}] <INFO> layer3.0.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-04 19:18:08,455 {dist_trainer.py:186}] <INFO> layer3.0.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,455 {dist_trainer.py:183}] <INFO> layer3.0.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-04 19:18:08,455 {dist_trainer.py:186}] <INFO> layer3.0.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,455 {dist_trainer.py:183}] <INFO> layer3.0.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-04 19:18:08,455 {dist_trainer.py:186}] <INFO> layer3.0.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,455 {dist_trainer.py:186}] <INFO> layer3.0.downsample: <class 'torch.nn.modules.container.Sequential'>
[2022-11-04 19:18:08,455 {dist_trainer.py:186}] <INFO> layer3.0.downsample.0: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,455 {dist_trainer.py:183}] <INFO> layer3.0.downsample.1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-04 19:18:08,455 {dist_trainer.py:186}] <INFO> layer3.1: <class 'model.resnet.Bottleneck'>
[2022-11-04 19:18:08,456 {dist_trainer.py:186}] <INFO> layer3.1.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,456 {dist_trainer.py:183}] <INFO> layer3.1.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-04 19:18:08,456 {dist_trainer.py:186}] <INFO> layer3.1.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,456 {dist_trainer.py:183}] <INFO> layer3.1.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-04 19:18:08,456 {dist_trainer.py:186}] <INFO> layer3.1.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,456 {dist_trainer.py:183}] <INFO> layer3.1.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-04 19:18:08,456 {dist_trainer.py:186}] <INFO> layer3.1.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,456 {dist_trainer.py:186}] <INFO> layer3.2: <class 'model.resnet.Bottleneck'>
[2022-11-04 19:18:08,456 {dist_trainer.py:186}] <INFO> layer3.2.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,456 {dist_trainer.py:183}] <INFO> layer3.2.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-04 19:18:08,456 {dist_trainer.py:186}] <INFO> layer3.2.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,456 {dist_trainer.py:183}] <INFO> layer3.2.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-04 19:18:08,456 {dist_trainer.py:186}] <INFO> layer3.2.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,456 {dist_trainer.py:183}] <INFO> layer3.2.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-04 19:18:08,456 {dist_trainer.py:186}] <INFO> layer3.2.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,456 {dist_trainer.py:186}] <INFO> layer3.3: <class 'model.resnet.Bottleneck'>
[2022-11-04 19:18:08,456 {dist_trainer.py:186}] <INFO> layer3.3.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,456 {dist_trainer.py:183}] <INFO> layer3.3.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-04 19:18:08,456 {dist_trainer.py:186}] <INFO> layer3.3.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,456 {dist_trainer.py:183}] <INFO> layer3.3.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-04 19:18:08,456 {dist_trainer.py:186}] <INFO> layer3.3.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,456 {dist_trainer.py:183}] <INFO> layer3.3.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-04 19:18:08,456 {dist_trainer.py:186}] <INFO> layer3.3.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,456 {dist_trainer.py:186}] <INFO> layer3.4: <class 'model.resnet.Bottleneck'>
[2022-11-04 19:18:08,456 {dist_trainer.py:186}] <INFO> layer3.4.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,456 {dist_trainer.py:183}] <INFO> layer3.4.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-04 19:18:08,456 {dist_trainer.py:186}] <INFO> layer3.4.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,456 {dist_trainer.py:183}] <INFO> layer3.4.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-04 19:18:08,456 {dist_trainer.py:186}] <INFO> layer3.4.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,456 {dist_trainer.py:183}] <INFO> layer3.4.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-04 19:18:08,456 {dist_trainer.py:186}] <INFO> layer3.4.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,457 {dist_trainer.py:186}] <INFO> layer3.5: <class 'model.resnet.Bottleneck'>
[2022-11-04 19:18:08,457 {dist_trainer.py:186}] <INFO> layer3.5.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,457 {dist_trainer.py:183}] <INFO> layer3.5.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-04 19:18:08,457 {dist_trainer.py:186}] <INFO> layer3.5.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,457 {dist_trainer.py:183}] <INFO> layer3.5.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-04 19:18:08,457 {dist_trainer.py:186}] <INFO> layer3.5.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,457 {dist_trainer.py:183}] <INFO> layer3.5.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-04 19:18:08,457 {dist_trainer.py:186}] <INFO> layer3.5.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,457 {dist_trainer.py:186}] <INFO> layer3.6: <class 'torch.nn.modules.dropout.Dropout2d'>
[2022-11-04 19:18:08,457 {dist_trainer.py:186}] <INFO> layer4: <class 'torch.nn.modules.container.Sequential'>
[2022-11-04 19:18:08,457 {dist_trainer.py:186}] <INFO> layer4.0: <class 'model.resnet.Bottleneck'>
[2022-11-04 19:18:08,457 {dist_trainer.py:186}] <INFO> layer4.0.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,457 {dist_trainer.py:183}] <INFO> layer4.0.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-04 19:18:08,457 {dist_trainer.py:186}] <INFO> layer4.0.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,457 {dist_trainer.py:183}] <INFO> layer4.0.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-04 19:18:08,457 {dist_trainer.py:186}] <INFO> layer4.0.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,457 {dist_trainer.py:183}] <INFO> layer4.0.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 64, channels: 2048, eps: 0.000010, affine: True
[2022-11-04 19:18:08,457 {dist_trainer.py:186}] <INFO> layer4.0.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,457 {dist_trainer.py:186}] <INFO> layer4.0.downsample: <class 'torch.nn.modules.container.Sequential'>
[2022-11-04 19:18:08,457 {dist_trainer.py:186}] <INFO> layer4.0.downsample.0: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,457 {dist_trainer.py:183}] <INFO> layer4.0.downsample.1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 64, channels: 2048, eps: 0.000010, affine: True
[2022-11-04 19:18:08,457 {dist_trainer.py:186}] <INFO> layer4.1: <class 'model.resnet.Bottleneck'>
[2022-11-04 19:18:08,457 {dist_trainer.py:186}] <INFO> layer4.1.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,457 {dist_trainer.py:183}] <INFO> layer4.1.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-04 19:18:08,457 {dist_trainer.py:186}] <INFO> layer4.1.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,457 {dist_trainer.py:183}] <INFO> layer4.1.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-04 19:18:08,457 {dist_trainer.py:186}] <INFO> layer4.1.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,457 {dist_trainer.py:183}] <INFO> layer4.1.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 64, channels: 2048, eps: 0.000010, affine: True
[2022-11-04 19:18:08,457 {dist_trainer.py:186}] <INFO> layer4.1.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,457 {dist_trainer.py:186}] <INFO> layer4.2: <class 'model.resnet.Bottleneck'>
[2022-11-04 19:18:08,457 {dist_trainer.py:186}] <INFO> layer4.2.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,458 {dist_trainer.py:183}] <INFO> layer4.2.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-04 19:18:08,458 {dist_trainer.py:186}] <INFO> layer4.2.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,458 {dist_trainer.py:183}] <INFO> layer4.2.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-04 19:18:08,458 {dist_trainer.py:186}] <INFO> layer4.2.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,458 {dist_trainer.py:183}] <INFO> layer4.2.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 64, channels: 2048, eps: 0.000010, affine: True
[2022-11-04 19:18:08,458 {dist_trainer.py:186}] <INFO> layer4.2.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,458 {dist_trainer.py:186}] <INFO> avgpool: <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>
[2022-11-04 19:18:08,458 {dist_trainer.py:186}] <INFO> dropout_fc: <class 'torch.nn.modules.dropout.Dropout'>
[2022-11-04 19:18:08,458 {dist_trainer.py:186}] <INFO> fc: <class 'torch.nn.modules.linear.Linear'>
[2022-11-04 19:18:08,458 {dist_trainer.py:192}] <INFO> parameter size: conv1.weight 37632B
[2022-11-04 19:18:08,458 {dist_trainer.py:192}] <INFO> parameter size: bn1.weight 256B
[2022-11-04 19:18:08,458 {dist_trainer.py:192}] <INFO> parameter size: bn1.bias 256B
[2022-11-04 19:18:08,458 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.conv1.weight 16384B
[2022-11-04 19:18:08,458 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.bn1.weight 256B
[2022-11-04 19:18:08,458 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.bn1.bias 256B
[2022-11-04 19:18:08,458 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.conv2.weight 147456B
[2022-11-04 19:18:08,458 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.bn2.weight 256B
[2022-11-04 19:18:08,458 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.bn2.bias 256B
[2022-11-04 19:18:08,458 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.conv3.weight 65536B
[2022-11-04 19:18:08,459 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.bn3.weight 1024B
[2022-11-04 19:18:08,459 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.bn3.bias 1024B
[2022-11-04 19:18:08,459 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.downsample.0.weight 65536B
[2022-11-04 19:18:08,459 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.downsample.1.weight 1024B
[2022-11-04 19:18:08,459 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.downsample.1.bias 1024B
[2022-11-04 19:18:08,459 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.conv1.weight 65536B
[2022-11-04 19:18:08,459 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.bn1.weight 256B
[2022-11-04 19:18:08,459 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.bn1.bias 256B
[2022-11-04 19:18:08,459 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.conv2.weight 147456B
[2022-11-04 19:18:08,459 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.bn2.weight 256B
[2022-11-04 19:18:08,459 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.bn2.bias 256B
[2022-11-04 19:18:08,459 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.conv3.weight 65536B
[2022-11-04 19:18:08,459 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.bn3.weight 1024B
[2022-11-04 19:18:08,459 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.bn3.bias 1024B
[2022-11-04 19:18:08,459 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.conv1.weight 65536B
[2022-11-04 19:18:08,459 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.bn1.weight 256B
[2022-11-04 19:18:08,459 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.bn1.bias 256B
[2022-11-04 19:18:08,459 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.conv2.weight 147456B
[2022-11-04 19:18:08,459 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.bn2.weight 256B
[2022-11-04 19:18:08,460 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.bn2.bias 256B
[2022-11-04 19:18:08,460 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.conv3.weight 65536B
[2022-11-04 19:18:08,460 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.bn3.weight 1024B
[2022-11-04 19:18:08,460 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.bn3.bias 1024B
[2022-11-04 19:18:08,460 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.conv1.weight 131072B
[2022-11-04 19:18:08,460 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.bn1.weight 512B
[2022-11-04 19:18:08,460 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.bn1.bias 512B
[2022-11-04 19:18:08,460 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.conv2.weight 589824B
[2022-11-04 19:18:08,460 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.bn2.weight 512B
[2022-11-04 19:18:08,460 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.bn2.bias 512B
[2022-11-04 19:18:08,460 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.conv3.weight 262144B
[2022-11-04 19:18:08,460 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.bn3.weight 2048B
[2022-11-04 19:18:08,460 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.bn3.bias 2048B
[2022-11-04 19:18:08,460 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.downsample.0.weight 524288B
[2022-11-04 19:18:08,460 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.downsample.1.weight 2048B
[2022-11-04 19:18:08,460 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.downsample.1.bias 2048B
[2022-11-04 19:18:08,460 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.conv1.weight 262144B
[2022-11-04 19:18:08,460 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.bn1.weight 512B
[2022-11-04 19:18:08,460 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.bn1.bias 512B
[2022-11-04 19:18:08,461 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.conv2.weight 589824B
[2022-11-04 19:18:08,461 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.bn2.weight 512B
[2022-11-04 19:18:08,461 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.bn2.bias 512B
[2022-11-04 19:18:08,461 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.conv3.weight 262144B
[2022-11-04 19:18:08,461 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.bn3.weight 2048B
[2022-11-04 19:18:08,461 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.bn3.bias 2048B
[2022-11-04 19:18:08,461 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.conv1.weight 262144B
[2022-11-04 19:18:08,461 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.bn1.weight 512B
[2022-11-04 19:18:08,461 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.bn1.bias 512B
[2022-11-04 19:18:08,461 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.conv2.weight 589824B
[2022-11-04 19:18:08,461 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.bn2.weight 512B
[2022-11-04 19:18:08,461 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.bn2.bias 512B
[2022-11-04 19:18:08,461 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.conv3.weight 262144B
[2022-11-04 19:18:08,461 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.bn3.weight 2048B
[2022-11-04 19:18:08,461 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.bn3.bias 2048B
[2022-11-04 19:18:08,461 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.conv1.weight 262144B
[2022-11-04 19:18:08,461 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.bn1.weight 512B
[2022-11-04 19:18:08,461 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.bn1.bias 512B
[2022-11-04 19:18:08,461 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.conv2.weight 589824B
[2022-11-04 19:18:08,462 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.bn2.weight 512B
[2022-11-04 19:18:08,462 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.bn2.bias 512B
[2022-11-04 19:18:08,462 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.conv3.weight 262144B
[2022-11-04 19:18:08,462 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.bn3.weight 2048B
[2022-11-04 19:18:08,462 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.bn3.bias 2048B
[2022-11-04 19:18:08,462 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.conv1.weight 524288B
[2022-11-04 19:18:08,462 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.bn1.weight 1024B
[2022-11-04 19:18:08,462 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.bn1.bias 1024B
[2022-11-04 19:18:08,462 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.conv2.weight 2359296B
[2022-11-04 19:18:08,462 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.bn2.weight 1024B
[2022-11-04 19:18:08,462 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.bn2.bias 1024B
[2022-11-04 19:18:08,462 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.conv3.weight 1048576B
[2022-11-04 19:18:08,462 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.bn3.weight 4096B
[2022-11-04 19:18:08,462 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.bn3.bias 4096B
[2022-11-04 19:18:08,462 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.downsample.0.weight 2097152B
[2022-11-04 19:18:08,462 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.downsample.1.weight 4096B
[2022-11-04 19:18:08,462 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.downsample.1.bias 4096B
[2022-11-04 19:18:08,462 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.conv1.weight 1048576B
[2022-11-04 19:18:08,462 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.bn1.weight 1024B
[2022-11-04 19:18:08,463 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.bn1.bias 1024B
[2022-11-04 19:18:08,463 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.conv2.weight 2359296B
[2022-11-04 19:18:08,463 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.bn2.weight 1024B
[2022-11-04 19:18:08,463 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.bn2.bias 1024B
[2022-11-04 19:18:08,463 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.conv3.weight 1048576B
[2022-11-04 19:18:08,463 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.bn3.weight 4096B
[2022-11-04 19:18:08,463 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.bn3.bias 4096B
[2022-11-04 19:18:08,463 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.conv1.weight 1048576B
[2022-11-04 19:18:08,463 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.bn1.weight 1024B
[2022-11-04 19:18:08,463 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.bn1.bias 1024B
[2022-11-04 19:18:08,463 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.conv2.weight 2359296B
[2022-11-04 19:18:08,463 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.bn2.weight 1024B
[2022-11-04 19:18:08,463 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.bn2.bias 1024B
[2022-11-04 19:18:08,463 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.conv3.weight 1048576B
[2022-11-04 19:18:08,463 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.bn3.weight 4096B
[2022-11-04 19:18:08,463 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.bn3.bias 4096B
[2022-11-04 19:18:08,463 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.conv1.weight 1048576B
[2022-11-04 19:18:08,463 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.bn1.weight 1024B
[2022-11-04 19:18:08,463 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.bn1.bias 1024B
[2022-11-04 19:18:08,464 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.conv2.weight 2359296B
[2022-11-04 19:18:08,466 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.bn2.weight 1024B
[2022-11-04 19:18:08,466 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.bn2.bias 1024B
[2022-11-04 19:18:08,467 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.conv3.weight 1048576B
[2022-11-04 19:18:08,467 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.bn3.weight 4096B
[2022-11-04 19:18:08,467 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.bn3.bias 4096B
[2022-11-04 19:18:08,467 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.conv1.weight 1048576B
[2022-11-04 19:18:08,467 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.bn1.weight 1024B
[2022-11-04 19:18:08,467 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.bn1.bias 1024B
[2022-11-04 19:18:08,467 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.conv2.weight 2359296B
[2022-11-04 19:18:08,467 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.bn2.weight 1024B
[2022-11-04 19:18:08,467 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.bn2.bias 1024B
[2022-11-04 19:18:08,467 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.conv3.weight 1048576B
[2022-11-04 19:18:08,467 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.bn3.weight 4096B
[2022-11-04 19:18:08,467 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.bn3.bias 4096B
[2022-11-04 19:18:08,467 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.conv1.weight 1048576B
[2022-11-04 19:18:08,467 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.bn1.weight 1024B
[2022-11-04 19:18:08,467 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.bn1.bias 1024B
[2022-11-04 19:18:08,467 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.conv2.weight 2359296B
[2022-11-04 19:18:08,467 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.bn2.weight 1024B
[2022-11-04 19:18:08,467 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.bn2.bias 1024B
[2022-11-04 19:18:08,468 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.conv3.weight 1048576B
[2022-11-04 19:18:08,468 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.bn3.weight 4096B
[2022-11-04 19:18:08,468 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.bn3.bias 4096B
[2022-11-04 19:18:08,468 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.conv1.weight 2097152B
[2022-11-04 19:18:08,468 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.bn1.weight 2048B
[2022-11-04 19:18:08,468 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.bn1.bias 2048B
[2022-11-04 19:18:08,468 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.conv2.weight 9437184B
[2022-11-04 19:18:08,468 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.bn2.weight 2048B
[2022-11-04 19:18:08,468 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.bn2.bias 2048B
[2022-11-04 19:18:08,468 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.conv3.weight 4194304B
[2022-11-04 19:18:08,468 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.bn3.weight 8192B
[2022-11-04 19:18:08,468 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.bn3.bias 8192B
[2022-11-04 19:18:08,468 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.downsample.0.weight 8388608B
[2022-11-04 19:18:08,468 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.downsample.1.weight 8192B
[2022-11-04 19:18:08,468 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.downsample.1.bias 8192B
[2022-11-04 19:18:08,468 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.conv1.weight 4194304B
[2022-11-04 19:18:08,469 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.bn1.weight 2048B
[2022-11-04 19:18:08,469 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.bn1.bias 2048B
[2022-11-04 19:18:08,469 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.conv2.weight 9437184B
[2022-11-04 19:18:08,469 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.bn2.weight 2048B
[2022-11-04 19:18:08,469 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.bn2.bias 2048B
[2022-11-04 19:18:08,469 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.conv3.weight 4194304B
[2022-11-04 19:18:08,469 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.bn3.weight 8192B
[2022-11-04 19:18:08,469 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.bn3.bias 8192B
[2022-11-04 19:18:08,469 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.conv1.weight 4194304B
[2022-11-04 19:18:08,469 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.bn1.weight 2048B
[2022-11-04 19:18:08,469 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.bn1.bias 2048B
[2022-11-04 19:18:08,469 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.conv2.weight 9437184B
[2022-11-04 19:18:08,469 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.bn2.weight 2048B
[2022-11-04 19:18:08,469 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.bn2.bias 2048B
[2022-11-04 19:18:08,469 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.conv3.weight 4194304B
[2022-11-04 19:18:08,469 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.bn3.weight 8192B
[2022-11-04 19:18:08,469 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.bn3.bias 8192B
[2022-11-04 19:18:08,470 {dist_trainer.py:192}] <INFO> parameter size: fc.weight 81920B
[2022-11-04 19:18:08,470 {dist_trainer.py:192}] <INFO> parameter size: fc.bias 40B
[2022-11-04 19:18:08,470 {dist_trainer.py:194}] <INFO> Model: resnet50 size: 89.754MiB
[2022-11-04 19:18:13,662 {dist_trainer.py:78}] <INFO> device: cuda:3 0/4, NVIDIA TITAN RTX
[2022-11-04 19:18:14,963 {dist_trainer.py:494}] <INFO> node0: [7,8,2,6,4,5,1,3]
[2022-11-04 19:18:14,963 {dist_trainer.py:494}] <INFO> node1: [4,5,1,3,0,9,7,8]
[2022-11-04 19:18:14,963 {dist_trainer.py:494}] <INFO> node2: [0,9,7,8,2,6,4,5]
[2022-11-04 19:18:14,964 {dist_trainer.py:497}] <INFO> class 0, [node1:0.472,node2:0.528]
[2022-11-04 19:18:14,964 {dist_trainer.py:497}] <INFO> class 1, [node0:0.505,node1:0.495]
[2022-11-04 19:18:14,964 {dist_trainer.py:497}] <INFO> class 2, [node0:0.535,node2:0.465]
[2022-11-04 19:18:14,964 {dist_trainer.py:497}] <INFO> class 3, [node0:0.502,node1:0.498]
[2022-11-04 19:18:14,964 {dist_trainer.py:497}] <INFO> class 4, [node0:0.325,node1:0.361,node2:0.314]
[2022-11-04 19:18:14,964 {dist_trainer.py:497}] <INFO> class 5, [node0:0.327,node1:0.343,node2:0.330]
[2022-11-04 19:18:14,964 {dist_trainer.py:497}] <INFO> class 6, [node0:0.497,node2:0.503]
[2022-11-04 19:18:14,964 {dist_trainer.py:497}] <INFO> class 7, [node0:0.340,node1:0.338,node2:0.322]
[2022-11-04 19:18:14,964 {dist_trainer.py:497}] <INFO> class 8, [node0:0.305,node1:0.352,node2:0.343]
[2022-11-04 19:18:14,964 {dist_trainer.py:497}] <INFO> class 9, [node1:0.475,node2:0.525]
[2022-11-04 19:18:14,965 {dist_trainer.py:527}] <INFO> train data node0: 1:2523,2:2675,3:2509,4:1624,5:1634,6:2484,7:1700,8:1524
[2022-11-04 19:18:14,966 {dist_trainer.py:527}] <INFO> train data node1: 0:2360,1:2477,3:2491,4:1806,5:1714,7:1690,8:1758,9:2375
[2022-11-04 19:18:14,966 {dist_trainer.py:527}] <INFO> train data node2: 0:2640,2:2325,4:1570,5:1652,6:2516,7:1610,8:1718,9:2625
[2022-11-04 19:18:28,019 {dist_trainer.py:531}] <INFO> split_load_datas(END)
[2022-11-04 19:18:28,020 {dist_trainer.py:114}] <INFO> datasets(END)
[2022-11-04 19:18:28,020 {dist_trainer.py:713}] <INFO> build_criterion(1)
[2022-11-04 19:18:28,020 {dist_trainer.py:721}] <INFO> build_criterion(2)
[2022-11-04 19:18:28,035 {contract.py:21}] <INFO> 0
[2022-11-04 19:18:28,035 {contract.py:21}] <INFO> 1
[2022-11-04 19:18:28,036 {contract.py:21}] <INFO> 2
[2022-11-04 19:18:28,098 {distributed_c10d.py:228}] <INFO> Added key: store_based_barrier_key:1 to store for rank: 2
[2022-11-04 19:18:28,098 {distributed_c10d.py:262}] <INFO> Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
[2022-11-04 19:18:28,227 {gateway.py:85}] <INFO> node1
[2022-11-04 19:18:28,301 {gateway.py:85}] <INFO> node0
[2022-11-04 19:18:28,307 {contract.py:36}] <INFO> contract(1)
[2022-11-04 19:18:28,382 {contract.py:44}] <INFO> <CLI> node2 : edge setup.
[2022-11-04 19:18:28,407 {gateway.py:59}] <INFO> <SRV> node2 : edge setup.
[2022-11-04 19:18:29,212 {contract.py:59}] <INFO> contract(2)
[2022-11-04 19:18:29,213 {admm_sgd.py:51}] <INFO> Optimizer <class 'optimizer.admm_sgd.AdmmSGD'> params: {'lr': 0.005, 'mu': 200, 'eta': 1.0, 'rho': 0.1, 'initial_lr': 0.005, 'eta_rate': 0.005}
[2022-11-04 19:18:29,213 {dist_trainer.py:725}] <INFO> build_optimizer()
[2022-11-04 19:18:29,214 {dist_trainer.py:736}] <INFO> Setup scheduler: <torch.optim.lr_scheduler.StepLR object at 0x7f558e0b5490>
[2022-11-04 19:19:08,261 {dist_trainer.py:770}] <INFO> [   1/ 200] connecting edge count: 2
[2022-11-04 19:20:01,487 {dist_trainer.py:821}] <INFO> [   1/ 200] loss: (train=2.606, val=2.595, test=2.595, l2=12465.201), acc: (train=0.151, val=0.109, test=0.110), diff=0.00022920, proc(train=39.047sec, eval=51.513sec)
[2022-11-04 19:20:40,162 {dist_trainer.py:770}] <INFO> [   2/ 200] connecting edge count: 2
[2022-11-04 19:21:28,566 {dist_trainer.py:821}] <INFO> [   2/ 200] loss: (train=2.504, val=2.413, test=2.403, l2=12449.946), acc: (train=0.193, val=0.138, test=0.137), diff=0.00000749, proc(train=38.674sec, eval=47.173sec)
[2022-11-04 19:22:06,526 {dist_trainer.py:770}] <INFO> [   3/ 200] connecting edge count: 2
[2022-11-04 19:22:54,459 {dist_trainer.py:821}] <INFO> [   3/ 200] loss: (train=2.204, val=2.252, test=2.256, l2=12376.030), acc: (train=0.192, val=0.177, test=0.172), diff=0.00000094, proc(train=37.959sec, eval=46.247sec)
[2022-11-04 19:23:32,400 {dist_trainer.py:770}] <INFO> [   4/ 200] connecting edge count: 2
[2022-11-04 19:24:24,986 {dist_trainer.py:821}] <INFO> [   4/ 200] loss: (train=2.095, val=2.058, test=2.049, l2=12307.488), acc: (train=0.262, val=0.218, test=0.217), diff=0.00000181, proc(train=37.940sec, eval=50.996sec)
[2022-11-04 19:25:03,785 {dist_trainer.py:770}] <INFO> [   5/ 200] connecting edge count: 2
[2022-11-04 19:25:51,664 {dist_trainer.py:821}] <INFO> [   5/ 200] loss: (train=2.002, val=1.918, test=1.906, l2=12236.867), acc: (train=0.381, val=0.266, test=0.275), diff=0.00000157, proc(train=38.799sec, eval=46.712sec)
[2022-11-04 19:26:30,547 {dist_trainer.py:770}] <INFO> [   6/ 200] connecting edge count: 2
[2022-11-04 19:27:19,733 {dist_trainer.py:821}] <INFO> [   6/ 200] loss: (train=1.934, val=1.998, test=1.993, l2=12151.454), acc: (train=0.399, val=0.279, test=0.281), diff=0.00000102, proc(train=38.883sec, eval=47.581sec)
[2022-11-04 19:27:55,806 {dist_trainer.py:770}] <INFO> [   7/ 200] connecting edge count: 2
[2022-11-04 19:28:48,799 {dist_trainer.py:821}] <INFO> [   7/ 200] loss: (train=1.910, val=1.869, test=1.869, l2=12086.685), acc: (train=0.308, val=0.298, test=0.298), diff=0.00000170, proc(train=36.073sec, eval=51.373sec)
[2022-11-04 19:29:27,835 {dist_trainer.py:770}] <INFO> [   8/ 200] connecting edge count: 2
[2022-11-04 19:30:14,293 {dist_trainer.py:821}] <INFO> [   8/ 200] loss: (train=1.837, val=1.746, test=1.737, l2=12010.122), acc: (train=0.414, val=0.342, test=0.347), diff=0.00000138, proc(train=39.035sec, eval=45.280sec)
[2022-11-04 19:30:52,790 {dist_trainer.py:770}] <INFO> [   9/ 200] connecting edge count: 2
[2022-11-04 19:31:41,756 {dist_trainer.py:821}] <INFO> [   9/ 200] loss: (train=1.819, val=1.717, test=1.710, l2=11930.077), acc: (train=0.479, val=0.361, test=0.365), diff=0.00000120, proc(train=38.497sec, eval=46.909sec)
[2022-11-04 19:32:20,931 {dist_trainer.py:770}] <INFO> [  10/ 200] connecting edge count: 2
[2022-11-04 19:33:12,601 {dist_trainer.py:821}] <INFO> [  10/ 200] loss: (train=1.776, val=1.890, test=1.880, l2=11860.484), acc: (train=0.403, val=0.319, test=0.320), diff=0.00000156, proc(train=39.174sec, eval=50.142sec)
[2022-11-04 19:33:51,045 {dist_trainer.py:770}] <INFO> [  11/ 200] connecting edge count: 2
[2022-11-04 19:34:38,620 {dist_trainer.py:821}] <INFO> [  11/ 200] loss: (train=1.716, val=1.624, test=1.620, l2=11799.774), acc: (train=0.475, val=0.399, test=0.397), diff=0.00000118, proc(train=38.444sec, eval=46.246sec)
[2022-11-04 19:35:18,523 {dist_trainer.py:770}] <INFO> [  12/ 200] connecting edge count: 2
[2022-11-04 19:36:10,206 {dist_trainer.py:821}] <INFO> [  12/ 200] loss: (train=1.723, val=1.828, test=1.829, l2=11720.220), acc: (train=0.389, val=0.363, test=0.364), diff=0.00000101, proc(train=39.903sec, eval=50.011sec)
[2022-11-04 19:36:49,240 {dist_trainer.py:770}] <INFO> [  13/ 200] connecting edge count: 2
[2022-11-04 19:37:40,755 {dist_trainer.py:821}] <INFO> [  13/ 200] loss: (train=1.651, val=1.592, test=1.604, l2=11640.397), acc: (train=0.455, val=0.416, test=0.408), diff=0.00000129, proc(train=39.034sec, eval=50.313sec)
[2022-11-04 19:38:20,001 {dist_trainer.py:770}] <INFO> [  14/ 200] connecting edge count: 2
[2022-11-04 19:39:05,270 {dist_trainer.py:821}] <INFO> [  14/ 200] loss: (train=1.638, val=1.600, test=1.607, l2=11566.233), acc: (train=0.436, val=0.430, test=0.428), diff=0.00000115, proc(train=39.246sec, eval=44.051sec)
[2022-11-04 19:39:44,664 {dist_trainer.py:770}] <INFO> [  15/ 200] connecting edge count: 2
[2022-11-04 19:40:37,666 {dist_trainer.py:821}] <INFO> [  15/ 200] loss: (train=1.605, val=1.590, test=1.596, l2=11494.909), acc: (train=0.481, val=0.425, test=0.418), diff=0.00000102, proc(train=39.394sec, eval=51.308sec)
[2022-11-04 19:41:17,034 {dist_trainer.py:770}] <INFO> [  16/ 200] connecting edge count: 2
[2022-11-04 19:42:06,664 {dist_trainer.py:821}] <INFO> [  16/ 200] loss: (train=1.592, val=1.501, test=1.520, l2=11423.755), acc: (train=0.469, val=0.448, test=0.449), diff=0.00000146, proc(train=39.367sec, eval=48.399sec)
[2022-11-04 19:42:45,400 {dist_trainer.py:770}] <INFO> [  17/ 200] connecting edge count: 2
[2022-11-04 19:43:31,368 {dist_trainer.py:821}] <INFO> [  17/ 200] loss: (train=1.568, val=1.669, test=1.685, l2=11347.905), acc: (train=0.505, val=0.410, test=0.405), diff=0.00000157, proc(train=38.735sec, eval=44.659sec)
[2022-11-04 19:44:11,152 {dist_trainer.py:770}] <INFO> [  18/ 200] connecting edge count: 2
[2022-11-04 19:45:03,862 {dist_trainer.py:821}] <INFO> [  18/ 200] loss: (train=1.554, val=1.514, test=1.537, l2=11281.183), acc: (train=0.516, val=0.457, test=0.449), diff=0.00000123, proc(train=39.784sec, eval=51.039sec)
[2022-11-04 19:45:41,392 {dist_trainer.py:770}] <INFO> [  19/ 200] connecting edge count: 2
[2022-11-04 19:46:28,764 {dist_trainer.py:821}] <INFO> [  19/ 200] loss: (train=1.539, val=1.390, test=1.408, l2=11211.914), acc: (train=0.523, val=0.497, test=0.490), diff=0.00000185, proc(train=37.530sec, eval=46.321sec)
[2022-11-04 19:47:06,456 {dist_trainer.py:770}] <INFO> [  20/ 200] connecting edge count: 2
[2022-11-04 19:47:54,334 {dist_trainer.py:821}] <INFO> [  20/ 200] loss: (train=1.465, val=1.435, test=1.454, l2=11143.611), acc: (train=0.532, val=0.481, test=0.477), diff=0.00000175, proc(train=37.692sec, eval=46.624sec)
[2022-11-04 19:48:32,533 {dist_trainer.py:770}] <INFO> [  21/ 200] connecting edge count: 2
[2022-11-04 19:49:25,450 {dist_trainer.py:821}] <INFO> [  21/ 200] loss: (train=1.498, val=1.381, test=1.402, l2=11072.980), acc: (train=0.504, val=0.499, test=0.492), diff=0.00000118, proc(train=38.198sec, eval=51.409sec)
[2022-11-04 19:50:04,291 {dist_trainer.py:770}] <INFO> [  22/ 200] connecting edge count: 2
[2022-11-04 19:50:52,340 {dist_trainer.py:821}] <INFO> [  22/ 200] loss: (train=1.479, val=1.380, test=1.407, l2=11004.066), acc: (train=0.511, val=0.506, test=0.496), diff=0.00000141, proc(train=38.841sec, eval=46.584sec)
[2022-11-04 19:51:31,483 {dist_trainer.py:770}] <INFO> [  23/ 200] connecting edge count: 2
[2022-11-04 19:52:19,172 {dist_trainer.py:821}] <INFO> [  23/ 200] loss: (train=1.425, val=1.347, test=1.382, l2=10947.143), acc: (train=0.546, val=0.518, test=0.507), diff=0.00000126, proc(train=39.143sec, eval=46.215sec)
[2022-11-04 19:52:58,979 {dist_trainer.py:770}] <INFO> [  24/ 200] connecting edge count: 2
[2022-11-04 19:53:47,366 {dist_trainer.py:821}] <INFO> [  24/ 200] loss: (train=1.406, val=1.326, test=1.360, l2=10899.642), acc: (train=0.560, val=0.523, test=0.508), diff=0.02281804, proc(train=39.807sec, eval=46.922sec)
[2022-11-04 19:54:26,264 {dist_trainer.py:770}] <INFO> [  25/ 200] connecting edge count: 2
[2022-11-04 19:55:15,466 {dist_trainer.py:821}] <INFO> [  25/ 200] loss: (train=1.372, val=1.321, test=1.353, l2=9658.028), acc: (train=0.577, val=0.523, test=0.514), diff=0.00018574, proc(train=38.898sec, eval=47.960sec)
[2022-11-04 19:55:54,230 {dist_trainer.py:770}] <INFO> [  26/ 200] connecting edge count: 2
[2022-11-04 19:56:41,982 {dist_trainer.py:821}] <INFO> [  26/ 200] loss: (train=1.339, val=1.331, test=1.356, l2=9555.349), acc: (train=0.570, val=0.524, test=0.516), diff=0.00000291, proc(train=38.764sec, eval=46.141sec)
[2022-11-04 19:57:19,563 {dist_trainer.py:770}] <INFO> [  27/ 200] connecting edge count: 2
[2022-11-04 19:58:08,414 {dist_trainer.py:821}] <INFO> [  27/ 200] loss: (train=1.345, val=1.314, test=1.346, l2=9515.102), acc: (train=0.603, val=0.525, test=0.518), diff=0.00000136, proc(train=37.581sec, eval=47.313sec)
[2022-11-04 19:58:47,867 {dist_trainer.py:770}] <INFO> [  28/ 200] connecting edge count: 2
[2022-11-04 19:59:38,138 {dist_trainer.py:821}] <INFO> [  28/ 200] loss: (train=1.356, val=1.311, test=1.347, l2=9451.261), acc: (train=0.592, val=0.527, test=0.514), diff=0.00000139, proc(train=39.453sec, eval=49.108sec)
[2022-11-04 20:00:16,768 {dist_trainer.py:770}] <INFO> [  29/ 200] connecting edge count: 2
[2022-11-04 20:01:05,488 {dist_trainer.py:821}] <INFO> [  29/ 200] loss: (train=1.292, val=1.295, test=1.335, l2=9395.038), acc: (train=0.580, val=0.539, test=0.529), diff=0.00000102, proc(train=38.630sec, eval=47.006sec)
[2022-11-04 20:01:45,182 {dist_trainer.py:770}] <INFO> [  30/ 200] connecting edge count: 2
[2022-11-04 20:02:33,629 {dist_trainer.py:821}] <INFO> [  30/ 200] loss: (train=1.300, val=1.256, test=1.292, l2=9348.842), acc: (train=0.610, val=0.549, test=0.538), diff=0.00000149, proc(train=39.694sec, eval=46.693sec)
[2022-11-04 20:03:12,333 {dist_trainer.py:770}] <INFO> [  31/ 200] connecting edge count: 2
[2022-11-04 20:04:02,051 {dist_trainer.py:821}] <INFO> [  31/ 200] loss: (train=1.311, val=1.285, test=1.326, l2=9301.069), acc: (train=0.590, val=0.546, test=0.532), diff=0.00000165, proc(train=38.704sec, eval=48.247sec)
[2022-11-04 20:04:41,348 {dist_trainer.py:770}] <INFO> [  32/ 200] connecting edge count: 2
[2022-11-04 20:05:29,691 {dist_trainer.py:821}] <INFO> [  32/ 200] loss: (train=1.282, val=1.266, test=1.314, l2=9246.854), acc: (train=0.592, val=0.551, test=0.538), diff=0.00000144, proc(train=39.297sec, eval=46.745sec)
[2022-11-04 20:06:08,332 {dist_trainer.py:770}] <INFO> [  33/ 200] connecting edge count: 2
[2022-11-04 20:06:58,798 {dist_trainer.py:821}] <INFO> [  33/ 200] loss: (train=1.257, val=1.287, test=1.334, l2=9180.419), acc: (train=0.599, val=0.556, test=0.540), diff=0.00000150, proc(train=38.640sec, eval=48.999sec)
[2022-11-04 20:07:36,910 {dist_trainer.py:770}] <INFO> [  34/ 200] connecting edge count: 2
[2022-11-04 20:08:25,770 {dist_trainer.py:821}] <INFO> [  34/ 200] loss: (train=1.274, val=1.196, test=1.245, l2=9126.457), acc: (train=0.640, val=0.568, test=0.559), diff=0.00000119, proc(train=38.111sec, eval=47.531sec)
[2022-11-04 20:09:04,630 {dist_trainer.py:770}] <INFO> [  35/ 200] connecting edge count: 2
[2022-11-04 20:09:52,680 {dist_trainer.py:821}] <INFO> [  35/ 200] loss: (train=1.284, val=1.195, test=1.235, l2=9087.538), acc: (train=0.611, val=0.577, test=0.568), diff=0.00000211, proc(train=38.859sec, eval=46.513sec)
[2022-11-04 20:10:31,039 {dist_trainer.py:770}] <INFO> [  36/ 200] connecting edge count: 2
[2022-11-04 20:11:20,542 {dist_trainer.py:821}] <INFO> [  36/ 200] loss: (train=1.285, val=1.218, test=1.269, l2=9039.569), acc: (train=0.592, val=0.571, test=0.554), diff=0.00000174, proc(train=38.358sec, eval=48.079sec)
[2022-11-04 20:11:58,251 {dist_trainer.py:770}] <INFO> [  37/ 200] connecting edge count: 2
[2022-11-04 20:12:49,656 {dist_trainer.py:821}] <INFO> [  37/ 200] loss: (train=1.281, val=1.149, test=1.208, l2=8972.161), acc: (train=0.620, val=0.593, test=0.578), diff=0.00000122, proc(train=37.708sec, eval=49.719sec)
[2022-11-04 20:13:28,360 {dist_trainer.py:770}] <INFO> [  38/ 200] connecting edge count: 2
[2022-11-04 20:14:15,867 {dist_trainer.py:821}] <INFO> [  38/ 200] loss: (train=1.252, val=1.140, test=1.200, l2=8921.871), acc: (train=0.624, val=0.597, test=0.581), diff=0.00000117, proc(train=38.704sec, eval=46.291sec)
[2022-11-04 20:14:55,545 {dist_trainer.py:770}] <INFO> [  39/ 200] connecting edge count: 2
[2022-11-04 20:15:43,133 {dist_trainer.py:821}] <INFO> [  39/ 200] loss: (train=1.225, val=1.188, test=1.239, l2=8876.522), acc: (train=0.617, val=0.580, test=0.567), diff=0.00000154, proc(train=39.677sec, eval=46.261sec)
[2022-11-04 20:16:21,735 {dist_trainer.py:770}] <INFO> [  40/ 200] connecting edge count: 2
[2022-11-04 20:17:13,058 {dist_trainer.py:821}] <INFO> [  40/ 200] loss: (train=1.187, val=1.273, test=1.326, l2=8817.973), acc: (train=0.604, val=0.568, test=0.557), diff=0.00000123, proc(train=38.602sec, eval=49.956sec)
[2022-11-04 20:17:50,354 {dist_trainer.py:770}] <INFO> [  41/ 200] connecting edge count: 2
[2022-11-04 20:18:38,660 {dist_trainer.py:821}] <INFO> [  41/ 200] loss: (train=1.142, val=1.149, test=1.218, l2=8766.336), acc: (train=0.613, val=0.600, test=0.581), diff=0.00000156, proc(train=37.296sec, eval=46.816sec)
[2022-11-04 20:19:17,755 {dist_trainer.py:770}] <INFO> [  42/ 200] connecting edge count: 2
[2022-11-04 20:20:05,441 {dist_trainer.py:821}] <INFO> [  42/ 200] loss: (train=1.207, val=1.109, test=1.179, l2=8730.825), acc: (train=0.656, val=0.609, test=0.597), diff=0.00000192, proc(train=39.095sec, eval=46.486sec)
[2022-11-04 20:20:44,477 {dist_trainer.py:770}] <INFO> [  43/ 200] connecting edge count: 2
[2022-11-04 20:21:34,412 {dist_trainer.py:821}] <INFO> [  43/ 200] loss: (train=1.159, val=1.138, test=1.209, l2=8684.705), acc: (train=0.667, val=0.595, test=0.577), diff=0.00000158, proc(train=39.036sec, eval=48.371sec)
[2022-11-04 20:22:11,418 {dist_trainer.py:770}] <INFO> [  44/ 200] connecting edge count: 2
[2022-11-04 20:23:02,652 {dist_trainer.py:821}] <INFO> [  44/ 200] loss: (train=1.161, val=1.159, test=1.233, l2=8632.481), acc: (train=0.642, val=0.592, test=0.565), diff=0.00000150, proc(train=37.006sec, eval=49.413sec)
[2022-11-04 20:23:41,431 {dist_trainer.py:770}] <INFO> [  45/ 200] connecting edge count: 2
[2022-11-04 20:24:27,722 {dist_trainer.py:821}] <INFO> [  45/ 200] loss: (train=1.130, val=1.064, test=1.147, l2=8579.509), acc: (train=0.659, val=0.628, test=0.606), diff=0.00000203, proc(train=38.779sec, eval=44.867sec)
[2022-11-04 20:25:06,119 {dist_trainer.py:770}] <INFO> [  46/ 200] connecting edge count: 2
[2022-11-04 20:25:54,861 {dist_trainer.py:821}] <INFO> [  46/ 200] loss: (train=1.131, val=1.163, test=1.232, l2=8533.869), acc: (train=0.669, val=0.595, test=0.573), diff=0.00000160, proc(train=38.397sec, eval=47.235sec)
[2022-11-04 20:26:34,189 {dist_trainer.py:770}] <INFO> [  47/ 200] connecting edge count: 2
[2022-11-04 20:27:24,510 {dist_trainer.py:821}] <INFO> [  47/ 200] loss: (train=1.095, val=1.025, test=1.100, l2=8477.396), acc: (train=0.677, val=0.643, test=0.616), diff=0.00000165, proc(train=39.328sec, eval=49.186sec)
[2022-11-04 20:28:03,409 {dist_trainer.py:770}] <INFO> [  48/ 200] connecting edge count: 2
[2022-11-04 20:28:52,763 {dist_trainer.py:821}] <INFO> [  48/ 200] loss: (train=1.112, val=1.059, test=1.145, l2=8415.805), acc: (train=0.692, val=0.625, test=0.601), diff=0.00000150, proc(train=38.899sec, eval=48.012sec)
[2022-11-04 20:29:32,774 {dist_trainer.py:770}] <INFO> [  49/ 200] connecting edge count: 2
[2022-11-04 20:30:22,615 {dist_trainer.py:821}] <INFO> [  49/ 200] loss: (train=1.054, val=1.038, test=1.128, l2=8368.590), acc: (train=0.684, val=0.631, test=0.602), diff=0.00000146, proc(train=40.011sec, eval=48.361sec)
[2022-11-04 20:31:00,902 {dist_trainer.py:770}] <INFO> [  50/ 200] connecting edge count: 2
[2022-11-04 20:31:49,650 {dist_trainer.py:821}] <INFO> [  50/ 200] loss: (train=1.041, val=1.210, test=1.295, l2=8329.337), acc: (train=0.680, val=0.582, test=0.554), diff=0.00000167, proc(train=38.287sec, eval=47.257sec)
[2022-11-04 20:32:27,711 {dist_trainer.py:770}] <INFO> [  51/ 200] connecting edge count: 2
[2022-11-04 20:33:17,642 {dist_trainer.py:821}] <INFO> [  51/ 200] loss: (train=1.055, val=1.003, test=1.084, l2=8281.846), acc: (train=0.692, val=0.648, test=0.625), diff=0.00000151, proc(train=38.061sec, eval=48.702sec)
[2022-11-04 20:33:55,470 {dist_trainer.py:770}] <INFO> [  52/ 200] connecting edge count: 2
[2022-11-04 20:34:46,936 {dist_trainer.py:821}] <INFO> [  52/ 200] loss: (train=1.055, val=1.075, test=1.157, l2=8229.457), acc: (train=0.675, val=0.624, test=0.601), diff=0.00000128, proc(train=37.828sec, eval=50.016sec)
[2022-11-04 20:35:27,147 {dist_trainer.py:770}] <INFO> [  53/ 200] connecting edge count: 2
[2022-11-04 20:36:14,350 {dist_trainer.py:821}] <INFO> [  53/ 200] loss: (train=1.107, val=1.006, test=1.114, l2=8173.868), acc: (train=0.694, val=0.650, test=0.620), diff=0.00000186, proc(train=40.211sec, eval=45.929sec)
[2022-11-04 20:36:53,812 {dist_trainer.py:770}] <INFO> [  54/ 200] connecting edge count: 2
[2022-11-04 20:37:43,879 {dist_trainer.py:821}] <INFO> [  54/ 200] loss: (train=1.092, val=1.156, test=1.256, l2=8126.121), acc: (train=0.578, val=0.611, test=0.585), diff=0.00000142, proc(train=39.462sec, eval=48.492sec)
[2022-11-04 20:38:21,755 {dist_trainer.py:770}] <INFO> [  55/ 200] connecting edge count: 2
[2022-11-04 20:39:12,009 {dist_trainer.py:821}] <INFO> [  55/ 200] loss: (train=1.071, val=0.959, test=1.059, l2=8075.968), acc: (train=0.706, val=0.667, test=0.641), diff=0.00000199, proc(train=37.876sec, eval=48.934sec)
[2022-11-04 20:39:50,148 {dist_trainer.py:770}] <INFO> [  56/ 200] connecting edge count: 2
[2022-11-04 20:40:38,928 {dist_trainer.py:821}] <INFO> [  56/ 200] loss: (train=1.060, val=1.202, test=1.303, l2=8026.590), acc: (train=0.637, val=0.599, test=0.578), diff=0.00000180, proc(train=38.139sec, eval=47.195sec)
[2022-11-04 20:41:17,102 {dist_trainer.py:770}] <INFO> [  57/ 200] connecting edge count: 2
[2022-11-04 20:42:09,256 {dist_trainer.py:821}] <INFO> [  57/ 200] loss: (train=1.031, val=1.093, test=1.191, l2=7978.566), acc: (train=0.694, val=0.615, test=0.588), diff=0.00000162, proc(train=38.173sec, eval=50.639sec)
[2022-11-04 20:42:48,583 {dist_trainer.py:770}] <INFO> [  58/ 200] connecting edge count: 2
[2022-11-04 20:43:36,279 {dist_trainer.py:821}] <INFO> [  58/ 200] loss: (train=1.017, val=1.133, test=1.211, l2=7929.408), acc: (train=0.620, val=0.609, test=0.587), diff=0.00000200, proc(train=39.327sec, eval=46.169sec)
[2022-11-04 20:44:16,069 {dist_trainer.py:770}] <INFO> [  59/ 200] connecting edge count: 2
[2022-11-04 20:45:06,114 {dist_trainer.py:821}] <INFO> [  59/ 200] loss: (train=1.043, val=0.908, test=1.015, l2=7881.027), acc: (train=0.711, val=0.685, test=0.651), diff=0.00000132, proc(train=39.789sec, eval=48.498sec)
[2022-11-04 20:45:44,123 {dist_trainer.py:770}] <INFO> [  60/ 200] connecting edge count: 2
[2022-11-04 20:46:35,169 {dist_trainer.py:821}] <INFO> [  60/ 200] loss: (train=1.007, val=1.034, test=1.153, l2=7833.329), acc: (train=0.715, val=0.649, test=0.616), diff=0.00000246, proc(train=38.009sec, eval=49.366sec)
[2022-11-04 20:47:14,902 {dist_trainer.py:770}] <INFO> [  61/ 200] connecting edge count: 2
[2022-11-04 20:48:02,533 {dist_trainer.py:821}] <INFO> [  61/ 200] loss: (train=1.045, val=0.918, test=1.044, l2=7784.393), acc: (train=0.715, val=0.686, test=0.649), diff=0.00000175, proc(train=39.732sec, eval=46.351sec)
[2022-11-04 20:48:40,183 {dist_trainer.py:770}] <INFO> [  62/ 200] connecting edge count: 2
[2022-11-04 20:49:31,932 {dist_trainer.py:821}] <INFO> [  62/ 200] loss: (train=1.023, val=1.067, test=1.183, l2=7739.920), acc: (train=0.679, val=0.634, test=0.598), diff=0.00000151, proc(train=37.650sec, eval=50.132sec)
[2022-11-04 20:50:11,806 {dist_trainer.py:770}] <INFO> [  63/ 200] connecting edge count: 2
[2022-11-04 20:50:59,465 {dist_trainer.py:821}] <INFO> [  63/ 200] loss: (train=0.975, val=0.880, test=1.014, l2=7687.751), acc: (train=0.730, val=0.694, test=0.661), diff=0.00000200, proc(train=39.873sec, eval=46.304sec)
[2022-11-04 20:51:37,865 {dist_trainer.py:770}] <INFO> [  64/ 200] connecting edge count: 2
[2022-11-04 20:52:26,007 {dist_trainer.py:821}] <INFO> [  64/ 200] loss: (train=0.977, val=1.050, test=1.174, l2=7642.308), acc: (train=0.675, val=0.643, test=0.612), diff=0.00000193, proc(train=38.400sec, eval=46.561sec)
[2022-11-04 20:53:05,018 {dist_trainer.py:770}] <INFO> [  65/ 200] connecting edge count: 2
[2022-11-04 20:53:55,272 {dist_trainer.py:821}] <INFO> [  65/ 200] loss: (train=0.965, val=1.015, test=1.145, l2=7595.398), acc: (train=0.707, val=0.653, test=0.618), diff=0.00000171, proc(train=39.011sec, eval=48.757sec)
[2022-11-04 20:54:34,212 {dist_trainer.py:770}] <INFO> [  66/ 200] connecting edge count: 2
[2022-11-04 20:55:23,674 {dist_trainer.py:821}] <INFO> [  66/ 200] loss: (train=0.976, val=0.856, test=0.990, l2=7544.463), acc: (train=0.715, val=0.705, test=0.664), diff=0.00000154, proc(train=38.940sec, eval=48.180sec)
[2022-11-04 20:56:02,212 {dist_trainer.py:770}] <INFO> [  67/ 200] connecting edge count: 2
[2022-11-04 20:56:55,378 {dist_trainer.py:821}] <INFO> [  67/ 200] loss: (train=0.935, val=0.856, test=0.994, l2=7498.835), acc: (train=0.708, val=0.705, test=0.660), diff=0.00000193, proc(train=38.537sec, eval=51.598sec)
[2022-11-04 20:57:32,145 {dist_trainer.py:770}] <INFO> [  68/ 200] connecting edge count: 2
[2022-11-04 20:58:19,993 {dist_trainer.py:821}] <INFO> [  68/ 200] loss: (train=0.964, val=0.858, test=0.995, l2=7457.553), acc: (train=0.727, val=0.703, test=0.665), diff=0.00000177, proc(train=36.766sec, eval=46.329sec)
[2022-11-04 20:58:59,137 {dist_trainer.py:770}] <INFO> [  69/ 200] connecting edge count: 2
[2022-11-04 20:59:48,074 {dist_trainer.py:821}] <INFO> [  69/ 200] loss: (train=0.974, val=0.929, test=1.074, l2=7416.026), acc: (train=0.710, val=0.682, test=0.641), diff=0.00000165, proc(train=39.143sec, eval=47.236sec)
[2022-11-04 21:00:26,667 {dist_trainer.py:770}] <INFO> [  70/ 200] connecting edge count: 2
[2022-11-04 21:01:18,686 {dist_trainer.py:821}] <INFO> [  70/ 200] loss: (train=0.952, val=0.811, test=0.960, l2=7370.268), acc: (train=0.744, val=0.719, test=0.674), diff=0.00000146, proc(train=38.593sec, eval=50.789sec)
[2022-11-04 21:01:56,655 {dist_trainer.py:770}] <INFO> [  71/ 200] connecting edge count: 2
[2022-11-04 21:02:45,116 {dist_trainer.py:821}] <INFO> [  71/ 200] loss: (train=0.931, val=0.836, test=0.984, l2=7323.945), acc: (train=0.730, val=0.714, test=0.672), diff=0.00000196, proc(train=37.968sec, eval=47.066sec)
[2022-11-04 21:03:24,029 {dist_trainer.py:770}] <INFO> [  72/ 200] connecting edge count: 2
[2022-11-04 21:04:12,852 {dist_trainer.py:821}] <INFO> [  72/ 200] loss: (train=0.937, val=0.959, test=1.103, l2=7279.151), acc: (train=0.676, val=0.673, test=0.636), diff=0.00000204, proc(train=38.914sec, eval=47.247sec)
[2022-11-04 21:04:52,304 {dist_trainer.py:770}] <INFO> [  73/ 200] connecting edge count: 2
[2022-11-04 21:05:40,626 {dist_trainer.py:821}] <INFO> [  73/ 200] loss: (train=0.921, val=0.786, test=0.947, l2=7244.063), acc: (train=0.754, val=0.727, test=0.683), diff=0.00000208, proc(train=39.452sec, eval=46.610sec)
[2022-11-04 21:06:20,017 {dist_trainer.py:770}] <INFO> [  74/ 200] connecting edge count: 2
[2022-11-04 21:07:08,522 {dist_trainer.py:821}] <INFO> [  74/ 200] loss: (train=0.918, val=0.885, test=1.048, l2=7203.345), acc: (train=0.742, val=0.697, test=0.654), diff=0.00000189, proc(train=39.391sec, eval=46.949sec)
[2022-11-04 21:07:47,417 {dist_trainer.py:770}] <INFO> [  75/ 200] connecting edge count: 2
[2022-11-04 21:08:38,428 {dist_trainer.py:821}] <INFO> [  75/ 200] loss: (train=0.892, val=0.812, test=0.965, l2=7155.426), acc: (train=0.743, val=0.723, test=0.679), diff=0.00000157, proc(train=38.894sec, eval=49.403sec)
[2022-11-04 21:09:17,611 {dist_trainer.py:770}] <INFO> [  76/ 200] connecting edge count: 2
[2022-11-04 21:10:06,225 {dist_trainer.py:821}] <INFO> [  76/ 200] loss: (train=0.883, val=0.928, test=1.104, l2=7107.500), acc: (train=0.733, val=0.692, test=0.646), diff=0.00000208, proc(train=39.183sec, eval=47.333sec)
[2022-11-04 21:10:45,407 {dist_trainer.py:770}] <INFO> [  77/ 200] connecting edge count: 2
[2022-11-04 21:11:36,075 {dist_trainer.py:821}] <INFO> [  77/ 200] loss: (train=0.892, val=0.777, test=0.935, l2=7066.244), acc: (train=0.743, val=0.734, test=0.685), diff=0.00000195, proc(train=39.181sec, eval=48.999sec)
[2022-11-04 21:12:15,158 {dist_trainer.py:770}] <INFO> [  78/ 200] connecting edge count: 2
[2022-11-04 21:13:02,234 {dist_trainer.py:821}] <INFO> [  78/ 200] loss: (train=0.921, val=0.908, test=1.083, l2=7021.828), acc: (train=0.690, val=0.692, test=0.651), diff=0.00000261, proc(train=39.083sec, eval=45.587sec)
[2022-11-04 21:13:40,385 {dist_trainer.py:770}] <INFO> [  79/ 200] connecting edge count: 2
[2022-11-04 21:14:29,570 {dist_trainer.py:821}] <INFO> [  79/ 200] loss: (train=0.885, val=0.804, test=0.968, l2=6979.900), acc: (train=0.728, val=0.725, test=0.679), diff=0.00000185, proc(train=38.151sec, eval=47.905sec)
[2022-11-04 21:15:07,301 {dist_trainer.py:770}] <INFO> [  80/ 200] connecting edge count: 2
[2022-11-04 21:15:59,240 {dist_trainer.py:821}] <INFO> [  80/ 200] loss: (train=0.890, val=0.820, test=1.003, l2=6933.389), acc: (train=0.734, val=0.718, test=0.662), diff=0.00000213, proc(train=37.732sec, eval=50.649sec)
[2022-11-04 21:16:37,840 {dist_trainer.py:770}] <INFO> [  81/ 200] connecting edge count: 2
[2022-11-04 21:17:26,808 {dist_trainer.py:821}] <INFO> [  81/ 200] loss: (train=0.868, val=0.781, test=0.951, l2=6888.081), acc: (train=0.746, val=0.734, test=0.675), diff=0.00000173, proc(train=38.599sec, eval=47.488sec)
[2022-11-04 21:18:05,383 {dist_trainer.py:770}] <INFO> [  82/ 200] connecting edge count: 2
[2022-11-04 21:18:55,534 {dist_trainer.py:821}] <INFO> [  82/ 200] loss: (train=0.854, val=0.809, test=0.993, l2=6846.073), acc: (train=0.754, val=0.724, test=0.668), diff=0.00000236, proc(train=38.575sec, eval=48.117sec)
[2022-11-04 21:19:34,283 {dist_trainer.py:770}] <INFO> [  83/ 200] connecting edge count: 2
[2022-11-04 21:20:22,766 {dist_trainer.py:821}] <INFO> [  83/ 200] loss: (train=0.860, val=0.806, test=0.994, l2=6811.177), acc: (train=0.739, val=0.729, test=0.675), diff=0.00000225, proc(train=38.749sec, eval=46.933sec)
[2022-11-04 21:21:01,465 {dist_trainer.py:770}] <INFO> [  84/ 200] connecting edge count: 2
[2022-11-04 21:21:49,989 {dist_trainer.py:821}] <INFO> [  84/ 200] loss: (train=0.860, val=0.807, test=1.001, l2=6775.028), acc: (train=0.744, val=0.725, test=0.671), diff=0.00000183, proc(train=38.699sec, eval=46.967sec)
[2022-11-04 21:22:20,978 {contract.py:84}] <INFO>  => node2 : edge disconnect.
[2022-11-04 21:22:29,534 {dist_trainer.py:770}] <INFO> [  85/ 200] connecting edge count: 1
[2022-11-04 21:23:09,886 {dist_trainer.py:821}] <INFO> [  85/ 200] loss: (train=1.560, val=3.381, test=3.381, l2=11563.261), acc: (train=0.178, val=0.129, test=0.129), diff=0.02567556, proc(train=39.545sec, eval=30.319sec)
[2022-11-04 21:23:09,886 {dist_trainer.py:836}] <INFO> [  85/ 200] found edge disconnection: 2 -> 1. finished train.
[2022-11-04 21:23:43,850 {dist_trainer.py:899}] <INFO> [EVAL] loss: (train=2.682, val=3.381, test=3.381, l2=11578.245), acc: (train=0.176, val=0.129, test=0.129), proc=33.963sec
[2022-11-04 21:23:43,960 {dist_trainer.py:380}] <INFO> GC: check garbage []
[2022-11-04 21:23:44,261 {main.py:285}] <INFO> GC: check garbage []
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
