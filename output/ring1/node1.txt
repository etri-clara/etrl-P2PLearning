[2022-11-04 19:18:08,313 {main.py:152}] <INFO> Namespace(datadir='./data', outdir='./output/ring1', epochs=200, batch_size=100, seed=569, data_init_seed=11, model_init_seed=13, l2_lambda=0.01, model_name='resnet50', dataset_name='cifar10', train_data_length=10000, group_channels=32, drop_rate=0.1, last_drop_rate=0.5, cuda=True, cuda_device_no=1, plot=False, scheduler='StepLR', step_size=410, gamma=0.9, sleep_factor=0.0, loglevel=<LogLevel.INFO: 20>, logfile=None, optimizer='AdmmSGD', nodename='node0', conf='./conf/node_list.json', host='./conf/hosts.json', lr=0.002, mu=200, eta=1.0, rho=0.1, round_step=False, swap_timeout=10)
[2022-11-04 19:18:08,313 {main.py:247}] <INFO> {'nodes': {'node0': {'device': 'cuda', 'round': 10, 'edges': {'node2': 0, 'node1': 4}}, 'node1': {'device': 'cuda', 'round': 10, 'edges': {'node0': 1, 'node2': 5}}, 'node2': {'device': 'cuda', 'round': 10, 'edges': {'node1': 2, 'node0': 6}}}}
[2022-11-04 19:18:08,436 {dist_trainer.py:186}] <INFO> : <class 'model.resnet.ResNet'>
[2022-11-04 19:18:08,436 {dist_trainer.py:186}] <INFO> conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,436 {dist_trainer.py:183}] <INFO> bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-04 19:18:08,436 {dist_trainer.py:186}] <INFO> relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,436 {dist_trainer.py:186}] <INFO> maxpool: <class 'torch.nn.modules.pooling.MaxPool2d'>
[2022-11-04 19:18:08,436 {dist_trainer.py:186}] <INFO> dropout1: <class 'torch.nn.modules.dropout.Dropout2d'>
[2022-11-04 19:18:08,436 {dist_trainer.py:186}] <INFO> layer1: <class 'torch.nn.modules.container.Sequential'>
[2022-11-04 19:18:08,436 {dist_trainer.py:186}] <INFO> layer1.0: <class 'model.resnet.Bottleneck'>
[2022-11-04 19:18:08,436 {dist_trainer.py:186}] <INFO> layer1.0.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,436 {dist_trainer.py:183}] <INFO> layer1.0.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-04 19:18:08,436 {dist_trainer.py:186}] <INFO> layer1.0.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,437 {dist_trainer.py:183}] <INFO> layer1.0.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-04 19:18:08,437 {dist_trainer.py:186}] <INFO> layer1.0.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,437 {dist_trainer.py:183}] <INFO> layer1.0.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-04 19:18:08,437 {dist_trainer.py:186}] <INFO> layer1.0.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,437 {dist_trainer.py:186}] <INFO> layer1.0.downsample: <class 'torch.nn.modules.container.Sequential'>
[2022-11-04 19:18:08,437 {dist_trainer.py:186}] <INFO> layer1.0.downsample.0: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,437 {dist_trainer.py:183}] <INFO> layer1.0.downsample.1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-04 19:18:08,437 {dist_trainer.py:186}] <INFO> layer1.1: <class 'model.resnet.Bottleneck'>
[2022-11-04 19:18:08,437 {dist_trainer.py:186}] <INFO> layer1.1.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,437 {dist_trainer.py:183}] <INFO> layer1.1.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-04 19:18:08,437 {dist_trainer.py:186}] <INFO> layer1.1.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,437 {dist_trainer.py:183}] <INFO> layer1.1.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-04 19:18:08,437 {dist_trainer.py:186}] <INFO> layer1.1.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,437 {dist_trainer.py:183}] <INFO> layer1.1.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-04 19:18:08,437 {dist_trainer.py:186}] <INFO> layer1.1.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,437 {dist_trainer.py:186}] <INFO> layer1.2: <class 'model.resnet.Bottleneck'>
[2022-11-04 19:18:08,437 {dist_trainer.py:186}] <INFO> layer1.2.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,437 {dist_trainer.py:183}] <INFO> layer1.2.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-04 19:18:08,437 {dist_trainer.py:186}] <INFO> layer1.2.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,437 {dist_trainer.py:183}] <INFO> layer1.2.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-04 19:18:08,437 {dist_trainer.py:186}] <INFO> layer1.2.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,437 {dist_trainer.py:183}] <INFO> layer1.2.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-04 19:18:08,437 {dist_trainer.py:186}] <INFO> layer1.2.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,437 {dist_trainer.py:186}] <INFO> layer1.3: <class 'torch.nn.modules.dropout.Dropout2d'>
[2022-11-04 19:18:08,437 {dist_trainer.py:186}] <INFO> layer2: <class 'torch.nn.modules.container.Sequential'>
[2022-11-04 19:18:08,437 {dist_trainer.py:186}] <INFO> layer2.0: <class 'model.resnet.Bottleneck'>
[2022-11-04 19:18:08,437 {dist_trainer.py:186}] <INFO> layer2.0.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,437 {dist_trainer.py:183}] <INFO> layer2.0.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-04 19:18:08,437 {dist_trainer.py:186}] <INFO> layer2.0.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,437 {dist_trainer.py:183}] <INFO> layer2.0.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-04 19:18:08,437 {dist_trainer.py:186}] <INFO> layer2.0.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,437 {dist_trainer.py:183}] <INFO> layer2.0.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-04 19:18:08,437 {dist_trainer.py:186}] <INFO> layer2.0.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,437 {dist_trainer.py:186}] <INFO> layer2.0.downsample: <class 'torch.nn.modules.container.Sequential'>
[2022-11-04 19:18:08,438 {dist_trainer.py:186}] <INFO> layer2.0.downsample.0: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,438 {dist_trainer.py:183}] <INFO> layer2.0.downsample.1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-04 19:18:08,438 {dist_trainer.py:186}] <INFO> layer2.1: <class 'model.resnet.Bottleneck'>
[2022-11-04 19:18:08,438 {dist_trainer.py:186}] <INFO> layer2.1.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,438 {dist_trainer.py:183}] <INFO> layer2.1.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-04 19:18:08,438 {dist_trainer.py:186}] <INFO> layer2.1.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,438 {dist_trainer.py:183}] <INFO> layer2.1.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-04 19:18:08,438 {dist_trainer.py:186}] <INFO> layer2.1.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,438 {dist_trainer.py:183}] <INFO> layer2.1.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-04 19:18:08,438 {dist_trainer.py:186}] <INFO> layer2.1.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,438 {dist_trainer.py:186}] <INFO> layer2.2: <class 'model.resnet.Bottleneck'>
[2022-11-04 19:18:08,438 {dist_trainer.py:186}] <INFO> layer2.2.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,438 {dist_trainer.py:183}] <INFO> layer2.2.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-04 19:18:08,438 {dist_trainer.py:186}] <INFO> layer2.2.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,438 {dist_trainer.py:183}] <INFO> layer2.2.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-04 19:18:08,438 {dist_trainer.py:186}] <INFO> layer2.2.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,438 {dist_trainer.py:183}] <INFO> layer2.2.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-04 19:18:08,438 {dist_trainer.py:186}] <INFO> layer2.2.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,438 {dist_trainer.py:186}] <INFO> layer2.3: <class 'model.resnet.Bottleneck'>
[2022-11-04 19:18:08,438 {dist_trainer.py:186}] <INFO> layer2.3.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,438 {dist_trainer.py:183}] <INFO> layer2.3.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-04 19:18:08,438 {dist_trainer.py:186}] <INFO> layer2.3.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,438 {dist_trainer.py:183}] <INFO> layer2.3.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-04 19:18:08,438 {dist_trainer.py:186}] <INFO> layer2.3.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,438 {dist_trainer.py:183}] <INFO> layer2.3.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-04 19:18:08,438 {dist_trainer.py:186}] <INFO> layer2.3.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,438 {dist_trainer.py:186}] <INFO> layer2.4: <class 'torch.nn.modules.dropout.Dropout2d'>
[2022-11-04 19:18:08,438 {dist_trainer.py:186}] <INFO> layer3: <class 'torch.nn.modules.container.Sequential'>
[2022-11-04 19:18:08,438 {dist_trainer.py:186}] <INFO> layer3.0: <class 'model.resnet.Bottleneck'>
[2022-11-04 19:18:08,438 {dist_trainer.py:186}] <INFO> layer3.0.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,438 {dist_trainer.py:183}] <INFO> layer3.0.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-04 19:18:08,438 {dist_trainer.py:186}] <INFO> layer3.0.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,438 {dist_trainer.py:183}] <INFO> layer3.0.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-04 19:18:08,438 {dist_trainer.py:186}] <INFO> layer3.0.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,439 {dist_trainer.py:183}] <INFO> layer3.0.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-04 19:18:08,439 {dist_trainer.py:186}] <INFO> layer3.0.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,439 {dist_trainer.py:186}] <INFO> layer3.0.downsample: <class 'torch.nn.modules.container.Sequential'>
[2022-11-04 19:18:08,439 {dist_trainer.py:186}] <INFO> layer3.0.downsample.0: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,439 {dist_trainer.py:183}] <INFO> layer3.0.downsample.1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-04 19:18:08,439 {dist_trainer.py:186}] <INFO> layer3.1: <class 'model.resnet.Bottleneck'>
[2022-11-04 19:18:08,439 {dist_trainer.py:186}] <INFO> layer3.1.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,439 {dist_trainer.py:183}] <INFO> layer3.1.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-04 19:18:08,439 {dist_trainer.py:186}] <INFO> layer3.1.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,439 {dist_trainer.py:183}] <INFO> layer3.1.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-04 19:18:08,439 {dist_trainer.py:186}] <INFO> layer3.1.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,439 {dist_trainer.py:183}] <INFO> layer3.1.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-04 19:18:08,439 {dist_trainer.py:186}] <INFO> layer3.1.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,439 {dist_trainer.py:186}] <INFO> layer3.2: <class 'model.resnet.Bottleneck'>
[2022-11-04 19:18:08,439 {dist_trainer.py:186}] <INFO> layer3.2.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,439 {dist_trainer.py:183}] <INFO> layer3.2.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-04 19:18:08,439 {dist_trainer.py:186}] <INFO> layer3.2.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,439 {dist_trainer.py:183}] <INFO> layer3.2.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-04 19:18:08,439 {dist_trainer.py:186}] <INFO> layer3.2.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,439 {dist_trainer.py:183}] <INFO> layer3.2.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-04 19:18:08,439 {dist_trainer.py:186}] <INFO> layer3.2.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,439 {dist_trainer.py:186}] <INFO> layer3.3: <class 'model.resnet.Bottleneck'>
[2022-11-04 19:18:08,439 {dist_trainer.py:186}] <INFO> layer3.3.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,439 {dist_trainer.py:183}] <INFO> layer3.3.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-04 19:18:08,439 {dist_trainer.py:186}] <INFO> layer3.3.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,439 {dist_trainer.py:183}] <INFO> layer3.3.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-04 19:18:08,439 {dist_trainer.py:186}] <INFO> layer3.3.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,439 {dist_trainer.py:183}] <INFO> layer3.3.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-04 19:18:08,439 {dist_trainer.py:186}] <INFO> layer3.3.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,439 {dist_trainer.py:186}] <INFO> layer3.4: <class 'model.resnet.Bottleneck'>
[2022-11-04 19:18:08,439 {dist_trainer.py:186}] <INFO> layer3.4.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,439 {dist_trainer.py:183}] <INFO> layer3.4.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-04 19:18:08,439 {dist_trainer.py:186}] <INFO> layer3.4.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,439 {dist_trainer.py:183}] <INFO> layer3.4.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-04 19:18:08,439 {dist_trainer.py:186}] <INFO> layer3.4.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,440 {dist_trainer.py:183}] <INFO> layer3.4.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-04 19:18:08,440 {dist_trainer.py:186}] <INFO> layer3.4.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,440 {dist_trainer.py:186}] <INFO> layer3.5: <class 'model.resnet.Bottleneck'>
[2022-11-04 19:18:08,440 {dist_trainer.py:186}] <INFO> layer3.5.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,440 {dist_trainer.py:183}] <INFO> layer3.5.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-04 19:18:08,440 {dist_trainer.py:186}] <INFO> layer3.5.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,440 {dist_trainer.py:183}] <INFO> layer3.5.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-04 19:18:08,440 {dist_trainer.py:186}] <INFO> layer3.5.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,440 {dist_trainer.py:183}] <INFO> layer3.5.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-04 19:18:08,440 {dist_trainer.py:186}] <INFO> layer3.5.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,440 {dist_trainer.py:186}] <INFO> layer3.6: <class 'torch.nn.modules.dropout.Dropout2d'>
[2022-11-04 19:18:08,440 {dist_trainer.py:186}] <INFO> layer4: <class 'torch.nn.modules.container.Sequential'>
[2022-11-04 19:18:08,440 {dist_trainer.py:186}] <INFO> layer4.0: <class 'model.resnet.Bottleneck'>
[2022-11-04 19:18:08,440 {dist_trainer.py:186}] <INFO> layer4.0.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,440 {dist_trainer.py:183}] <INFO> layer4.0.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-04 19:18:08,440 {dist_trainer.py:186}] <INFO> layer4.0.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,440 {dist_trainer.py:183}] <INFO> layer4.0.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-04 19:18:08,440 {dist_trainer.py:186}] <INFO> layer4.0.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,440 {dist_trainer.py:183}] <INFO> layer4.0.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 64, channels: 2048, eps: 0.000010, affine: True
[2022-11-04 19:18:08,440 {dist_trainer.py:186}] <INFO> layer4.0.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,440 {dist_trainer.py:186}] <INFO> layer4.0.downsample: <class 'torch.nn.modules.container.Sequential'>
[2022-11-04 19:18:08,440 {dist_trainer.py:186}] <INFO> layer4.0.downsample.0: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,440 {dist_trainer.py:183}] <INFO> layer4.0.downsample.1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 64, channels: 2048, eps: 0.000010, affine: True
[2022-11-04 19:18:08,440 {dist_trainer.py:186}] <INFO> layer4.1: <class 'model.resnet.Bottleneck'>
[2022-11-04 19:18:08,440 {dist_trainer.py:186}] <INFO> layer4.1.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,440 {dist_trainer.py:183}] <INFO> layer4.1.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-04 19:18:08,440 {dist_trainer.py:186}] <INFO> layer4.1.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,440 {dist_trainer.py:183}] <INFO> layer4.1.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-04 19:18:08,440 {dist_trainer.py:186}] <INFO> layer4.1.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,440 {dist_trainer.py:183}] <INFO> layer4.1.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 64, channels: 2048, eps: 0.000010, affine: True
[2022-11-04 19:18:08,440 {dist_trainer.py:186}] <INFO> layer4.1.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,440 {dist_trainer.py:186}] <INFO> layer4.2: <class 'model.resnet.Bottleneck'>
[2022-11-04 19:18:08,440 {dist_trainer.py:186}] <INFO> layer4.2.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,440 {dist_trainer.py:183}] <INFO> layer4.2.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-04 19:18:08,440 {dist_trainer.py:186}] <INFO> layer4.2.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,441 {dist_trainer.py:183}] <INFO> layer4.2.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-04 19:18:08,441 {dist_trainer.py:186}] <INFO> layer4.2.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-04 19:18:08,441 {dist_trainer.py:183}] <INFO> layer4.2.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 64, channels: 2048, eps: 0.000010, affine: True
[2022-11-04 19:18:08,441 {dist_trainer.py:186}] <INFO> layer4.2.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-04 19:18:08,441 {dist_trainer.py:186}] <INFO> avgpool: <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>
[2022-11-04 19:18:08,441 {dist_trainer.py:186}] <INFO> dropout_fc: <class 'torch.nn.modules.dropout.Dropout'>
[2022-11-04 19:18:08,441 {dist_trainer.py:186}] <INFO> fc: <class 'torch.nn.modules.linear.Linear'>
[2022-11-04 19:18:08,441 {dist_trainer.py:192}] <INFO> parameter size: conv1.weight 37632B
[2022-11-04 19:18:08,441 {dist_trainer.py:192}] <INFO> parameter size: bn1.weight 256B
[2022-11-04 19:18:08,441 {dist_trainer.py:192}] <INFO> parameter size: bn1.bias 256B
[2022-11-04 19:18:08,441 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.conv1.weight 16384B
[2022-11-04 19:18:08,441 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.bn1.weight 256B
[2022-11-04 19:18:08,441 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.bn1.bias 256B
[2022-11-04 19:18:08,441 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.conv2.weight 147456B
[2022-11-04 19:18:08,441 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.bn2.weight 256B
[2022-11-04 19:18:08,441 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.bn2.bias 256B
[2022-11-04 19:18:08,441 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.conv3.weight 65536B
[2022-11-04 19:18:08,441 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.bn3.weight 1024B
[2022-11-04 19:18:08,441 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.bn3.bias 1024B
[2022-11-04 19:18:08,441 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.downsample.0.weight 65536B
[2022-11-04 19:18:08,441 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.downsample.1.weight 1024B
[2022-11-04 19:18:08,442 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.downsample.1.bias 1024B
[2022-11-04 19:18:08,442 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.conv1.weight 65536B
[2022-11-04 19:18:08,442 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.bn1.weight 256B
[2022-11-04 19:18:08,442 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.bn1.bias 256B
[2022-11-04 19:18:08,442 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.conv2.weight 147456B
[2022-11-04 19:18:08,442 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.bn2.weight 256B
[2022-11-04 19:18:08,442 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.bn2.bias 256B
[2022-11-04 19:18:08,442 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.conv3.weight 65536B
[2022-11-04 19:18:08,442 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.bn3.weight 1024B
[2022-11-04 19:18:08,442 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.bn3.bias 1024B
[2022-11-04 19:18:08,442 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.conv1.weight 65536B
[2022-11-04 19:18:08,442 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.bn1.weight 256B
[2022-11-04 19:18:08,442 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.bn1.bias 256B
[2022-11-04 19:18:08,442 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.conv2.weight 147456B
[2022-11-04 19:18:08,442 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.bn2.weight 256B
[2022-11-04 19:18:08,442 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.bn2.bias 256B
[2022-11-04 19:18:08,442 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.conv3.weight 65536B
[2022-11-04 19:18:08,442 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.bn3.weight 1024B
[2022-11-04 19:18:08,442 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.bn3.bias 1024B
[2022-11-04 19:18:08,442 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.conv1.weight 131072B
[2022-11-04 19:18:08,442 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.bn1.weight 512B
[2022-11-04 19:18:08,443 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.bn1.bias 512B
[2022-11-04 19:18:08,443 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.conv2.weight 589824B
[2022-11-04 19:18:08,443 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.bn2.weight 512B
[2022-11-04 19:18:08,443 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.bn2.bias 512B
[2022-11-04 19:18:08,443 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.conv3.weight 262144B
[2022-11-04 19:18:08,443 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.bn3.weight 2048B
[2022-11-04 19:18:08,443 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.bn3.bias 2048B
[2022-11-04 19:18:08,443 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.downsample.0.weight 524288B
[2022-11-04 19:18:08,443 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.downsample.1.weight 2048B
[2022-11-04 19:18:08,443 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.downsample.1.bias 2048B
[2022-11-04 19:18:08,443 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.conv1.weight 262144B
[2022-11-04 19:18:08,443 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.bn1.weight 512B
[2022-11-04 19:18:08,443 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.bn1.bias 512B
[2022-11-04 19:18:08,443 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.conv2.weight 589824B
[2022-11-04 19:18:08,443 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.bn2.weight 512B
[2022-11-04 19:18:08,443 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.bn2.bias 512B
[2022-11-04 19:18:08,443 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.conv3.weight 262144B
[2022-11-04 19:18:08,443 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.bn3.weight 2048B
[2022-11-04 19:18:08,443 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.bn3.bias 2048B
[2022-11-04 19:18:08,443 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.conv1.weight 262144B
[2022-11-04 19:18:08,443 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.bn1.weight 512B
[2022-11-04 19:18:08,443 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.bn1.bias 512B
[2022-11-04 19:18:08,444 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.conv2.weight 589824B
[2022-11-04 19:18:08,444 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.bn2.weight 512B
[2022-11-04 19:18:08,444 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.bn2.bias 512B
[2022-11-04 19:18:08,444 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.conv3.weight 262144B
[2022-11-04 19:18:08,444 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.bn3.weight 2048B
[2022-11-04 19:18:08,444 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.bn3.bias 2048B
[2022-11-04 19:18:08,444 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.conv1.weight 262144B
[2022-11-04 19:18:08,444 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.bn1.weight 512B
[2022-11-04 19:18:08,444 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.bn1.bias 512B
[2022-11-04 19:18:08,444 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.conv2.weight 589824B
[2022-11-04 19:18:08,444 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.bn2.weight 512B
[2022-11-04 19:18:08,444 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.bn2.bias 512B
[2022-11-04 19:18:08,444 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.conv3.weight 262144B
[2022-11-04 19:18:08,444 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.bn3.weight 2048B
[2022-11-04 19:18:08,444 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.bn3.bias 2048B
[2022-11-04 19:18:08,444 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.conv1.weight 524288B
[2022-11-04 19:18:08,444 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.bn1.weight 1024B
[2022-11-04 19:18:08,444 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.bn1.bias 1024B
[2022-11-04 19:18:08,444 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.conv2.weight 2359296B
[2022-11-04 19:18:08,444 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.bn2.weight 1024B
[2022-11-04 19:18:08,444 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.bn2.bias 1024B
[2022-11-04 19:18:08,445 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.conv3.weight 1048576B
[2022-11-04 19:18:08,445 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.bn3.weight 4096B
[2022-11-04 19:18:08,445 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.bn3.bias 4096B
[2022-11-04 19:18:08,445 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.downsample.0.weight 2097152B
[2022-11-04 19:18:08,445 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.downsample.1.weight 4096B
[2022-11-04 19:18:08,445 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.downsample.1.bias 4096B
[2022-11-04 19:18:08,445 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.conv1.weight 1048576B
[2022-11-04 19:18:08,445 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.bn1.weight 1024B
[2022-11-04 19:18:08,445 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.bn1.bias 1024B
[2022-11-04 19:18:08,445 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.conv2.weight 2359296B
[2022-11-04 19:18:08,445 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.bn2.weight 1024B
[2022-11-04 19:18:08,445 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.bn2.bias 1024B
[2022-11-04 19:18:08,445 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.conv3.weight 1048576B
[2022-11-04 19:18:08,445 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.bn3.weight 4096B
[2022-11-04 19:18:08,445 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.bn3.bias 4096B
[2022-11-04 19:18:08,445 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.conv1.weight 1048576B
[2022-11-04 19:18:08,445 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.bn1.weight 1024B
[2022-11-04 19:18:08,445 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.bn1.bias 1024B
[2022-11-04 19:18:08,445 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.conv2.weight 2359296B
[2022-11-04 19:18:08,445 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.bn2.weight 1024B
[2022-11-04 19:18:08,445 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.bn2.bias 1024B
[2022-11-04 19:18:08,446 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.conv3.weight 1048576B
[2022-11-04 19:18:08,446 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.bn3.weight 4096B
[2022-11-04 19:18:08,446 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.bn3.bias 4096B
[2022-11-04 19:18:08,446 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.conv1.weight 1048576B
[2022-11-04 19:18:08,446 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.bn1.weight 1024B
[2022-11-04 19:18:08,446 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.bn1.bias 1024B
[2022-11-04 19:18:08,446 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.conv2.weight 2359296B
[2022-11-04 19:18:08,446 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.bn2.weight 1024B
[2022-11-04 19:18:08,446 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.bn2.bias 1024B
[2022-11-04 19:18:08,446 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.conv3.weight 1048576B
[2022-11-04 19:18:08,446 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.bn3.weight 4096B
[2022-11-04 19:18:08,446 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.bn3.bias 4096B
[2022-11-04 19:18:08,446 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.conv1.weight 1048576B
[2022-11-04 19:18:08,446 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.bn1.weight 1024B
[2022-11-04 19:18:08,446 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.bn1.bias 1024B
[2022-11-04 19:18:08,446 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.conv2.weight 2359296B
[2022-11-04 19:18:08,446 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.bn2.weight 1024B
[2022-11-04 19:18:08,446 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.bn2.bias 1024B
[2022-11-04 19:18:08,446 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.conv3.weight 1048576B
[2022-11-04 19:18:08,446 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.bn3.weight 4096B
[2022-11-04 19:18:08,446 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.bn3.bias 4096B
[2022-11-04 19:18:08,446 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.conv1.weight 1048576B
[2022-11-04 19:18:08,447 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.bn1.weight 1024B
[2022-11-04 19:18:08,447 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.bn1.bias 1024B
[2022-11-04 19:18:08,447 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.conv2.weight 2359296B
[2022-11-04 19:18:08,447 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.bn2.weight 1024B
[2022-11-04 19:18:08,447 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.bn2.bias 1024B
[2022-11-04 19:18:08,447 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.conv3.weight 1048576B
[2022-11-04 19:18:08,447 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.bn3.weight 4096B
[2022-11-04 19:18:08,447 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.bn3.bias 4096B
[2022-11-04 19:18:08,447 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.conv1.weight 2097152B
[2022-11-04 19:18:08,447 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.bn1.weight 2048B
[2022-11-04 19:18:08,447 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.bn1.bias 2048B
[2022-11-04 19:18:08,447 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.conv2.weight 9437184B
[2022-11-04 19:18:08,447 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.bn2.weight 2048B
[2022-11-04 19:18:08,447 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.bn2.bias 2048B
[2022-11-04 19:18:08,447 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.conv3.weight 4194304B
[2022-11-04 19:18:08,447 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.bn3.weight 8192B
[2022-11-04 19:18:08,447 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.bn3.bias 8192B
[2022-11-04 19:18:08,447 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.downsample.0.weight 8388608B
[2022-11-04 19:18:08,447 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.downsample.1.weight 8192B
[2022-11-04 19:18:08,447 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.downsample.1.bias 8192B
[2022-11-04 19:18:08,447 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.conv1.weight 4194304B
[2022-11-04 19:18:08,448 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.bn1.weight 2048B
[2022-11-04 19:18:08,448 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.bn1.bias 2048B
[2022-11-04 19:18:08,448 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.conv2.weight 9437184B
[2022-11-04 19:18:08,448 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.bn2.weight 2048B
[2022-11-04 19:18:08,448 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.bn2.bias 2048B
[2022-11-04 19:18:08,448 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.conv3.weight 4194304B
[2022-11-04 19:18:08,448 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.bn3.weight 8192B
[2022-11-04 19:18:08,448 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.bn3.bias 8192B
[2022-11-04 19:18:08,448 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.conv1.weight 4194304B
[2022-11-04 19:18:08,448 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.bn1.weight 2048B
[2022-11-04 19:18:08,448 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.bn1.bias 2048B
[2022-11-04 19:18:08,448 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.conv2.weight 9437184B
[2022-11-04 19:18:08,448 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.bn2.weight 2048B
[2022-11-04 19:18:08,448 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.bn2.bias 2048B
[2022-11-04 19:18:08,448 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.conv3.weight 4194304B
[2022-11-04 19:18:08,448 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.bn3.weight 8192B
[2022-11-04 19:18:08,448 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.bn3.bias 8192B
[2022-11-04 19:18:08,448 {dist_trainer.py:192}] <INFO> parameter size: fc.weight 81920B
[2022-11-04 19:18:08,448 {dist_trainer.py:192}] <INFO> parameter size: fc.bias 40B
[2022-11-04 19:18:08,448 {dist_trainer.py:194}] <INFO> Model: resnet50 size: 89.754MiB
[2022-11-04 19:18:10,407 {dist_trainer.py:78}] <INFO> device: cuda:1 0/4, NVIDIA TITAN RTX
[2022-11-04 19:18:11,729 {dist_trainer.py:494}] <INFO> node0: [7,8,2,6,4,5,1,3]
[2022-11-04 19:18:11,729 {dist_trainer.py:494}] <INFO> node1: [4,5,1,3,0,9,7,8]
[2022-11-04 19:18:11,729 {dist_trainer.py:494}] <INFO> node2: [0,9,7,8,2,6,4,5]
[2022-11-04 19:18:11,729 {dist_trainer.py:497}] <INFO> class 0, [node1:0.472,node2:0.528]
[2022-11-04 19:18:11,729 {dist_trainer.py:497}] <INFO> class 1, [node0:0.505,node1:0.495]
[2022-11-04 19:18:11,729 {dist_trainer.py:497}] <INFO> class 2, [node0:0.535,node2:0.465]
[2022-11-04 19:18:11,729 {dist_trainer.py:497}] <INFO> class 3, [node0:0.502,node1:0.498]
[2022-11-04 19:18:11,729 {dist_trainer.py:497}] <INFO> class 4, [node0:0.325,node1:0.361,node2:0.314]
[2022-11-04 19:18:11,729 {dist_trainer.py:497}] <INFO> class 5, [node0:0.327,node1:0.343,node2:0.330]
[2022-11-04 19:18:11,729 {dist_trainer.py:497}] <INFO> class 6, [node0:0.497,node2:0.503]
[2022-11-04 19:18:11,729 {dist_trainer.py:497}] <INFO> class 7, [node0:0.340,node1:0.338,node2:0.322]
[2022-11-04 19:18:11,729 {dist_trainer.py:497}] <INFO> class 8, [node0:0.305,node1:0.352,node2:0.343]
[2022-11-04 19:18:11,729 {dist_trainer.py:497}] <INFO> class 9, [node1:0.475,node2:0.525]
[2022-11-04 19:18:11,731 {dist_trainer.py:527}] <INFO> train data node0: 1:2523,2:2675,3:2509,4:1624,5:1634,6:2484,7:1700,8:1524
[2022-11-04 19:18:11,731 {dist_trainer.py:527}] <INFO> train data node1: 0:2360,1:2477,3:2491,4:1806,5:1714,7:1690,8:1758,9:2375
[2022-11-04 19:18:11,731 {dist_trainer.py:527}] <INFO> train data node2: 0:2640,2:2325,4:1570,5:1652,6:2516,7:1610,8:1718,9:2625
[2022-11-04 19:18:25,037 {dist_trainer.py:531}] <INFO> split_load_datas(END)
[2022-11-04 19:18:25,038 {dist_trainer.py:114}] <INFO> datasets(END)
[2022-11-04 19:18:25,038 {dist_trainer.py:713}] <INFO> build_criterion(1)
[2022-11-04 19:18:25,038 {dist_trainer.py:721}] <INFO> build_criterion(2)
[2022-11-04 19:18:25,049 {contract.py:21}] <INFO> 0
[2022-11-04 19:18:25,049 {contract.py:21}] <INFO> 1
[2022-11-04 19:18:25,049 {contract.py:21}] <INFO> 2
[2022-11-04 19:18:28,088 {distributed_c10d.py:228}] <INFO> Added key: store_based_barrier_key:1 to store for rank: 0
[2022-11-04 19:18:28,098 {distributed_c10d.py:262}] <INFO> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
[2022-11-04 19:18:28,230 {gateway.py:85}] <INFO> node2
[2022-11-04 19:18:28,293 {gateway.py:85}] <INFO> node1
[2022-11-04 19:18:28,304 {contract.py:36}] <INFO> contract(1)
[2022-11-04 19:18:28,318 {gateway.py:59}] <INFO> <SRV> node0 : edge setup.
[2022-11-04 19:18:28,407 {contract.py:44}] <INFO> <CLI> node0 : edge setup.
[2022-11-04 19:18:28,407 {contract.py:59}] <INFO> contract(2)
[2022-11-04 19:18:28,409 {admm_sgd.py:51}] <INFO> Optimizer <class 'optimizer.admm_sgd.AdmmSGD'> params: {'lr': 0.005, 'mu': 200, 'eta': 1.0, 'rho': 0.1, 'initial_lr': 0.005, 'eta_rate': 0.005}
[2022-11-04 19:18:28,409 {dist_trainer.py:725}] <INFO> build_optimizer()
[2022-11-04 19:18:28,409 {dist_trainer.py:736}] <INFO> Setup scheduler: <torch.optim.lr_scheduler.StepLR object at 0x7fb3f4311490>
[2022-11-04 19:18:54,990 {dist_trainer.py:770}] <INFO> [   1/ 200] connecting edge count: 2
[2022-11-04 19:19:07,907 {dist_trainer.py:821}] <INFO> [   1/ 200] loss: (train=2.505, val=2.898, test=2.897, l2=11505.811), acc: (train=0.164, val=0.100, test=0.100), diff=0.00308985, proc(train=26.580sec, eval=11.774sec)
[2022-11-04 19:19:31,111 {dist_trainer.py:770}] <INFO> [   2/ 200] connecting edge count: 2
[2022-11-04 19:19:43,969 {dist_trainer.py:821}] <INFO> [   2/ 200] loss: (train=2.596, val=2.838, test=2.838, l2=12564.535), acc: (train=0.150, val=0.100, test=0.100), diff=0.00017926, proc(train=23.204sec, eval=11.407sec)
[2022-11-04 19:20:09,127 {dist_trainer.py:770}] <INFO> [   3/ 200] connecting edge count: 2
[2022-11-04 19:20:22,017 {dist_trainer.py:821}] <INFO> [   3/ 200] loss: (train=2.534, val=2.471, test=2.466, l2=12532.400), acc: (train=0.098, val=0.100, test=0.100), diff=0.00002672, proc(train=25.157sec, eval=11.627sec)
[2022-11-04 19:20:47,074 {dist_trainer.py:770}] <INFO> [   4/ 200] connecting edge count: 2
[2022-11-04 19:20:59,713 {dist_trainer.py:821}] <INFO> [   4/ 200] loss: (train=2.335, val=2.232, test=2.228, l2=12447.660), acc: (train=0.183, val=0.119, test=0.120), diff=0.00000111, proc(train=25.056sec, eval=11.393sec)
[2022-11-04 19:21:24,475 {dist_trainer.py:770}] <INFO> [   5/ 200] connecting edge count: 2
[2022-11-04 19:21:37,414 {dist_trainer.py:821}] <INFO> [   5/ 200] loss: (train=2.313, val=2.250, test=2.249, l2=12440.905), acc: (train=0.206, val=0.169, test=0.171), diff=0.00000117, proc(train=24.761sec, eval=11.590sec)
[2022-11-04 19:22:01,148 {dist_trainer.py:770}] <INFO> [   6/ 200] connecting edge count: 2
[2022-11-04 19:22:13,982 {dist_trainer.py:821}] <INFO> [   6/ 200] loss: (train=2.253, val=2.149, test=2.145, l2=12382.263), acc: (train=0.239, val=0.189, test=0.191), diff=0.00000078, proc(train=23.734sec, eval=11.595sec)
[2022-11-04 19:22:35,462 {dist_trainer.py:770}] <INFO> [   7/ 200] connecting edge count: 2
[2022-11-04 19:22:48,220 {dist_trainer.py:821}] <INFO> [   7/ 200] loss: (train=2.205, val=2.100, test=2.096, l2=12357.226), acc: (train=0.240, val=0.209, test=0.214), diff=0.00000062, proc(train=21.480sec, eval=11.487sec)
[2022-11-04 19:23:15,013 {dist_trainer.py:770}] <INFO> [   8/ 200] connecting edge count: 2
[2022-11-04 19:23:27,688 {dist_trainer.py:821}] <INFO> [   8/ 200] loss: (train=2.189, val=2.008, test=1.998, l2=12317.380), acc: (train=0.286, val=0.222, test=0.227), diff=0.00000078, proc(train=26.792sec, eval=11.605sec)
[2022-11-04 19:23:52,058 {dist_trainer.py:770}] <INFO> [   9/ 200] connecting edge count: 2
[2022-11-04 19:24:04,938 {dist_trainer.py:821}] <INFO> [   9/ 200] loss: (train=2.135, val=1.986, test=1.978, l2=12287.143), acc: (train=0.188, val=0.251, test=0.254), diff=0.00000088, proc(train=24.370sec, eval=11.374sec)
[2022-11-04 19:24:29,512 {dist_trainer.py:770}] <INFO> [  10/ 200] connecting edge count: 2
[2022-11-04 19:24:42,633 {dist_trainer.py:821}] <INFO> [  10/ 200] loss: (train=2.182, val=2.117, test=2.114, l2=12285.291), acc: (train=0.208, val=0.196, test=0.199), diff=0.00000105, proc(train=24.574sec, eval=11.643sec)
[2022-11-04 19:25:09,675 {dist_trainer.py:770}] <INFO> [  11/ 200] connecting edge count: 2
[2022-11-04 19:25:22,281 {dist_trainer.py:821}] <INFO> [  11/ 200] loss: (train=2.103, val=1.924, test=1.912, l2=12227.171), acc: (train=0.254, val=0.260, test=0.268), diff=0.00000056, proc(train=27.041sec, eval=11.412sec)
[2022-11-04 19:25:47,133 {dist_trainer.py:770}] <INFO> [  12/ 200] connecting edge count: 2
[2022-11-04 19:26:00,086 {dist_trainer.py:821}] <INFO> [  12/ 200] loss: (train=2.094, val=1.956, test=1.950, l2=12215.223), acc: (train=0.251, val=0.244, test=0.248), diff=0.00000062, proc(train=24.852sec, eval=11.591sec)
[2022-11-04 19:26:24,353 {dist_trainer.py:770}] <INFO> [  13/ 200] connecting edge count: 2
[2022-11-04 19:26:37,137 {dist_trainer.py:821}] <INFO> [  13/ 200] loss: (train=2.047, val=1.980, test=1.970, l2=12156.357), acc: (train=0.271, val=0.281, test=0.284), diff=0.00000075, proc(train=24.267sec, eval=11.519sec)
[2022-11-04 19:26:59,338 {dist_trainer.py:770}] <INFO> [  14/ 200] connecting edge count: 2
[2022-11-04 19:27:12,010 {dist_trainer.py:821}] <INFO> [  14/ 200] loss: (train=2.034, val=1.851, test=1.838, l2=12133.079), acc: (train=0.335, val=0.312, test=0.315), diff=0.00000060, proc(train=22.200sec, eval=11.387sec)
[2022-11-04 19:27:37,627 {dist_trainer.py:770}] <INFO> [  15/ 200] connecting edge count: 2
[2022-11-04 19:27:50,295 {dist_trainer.py:821}] <INFO> [  15/ 200] loss: (train=1.999, val=1.943, test=1.941, l2=12095.841), acc: (train=0.325, val=0.309, test=0.309), diff=0.00000125, proc(train=25.616sec, eval=11.596sec)
[2022-11-04 19:28:14,593 {dist_trainer.py:770}] <INFO> [  16/ 200] connecting edge count: 2
[2022-11-04 19:28:27,322 {dist_trainer.py:821}] <INFO> [  16/ 200] loss: (train=2.003, val=1.787, test=1.779, l2=12066.136), acc: (train=0.323, val=0.330, test=0.335), diff=0.00000085, proc(train=24.297sec, eval=11.355sec)
[2022-11-04 19:28:51,307 {dist_trainer.py:770}] <INFO> [  17/ 200] connecting edge count: 2
[2022-11-04 19:29:04,206 {dist_trainer.py:821}] <INFO> [  17/ 200] loss: (train=2.025, val=1.881, test=1.870, l2=12068.646), acc: (train=0.294, val=0.317, test=0.326), diff=0.00000247, proc(train=23.985sec, eval=11.648sec)
[2022-11-04 19:29:31,457 {dist_trainer.py:770}] <INFO> [  18/ 200] connecting edge count: 2
[2022-11-04 19:29:44,026 {dist_trainer.py:821}] <INFO> [  18/ 200] loss: (train=1.901, val=1.796, test=1.791, l2=12003.988), acc: (train=0.281, val=0.322, test=0.325), diff=0.00000082, proc(train=27.250sec, eval=11.396sec)
[2022-11-04 19:30:08,303 {dist_trainer.py:770}] <INFO> [  19/ 200] connecting edge count: 2
[2022-11-04 19:30:21,413 {dist_trainer.py:821}] <INFO> [  19/ 200] loss: (train=1.919, val=1.736, test=1.728, l2=11994.287), acc: (train=0.319, val=0.329, test=0.332), diff=0.00000058, proc(train=24.277sec, eval=11.544sec)
[2022-11-04 19:30:46,430 {dist_trainer.py:770}] <INFO> [  20/ 200] connecting edge count: 2
[2022-11-04 19:30:59,240 {dist_trainer.py:821}] <INFO> [  20/ 200] loss: (train=1.889, val=1.702, test=1.698, l2=11934.542), acc: (train=0.355, val=0.372, test=0.369), diff=0.00000080, proc(train=25.017sec, eval=11.520sec)
[2022-11-04 19:31:21,524 {dist_trainer.py:770}] <INFO> [  21/ 200] connecting edge count: 2
[2022-11-04 19:31:34,125 {dist_trainer.py:821}] <INFO> [  21/ 200] loss: (train=1.876, val=1.786, test=1.780, l2=11912.855), acc: (train=0.284, val=0.351, test=0.355), diff=0.00000069, proc(train=22.284sec, eval=11.380sec)
[2022-11-04 19:31:58,621 {dist_trainer.py:770}] <INFO> [  22/ 200] connecting edge count: 2
[2022-11-04 19:32:11,639 {dist_trainer.py:821}] <INFO> [  22/ 200] loss: (train=1.901, val=2.023, test=2.025, l2=11880.841), acc: (train=0.264, val=0.274, test=0.275), diff=0.00000129, proc(train=24.495sec, eval=11.606sec)
[2022-11-04 19:32:35,833 {dist_trainer.py:770}] <INFO> [  23/ 200] connecting edge count: 2
[2022-11-04 19:32:48,797 {dist_trainer.py:821}] <INFO> [  23/ 200] loss: (train=1.815, val=1.613, test=1.611, l2=11855.861), acc: (train=0.404, val=0.415, test=0.413), diff=0.00000073, proc(train=24.193sec, eval=11.331sec)
[2022-11-04 19:33:13,529 {dist_trainer.py:770}] <INFO> [  24/ 200] connecting edge count: 2
[2022-11-04 19:33:26,746 {dist_trainer.py:821}] <INFO> [  24/ 200] loss: (train=1.881, val=1.738, test=1.733, l2=11852.952), acc: (train=0.325, val=0.371, test=0.371), diff=0.00000101, proc(train=24.731sec, eval=11.716sec)
[2022-11-04 19:33:52,794 {dist_trainer.py:770}] <INFO> [  25/ 200] connecting edge count: 2
[2022-11-04 19:34:05,458 {dist_trainer.py:821}] <INFO> [  25/ 200] loss: (train=1.829, val=1.638, test=1.642, l2=11798.382), acc: (train=0.401, val=0.396, test=0.392), diff=0.00000073, proc(train=26.048sec, eval=11.428sec)
[2022-11-04 19:34:30,396 {dist_trainer.py:770}] <INFO> [  26/ 200] connecting edge count: 2
[2022-11-04 19:34:43,296 {dist_trainer.py:821}] <INFO> [  26/ 200] loss: (train=1.789, val=1.718, test=1.722, l2=11783.258), acc: (train=0.358, val=0.383, test=0.384), diff=0.00000056, proc(train=24.938sec, eval=11.543sec)
[2022-11-04 19:35:11,016 {dist_trainer.py:770}] <INFO> [  27/ 200] connecting edge count: 2
[2022-11-04 19:35:23,887 {dist_trainer.py:821}] <INFO> [  27/ 200] loss: (train=1.767, val=1.629, test=1.635, l2=11729.573), acc: (train=0.386, val=0.419, test=0.415), diff=0.00000079, proc(train=27.719sec, eval=11.636sec)
[2022-11-04 19:35:45,576 {dist_trainer.py:770}] <INFO> [  28/ 200] connecting edge count: 2
[2022-11-04 19:35:58,445 {dist_trainer.py:821}] <INFO> [  28/ 200] loss: (train=1.766, val=1.594, test=1.594, l2=11703.045), acc: (train=0.349, val=0.405, test=0.400), diff=0.00000061, proc(train=21.689sec, eval=11.417sec)
[2022-11-04 19:36:22,477 {dist_trainer.py:770}] <INFO> [  29/ 200] connecting edge count: 2
[2022-11-04 19:36:35,230 {dist_trainer.py:821}] <INFO> [  29/ 200] loss: (train=1.766, val=1.546, test=1.550, l2=11675.431), acc: (train=0.408, val=0.436, test=0.428), diff=0.00000084, proc(train=24.032sec, eval=11.678sec)
[2022-11-04 19:37:00,410 {dist_trainer.py:770}] <INFO> [  30/ 200] connecting edge count: 2
[2022-11-04 19:37:13,076 {dist_trainer.py:821}] <INFO> [  30/ 200] loss: (train=1.733, val=1.756, test=1.769, l2=11630.986), acc: (train=0.371, val=0.380, test=0.378), diff=0.00000061, proc(train=25.179sec, eval=11.349sec)
[2022-11-04 19:37:38,304 {dist_trainer.py:770}] <INFO> [  31/ 200] connecting edge count: 2
[2022-11-04 19:37:51,280 {dist_trainer.py:821}] <INFO> [  31/ 200] loss: (train=1.760, val=1.619, test=1.631, l2=11624.457), acc: (train=0.440, val=0.410, test=0.408), diff=0.00000075, proc(train=25.227sec, eval=11.680sec)
[2022-11-04 19:38:18,116 {dist_trainer.py:770}] <INFO> [  32/ 200] connecting edge count: 2
[2022-11-04 19:38:30,834 {dist_trainer.py:821}] <INFO> [  32/ 200] loss: (train=1.690, val=1.575, test=1.582, l2=11567.181), acc: (train=0.440, val=0.428, test=0.418), diff=0.00000058, proc(train=26.835sec, eval=11.431sec)
[2022-11-04 19:38:54,212 {dist_trainer.py:770}] <INFO> [  33/ 200] connecting edge count: 2
[2022-11-04 19:39:06,765 {dist_trainer.py:821}] <INFO> [  33/ 200] loss: (train=1.717, val=1.575, test=1.581, l2=11552.103), acc: (train=0.455, val=0.433, test=0.429), diff=0.00000063, proc(train=23.377sec, eval=11.483sec)
[2022-11-04 19:39:34,322 {dist_trainer.py:770}] <INFO> [  34/ 200] connecting edge count: 2
[2022-11-04 19:39:48,356 {dist_trainer.py:821}] <INFO> [  34/ 200] loss: (train=1.673, val=1.569, test=1.580, l2=11500.915), acc: (train=0.441, val=0.445, test=0.441), diff=0.00000087, proc(train=27.557sec, eval=11.685sec)
[2022-11-04 19:40:11,063 {dist_trainer.py:770}] <INFO> [  35/ 200] connecting edge count: 2
[2022-11-04 19:40:23,828 {dist_trainer.py:821}] <INFO> [  35/ 200] loss: (train=1.633, val=1.683, test=1.685, l2=11476.812), acc: (train=0.406, val=0.417, test=0.417), diff=0.00000064, proc(train=22.706sec, eval=11.453sec)
[2022-11-04 19:40:48,989 {dist_trainer.py:770}] <INFO> [  36/ 200] connecting edge count: 2
[2022-11-04 19:41:02,349 {dist_trainer.py:821}] <INFO> [  36/ 200] loss: (train=1.682, val=1.468, test=1.483, l2=11456.467), acc: (train=0.447, val=0.466, test=0.458), diff=0.00000102, proc(train=25.161sec, eval=11.757sec)
[2022-11-04 19:41:27,826 {dist_trainer.py:770}] <INFO> [  37/ 200] connecting edge count: 2
[2022-11-04 19:41:40,913 {dist_trainer.py:821}] <INFO> [  37/ 200] loss: (train=1.589, val=1.504, test=1.508, l2=11414.137), acc: (train=0.482, val=0.453, test=0.448), diff=0.00000081, proc(train=25.476sec, eval=11.620sec)
[2022-11-04 19:42:05,802 {dist_trainer.py:770}] <INFO> [  38/ 200] connecting edge count: 2
[2022-11-04 19:42:18,973 {dist_trainer.py:821}] <INFO> [  38/ 200] loss: (train=1.617, val=1.547, test=1.549, l2=11407.856), acc: (train=0.412, val=0.445, test=0.440), diff=0.00000096, proc(train=24.889sec, eval=11.727sec)
[2022-11-04 19:42:44,193 {dist_trainer.py:770}] <INFO> [  39/ 200] connecting edge count: 2
[2022-11-04 19:42:57,759 {dist_trainer.py:821}] <INFO> [  39/ 200] loss: (train=1.582, val=1.481, test=1.497, l2=11350.247), acc: (train=0.480, val=0.471, test=0.464), diff=0.00000098, proc(train=25.219sec, eval=11.539sec)
[2022-11-04 19:43:20,989 {dist_trainer.py:770}] <INFO> [  40/ 200] connecting edge count: 2
[2022-11-04 19:43:33,653 {dist_trainer.py:821}] <INFO> [  40/ 200] loss: (train=1.643, val=1.581, test=1.587, l2=11332.325), acc: (train=0.450, val=0.438, test=0.435), diff=0.00000097, proc(train=23.230sec, eval=11.563sec)
[2022-11-04 19:43:58,346 {dist_trainer.py:770}] <INFO> [  41/ 200] connecting edge count: 2
[2022-11-04 19:44:11,907 {dist_trainer.py:821}] <INFO> [  41/ 200] loss: (train=1.599, val=1.510, test=1.529, l2=11288.820), acc: (train=0.476, val=0.433, test=0.425), diff=0.00000104, proc(train=24.693sec, eval=11.724sec)
[2022-11-04 19:44:34,726 {dist_trainer.py:770}] <INFO> [  42/ 200] connecting edge count: 2
[2022-11-04 19:44:48,086 {dist_trainer.py:821}] <INFO> [  42/ 200] loss: (train=1.595, val=1.486, test=1.506, l2=11266.259), acc: (train=0.509, val=0.463, test=0.451), diff=0.00000106, proc(train=22.818sec, eval=11.548sec)
[2022-11-04 19:45:11,660 {dist_trainer.py:770}] <INFO> [  43/ 200] connecting edge count: 2
[2022-11-04 19:45:24,776 {dist_trainer.py:821}] <INFO> [  43/ 200] loss: (train=1.574, val=1.461, test=1.486, l2=11251.988), acc: (train=0.453, val=0.474, test=0.472), diff=0.00000072, proc(train=23.574sec, eval=11.687sec)
[2022-11-04 19:45:49,896 {dist_trainer.py:770}] <INFO> [  44/ 200] connecting edge count: 2
[2022-11-04 19:46:02,721 {dist_trainer.py:821}] <INFO> [  44/ 200] loss: (train=1.578, val=1.420, test=1.437, l2=11206.134), acc: (train=0.478, val=0.488, test=0.481), diff=0.00000123, proc(train=25.120sec, eval=11.502sec)
[2022-11-04 19:46:27,571 {dist_trainer.py:770}] <INFO> [  45/ 200] connecting edge count: 2
[2022-11-04 19:46:41,362 {dist_trainer.py:821}] <INFO> [  45/ 200] loss: (train=1.639, val=1.607, test=1.626, l2=11197.579), acc: (train=0.456, val=0.417, test=0.408), diff=0.00000126, proc(train=24.850sec, eval=11.872sec)
[2022-11-04 19:47:05,516 {dist_trainer.py:770}] <INFO> [  46/ 200] connecting edge count: 2
[2022-11-04 19:47:18,366 {dist_trainer.py:821}] <INFO> [  46/ 200] loss: (train=1.549, val=1.422, test=1.449, l2=11144.696), acc: (train=0.484, val=0.486, test=0.473), diff=0.00000081, proc(train=24.153sec, eval=11.604sec)
[2022-11-04 19:47:42,250 {dist_trainer.py:770}] <INFO> [  47/ 200] connecting edge count: 2
[2022-11-04 19:47:55,770 {dist_trainer.py:821}] <INFO> [  47/ 200] loss: (train=1.567, val=1.407, test=1.425, l2=11124.979), acc: (train=0.466, val=0.491, test=0.483), diff=0.00000082, proc(train=23.883sec, eval=11.698sec)
[2022-11-04 19:48:20,703 {dist_trainer.py:770}] <INFO> [  48/ 200] connecting edge count: 2
[2022-11-04 19:48:35,100 {dist_trainer.py:821}] <INFO> [  48/ 200] loss: (train=1.516, val=1.352, test=1.375, l2=11084.600), acc: (train=0.519, val=0.513, test=0.499), diff=0.00000084, proc(train=24.933sec, eval=11.949sec)
[2022-11-04 19:48:57,604 {dist_trainer.py:770}] <INFO> [  49/ 200] connecting edge count: 2
[2022-11-04 19:49:11,008 {dist_trainer.py:821}] <INFO> [  49/ 200] loss: (train=1.537, val=1.440, test=1.458, l2=11058.487), acc: (train=0.529, val=0.473, test=0.462), diff=0.00000098, proc(train=22.504sec, eval=11.665sec)
[2022-11-04 19:49:33,867 {dist_trainer.py:770}] <INFO> [  50/ 200] connecting edge count: 2
[2022-11-04 19:49:47,974 {dist_trainer.py:821}] <INFO> [  50/ 200] loss: (train=1.549, val=1.375, test=1.408, l2=11040.864), acc: (train=0.491, val=0.506, test=0.492), diff=0.00000073, proc(train=22.858sec, eval=11.882sec)
[2022-11-04 19:50:13,283 {dist_trainer.py:770}] <INFO> [  51/ 200] connecting edge count: 2
[2022-11-04 19:50:27,191 {dist_trainer.py:821}] <INFO> [  51/ 200] loss: (train=1.520, val=1.422, test=1.438, l2=10998.894), acc: (train=0.520, val=0.493, test=0.485), diff=0.00000136, proc(train=25.309sec, eval=11.665sec)
[2022-11-04 19:50:51,204 {dist_trainer.py:770}] <INFO> [  52/ 200] connecting edge count: 2
[2022-11-04 19:51:04,883 {dist_trainer.py:821}] <INFO> [  52/ 200] loss: (train=1.553, val=1.517, test=1.532, l2=10989.560), acc: (train=0.509, val=0.463, test=0.459), diff=0.00000105, proc(train=24.013sec, eval=12.056sec)
[2022-11-04 19:51:28,837 {dist_trainer.py:770}] <INFO> [  53/ 200] connecting edge count: 2
[2022-11-04 19:51:41,644 {dist_trainer.py:821}] <INFO> [  53/ 200] loss: (train=1.520, val=1.349, test=1.374, l2=10950.914), acc: (train=0.483, val=0.515, test=0.503), diff=0.00000124, proc(train=23.954sec, eval=11.672sec)
[2022-11-04 19:52:05,104 {dist_trainer.py:770}] <INFO> [  54/ 200] connecting edge count: 2
[2022-11-04 19:52:18,483 {dist_trainer.py:821}] <INFO> [  54/ 200] loss: (train=1.467, val=1.337, test=1.363, l2=10937.690), acc: (train=0.541, val=0.521, test=0.510), diff=0.00000079, proc(train=23.460sec, eval=11.603sec)
[2022-11-04 19:52:43,426 {dist_trainer.py:770}] <INFO> [  55/ 200] connecting edge count: 2
[2022-11-04 19:52:56,543 {dist_trainer.py:821}] <INFO> [  55/ 200] loss: (train=1.461, val=1.348, test=1.371, l2=10908.981), acc: (train=0.482, val=0.508, test=0.500), diff=0.00000105, proc(train=24.943sec, eval=11.980sec)
[2022-11-04 19:53:20,531 {dist_trainer.py:770}] <INFO> [  56/ 200] connecting edge count: 2
[2022-11-04 19:53:33,716 {dist_trainer.py:821}] <INFO> [  56/ 200] loss: (train=1.465, val=1.437, test=1.459, l2=10881.083), acc: (train=0.512, val=0.498, test=0.495), diff=0.00000113, proc(train=23.988sec, eval=11.627sec)
[2022-11-04 19:53:58,534 {dist_trainer.py:770}] <INFO> [  57/ 200] connecting edge count: 2
[2022-11-04 19:54:11,854 {dist_trainer.py:821}] <INFO> [  57/ 200] loss: (train=1.602, val=1.412, test=1.433, l2=9854.362), acc: (train=0.523, val=0.497, test=0.489), diff=0.00164383, proc(train=24.817sec, eval=11.950sec)
[2022-11-04 19:54:36,040 {dist_trainer.py:770}] <INFO> [  58/ 200] connecting edge count: 2
[2022-11-04 19:54:48,841 {dist_trainer.py:821}] <INFO> [  58/ 200] loss: (train=1.455, val=1.580, test=1.608, l2=9543.858), acc: (train=0.506, val=0.459, test=0.451), diff=0.00007086, proc(train=24.185sec, eval=11.608sec)
[2022-11-04 19:55:12,315 {dist_trainer.py:770}] <INFO> [  59/ 200] connecting edge count: 2
[2022-11-04 19:55:25,425 {dist_trainer.py:821}] <INFO> [  59/ 200] loss: (train=1.445, val=1.313, test=1.339, l2=9595.344), acc: (train=0.539, val=0.529, test=0.520), diff=0.00002933, proc(train=23.474sec, eval=11.860sec)
[2022-11-04 19:55:49,703 {dist_trainer.py:770}] <INFO> [  60/ 200] connecting edge count: 2
[2022-11-04 19:56:03,551 {dist_trainer.py:821}] <INFO> [  60/ 200] loss: (train=1.424, val=1.347, test=1.374, l2=9559.109), acc: (train=0.536, val=0.506, test=0.497), diff=0.00000107, proc(train=24.278sec, eval=11.806sec)
[2022-11-04 19:56:27,308 {dist_trainer.py:770}] <INFO> [  61/ 200] connecting edge count: 2
[2022-11-04 19:56:41,493 {dist_trainer.py:821}] <INFO> [  61/ 200] loss: (train=1.396, val=1.313, test=1.344, l2=9548.879), acc: (train=0.539, val=0.535, test=0.520), diff=0.00000149, proc(train=23.756sec, eval=11.600sec)
[2022-11-04 19:57:05,061 {dist_trainer.py:770}] <INFO> [  62/ 200] connecting edge count: 2
[2022-11-04 19:57:19,045 {dist_trainer.py:821}] <INFO> [  62/ 200] loss: (train=1.451, val=1.285, test=1.322, l2=9523.110), acc: (train=0.525, val=0.541, test=0.526), diff=0.00000092, proc(train=23.567sec, eval=11.896sec)
[2022-11-04 19:57:41,688 {dist_trainer.py:770}] <INFO> [  63/ 200] connecting edge count: 2
[2022-11-04 19:57:54,886 {dist_trainer.py:821}] <INFO> [  63/ 200] loss: (train=1.439, val=1.289, test=1.329, l2=9501.303), acc: (train=0.518, val=0.543, test=0.527), diff=0.00000087, proc(train=22.643sec, eval=11.747sec)
[2022-11-04 19:58:20,638 {dist_trainer.py:770}] <INFO> [  64/ 200] connecting edge count: 2
[2022-11-04 19:58:33,891 {dist_trainer.py:821}] <INFO> [  64/ 200] loss: (train=1.448, val=1.293, test=1.326, l2=9478.574), acc: (train=0.506, val=0.535, test=0.518), diff=0.00000090, proc(train=25.751sec, eval=11.809sec)
[2022-11-04 19:58:57,779 {dist_trainer.py:770}] <INFO> [  65/ 200] connecting edge count: 2
[2022-11-04 19:59:10,705 {dist_trainer.py:821}] <INFO> [  65/ 200] loss: (train=1.406, val=1.299, test=1.341, l2=9441.623), acc: (train=0.533, val=0.537, test=0.523), diff=0.00000072, proc(train=23.887sec, eval=11.637sec)
[2022-11-04 19:59:34,398 {dist_trainer.py:770}] <INFO> [  66/ 200] connecting edge count: 2
[2022-11-04 19:59:47,800 {dist_trainer.py:821}] <INFO> [  66/ 200] loss: (train=1.408, val=1.384, test=1.417, l2=9435.911), acc: (train=0.452, val=0.501, test=0.486), diff=0.00000088, proc(train=23.692sec, eval=11.778sec)
[2022-11-04 20:00:13,024 {dist_trainer.py:770}] <INFO> [  67/ 200] connecting edge count: 2
[2022-11-04 20:00:25,818 {dist_trainer.py:821}] <INFO> [  67/ 200] loss: (train=1.399, val=1.345, test=1.385, l2=9392.921), acc: (train=0.469, val=0.517, test=0.507), diff=0.00000106, proc(train=25.223sec, eval=11.616sec)
[2022-11-04 20:00:49,153 {dist_trainer.py:770}] <INFO> [  68/ 200] connecting edge count: 2
[2022-11-04 20:01:02,326 {dist_trainer.py:821}] <INFO> [  68/ 200] loss: (train=1.419, val=1.388, test=1.415, l2=9386.684), acc: (train=0.505, val=0.519, test=0.514), diff=0.00000080, proc(train=23.334sec, eval=11.633sec)
[2022-11-04 20:01:27,714 {dist_trainer.py:770}] <INFO> [  69/ 200] connecting edge count: 2
[2022-11-04 20:01:40,794 {dist_trainer.py:821}] <INFO> [  69/ 200] loss: (train=1.431, val=1.273, test=1.313, l2=9357.199), acc: (train=0.514, val=0.542, test=0.529), diff=0.00000096, proc(train=25.387sec, eval=11.767sec)
[2022-11-04 20:02:04,447 {dist_trainer.py:770}] <INFO> [  70/ 200] connecting edge count: 2
[2022-11-04 20:02:17,632 {dist_trainer.py:821}] <INFO> [  70/ 200] loss: (train=1.368, val=1.398, test=1.429, l2=9337.587), acc: (train=0.473, val=0.509, test=0.496), diff=0.00000091, proc(train=23.653sec, eval=11.643sec)
[2022-11-04 20:02:41,702 {dist_trainer.py:770}] <INFO> [  71/ 200] connecting edge count: 2
[2022-11-04 20:02:55,016 {dist_trainer.py:821}] <INFO> [  71/ 200] loss: (train=1.402, val=1.274, test=1.316, l2=9325.550), acc: (train=0.512, val=0.546, test=0.536), diff=0.00000093, proc(train=24.070sec, eval=11.986sec)
[2022-11-04 20:03:18,936 {dist_trainer.py:770}] <INFO> [  72/ 200] connecting edge count: 2
[2022-11-04 20:03:31,779 {dist_trainer.py:821}] <INFO> [  72/ 200] loss: (train=1.359, val=1.405, test=1.449, l2=9291.537), acc: (train=0.537, val=0.513, test=0.500), diff=0.00000098, proc(train=23.919sec, eval=11.633sec)
[2022-11-04 20:03:55,554 {dist_trainer.py:770}] <INFO> [  73/ 200] connecting edge count: 2
[2022-11-04 20:04:08,607 {dist_trainer.py:821}] <INFO> [  73/ 200] loss: (train=1.409, val=1.273, test=1.309, l2=9288.011), acc: (train=0.559, val=0.547, test=0.530), diff=0.00000109, proc(train=23.775sec, eval=11.770sec)
[2022-11-04 20:04:33,139 {dist_trainer.py:770}] <INFO> [  74/ 200] connecting edge count: 2
[2022-11-04 20:04:46,140 {dist_trainer.py:821}] <INFO> [  74/ 200] loss: (train=1.379, val=1.244, test=1.278, l2=9256.152), acc: (train=0.548, val=0.560, test=0.543), diff=0.00000102, proc(train=24.532sec, eval=11.780sec)
[2022-11-04 20:05:07,745 {dist_trainer.py:770}] <INFO> [  75/ 200] connecting edge count: 2
[2022-11-04 20:05:20,898 {dist_trainer.py:821}] <INFO> [  75/ 200] loss: (train=1.324, val=1.295, test=1.335, l2=9230.578), acc: (train=0.536, val=0.540, test=0.528), diff=0.00000094, proc(train=21.605sec, eval=11.607sec)
[2022-11-04 20:05:43,651 {dist_trainer.py:770}] <INFO> [  76/ 200] connecting edge count: 2
[2022-11-04 20:05:56,638 {dist_trainer.py:821}] <INFO> [  76/ 200] loss: (train=1.337, val=1.272, test=1.318, l2=9207.913), acc: (train=0.556, val=0.545, test=0.530), diff=0.00000094, proc(train=22.753sec, eval=11.805sec)
[2022-11-04 20:06:20,002 {dist_trainer.py:770}] <INFO> [  77/ 200] connecting edge count: 2
[2022-11-04 20:06:32,813 {dist_trainer.py:821}] <INFO> [  77/ 200] loss: (train=1.286, val=1.208, test=1.257, l2=9173.616), acc: (train=0.583, val=0.570, test=0.548), diff=0.00000085, proc(train=23.364sec, eval=11.598sec)
[2022-11-04 20:06:56,493 {dist_trainer.py:770}] <INFO> [  78/ 200] connecting edge count: 2
[2022-11-04 20:07:09,430 {dist_trainer.py:821}] <INFO> [  78/ 200] loss: (train=1.368, val=1.286, test=1.333, l2=9168.311), acc: (train=0.513, val=0.545, test=0.532), diff=0.00000089, proc(train=23.679sec, eval=11.807sec)
[2022-11-04 20:07:33,243 {dist_trainer.py:770}] <INFO> [  79/ 200] connecting edge count: 2
[2022-11-04 20:07:46,030 {dist_trainer.py:821}] <INFO> [  79/ 200] loss: (train=1.366, val=1.339, test=1.369, l2=9133.019), acc: (train=0.565, val=0.525, test=0.517), diff=0.00000123, proc(train=23.813sec, eval=11.587sec)
[2022-11-04 20:08:09,481 {dist_trainer.py:770}] <INFO> [  80/ 200] connecting edge count: 2
[2022-11-04 20:08:22,476 {dist_trainer.py:821}] <INFO> [  80/ 200] loss: (train=1.396, val=1.297, test=1.337, l2=9118.065), acc: (train=0.550, val=0.542, test=0.533), diff=0.00000080, proc(train=23.451sec, eval=11.614sec)
[2022-11-04 20:08:46,359 {dist_trainer.py:770}] <INFO> [  81/ 200] connecting edge count: 2
[2022-11-04 20:08:59,433 {dist_trainer.py:821}] <INFO> [  81/ 200] loss: (train=1.329, val=1.169, test=1.216, l2=9095.670), acc: (train=0.570, val=0.583, test=0.566), diff=0.00000096, proc(train=23.883sec, eval=11.751sec)
[2022-11-04 20:09:22,342 {dist_trainer.py:770}] <INFO> [  82/ 200] connecting edge count: 2
[2022-11-04 20:09:35,504 {dist_trainer.py:821}] <INFO> [  82/ 200] loss: (train=1.379, val=1.263, test=1.303, l2=9079.354), acc: (train=0.600, val=0.547, test=0.530), diff=0.00000119, proc(train=22.909sec, eval=11.661sec)
[2022-11-04 20:09:59,783 {dist_trainer.py:770}] <INFO> [  83/ 200] connecting edge count: 2
[2022-11-04 20:10:12,884 {dist_trainer.py:821}] <INFO> [  83/ 200] loss: (train=1.397, val=1.197, test=1.249, l2=9068.385), acc: (train=0.554, val=0.578, test=0.562), diff=0.00000100, proc(train=24.278sec, eval=11.843sec)
[2022-11-04 20:10:37,324 {dist_trainer.py:770}] <INFO> [  84/ 200] connecting edge count: 2
[2022-11-04 20:10:50,273 {dist_trainer.py:821}] <INFO> [  84/ 200] loss: (train=1.370, val=1.186, test=1.233, l2=9038.683), acc: (train=0.566, val=0.576, test=0.566), diff=0.00000105, proc(train=24.439sec, eval=11.660sec)
[2022-11-04 20:11:14,121 {dist_trainer.py:770}] <INFO> [  85/ 200] connecting edge count: 2
[2022-11-04 20:11:26,959 {dist_trainer.py:821}] <INFO> [  85/ 200] loss: (train=1.368, val=1.165, test=1.216, l2=9025.886), acc: (train=0.571, val=0.584, test=0.568), diff=0.00000093, proc(train=23.847sec, eval=11.802sec)
[2022-11-04 20:11:51,578 {dist_trainer.py:770}] <INFO> [  86/ 200] connecting edge count: 2
[2022-11-04 20:12:04,960 {dist_trainer.py:821}] <INFO> [  86/ 200] loss: (train=1.322, val=1.208, test=1.260, l2=8990.201), acc: (train=0.536, val=0.574, test=0.558), diff=0.00000144, proc(train=24.619sec, eval=11.920sec)
[2022-11-04 20:12:27,817 {dist_trainer.py:770}] <INFO> [  87/ 200] connecting edge count: 2
[2022-11-04 20:12:41,033 {dist_trainer.py:821}] <INFO> [  87/ 200] loss: (train=1.300, val=1.182, test=1.236, l2=8968.859), acc: (train=0.556, val=0.586, test=0.566), diff=0.00000086, proc(train=22.857sec, eval=11.653sec)
[2022-11-04 20:13:05,135 {dist_trainer.py:770}] <INFO> [  88/ 200] connecting edge count: 2
[2022-11-04 20:13:18,226 {dist_trainer.py:821}] <INFO> [  88/ 200] loss: (train=1.315, val=1.196, test=1.240, l2=8953.926), acc: (train=0.546, val=0.578, test=0.569), diff=0.00000143, proc(train=24.101sec, eval=11.853sec)
[2022-11-04 20:13:42,118 {dist_trainer.py:770}] <INFO> [  89/ 200] connecting edge count: 2
[2022-11-04 20:13:55,374 {dist_trainer.py:821}] <INFO> [  89/ 200] loss: (train=1.309, val=1.230, test=1.285, l2=8924.077), acc: (train=0.568, val=0.561, test=0.546), diff=0.00000136, proc(train=23.892sec, eval=11.651sec)
[2022-11-04 20:14:20,386 {dist_trainer.py:770}] <INFO> [  90/ 200] connecting edge count: 2
[2022-11-04 20:14:33,702 {dist_trainer.py:821}] <INFO> [  90/ 200] loss: (train=1.315, val=1.241, test=1.297, l2=8910.232), acc: (train=0.561, val=0.564, test=0.545), diff=0.00000118, proc(train=25.012sec, eval=11.933sec)
[2022-11-04 20:14:57,700 {dist_trainer.py:770}] <INFO> [  91/ 200] connecting edge count: 2
[2022-11-04 20:15:10,573 {dist_trainer.py:821}] <INFO> [  91/ 200] loss: (train=1.283, val=1.110, test=1.167, l2=8876.838), acc: (train=0.588, val=0.604, test=0.587), diff=0.00000100, proc(train=23.998sec, eval=11.664sec)
[2022-11-04 20:15:33,572 {dist_trainer.py:770}] <INFO> [  92/ 200] connecting edge count: 2
[2022-11-04 20:15:46,422 {dist_trainer.py:821}] <INFO> [  92/ 200] loss: (train=1.296, val=1.219, test=1.275, l2=8862.517), acc: (train=0.592, val=0.566, test=0.546), diff=0.00000070, proc(train=22.998sec, eval=11.704sec)
[2022-11-04 20:16:11,581 {dist_trainer.py:770}] <INFO> [  93/ 200] connecting edge count: 2
[2022-11-04 20:16:24,820 {dist_trainer.py:821}] <INFO> [  93/ 200] loss: (train=1.281, val=1.229, test=1.287, l2=8831.524), acc: (train=0.604, val=0.570, test=0.557), diff=0.00000117, proc(train=25.159sec, eval=11.765sec)
[2022-11-04 20:16:47,407 {dist_trainer.py:770}] <INFO> [  94/ 200] connecting edge count: 2
[2022-11-04 20:17:00,458 {dist_trainer.py:821}] <INFO> [  94/ 200] loss: (train=1.259, val=1.159, test=1.212, l2=8808.706), acc: (train=0.569, val=0.593, test=0.580), diff=0.00000088, proc(train=22.587sec, eval=11.650sec)
[2022-11-04 20:17:26,586 {dist_trainer.py:770}] <INFO> [  95/ 200] connecting edge count: 2
[2022-11-04 20:17:39,935 {dist_trainer.py:821}] <INFO> [  95/ 200] loss: (train=1.284, val=1.181, test=1.235, l2=8784.829), acc: (train=0.608, val=0.579, test=0.564), diff=0.00000096, proc(train=26.128sec, eval=11.811sec)
[2022-11-04 20:18:03,866 {dist_trainer.py:770}] <INFO> [  96/ 200] connecting edge count: 2
[2022-11-04 20:18:16,809 {dist_trainer.py:821}] <INFO> [  96/ 200] loss: (train=1.279, val=1.302, test=1.352, l2=8763.588), acc: (train=0.512, val=0.552, test=0.544), diff=0.00000092, proc(train=23.931sec, eval=11.649sec)
[2022-11-04 20:18:40,560 {dist_trainer.py:770}] <INFO> [  97/ 200] connecting edge count: 2
[2022-11-04 20:18:54,414 {dist_trainer.py:821}] <INFO> [  97/ 200] loss: (train=1.268, val=1.103, test=1.164, l2=8758.254), acc: (train=0.604, val=0.612, test=0.590), diff=0.00000135, proc(train=23.751sec, eval=11.856sec)
[2022-11-04 20:19:18,207 {dist_trainer.py:770}] <INFO> [  98/ 200] connecting edge count: 2
[2022-11-04 20:19:31,025 {dist_trainer.py:821}] <INFO> [  98/ 200] loss: (train=1.253, val=1.212, test=1.275, l2=8726.620), acc: (train=0.567, val=0.582, test=0.563), diff=0.00000140, proc(train=23.793sec, eval=11.635sec)
[2022-11-04 20:19:54,621 {dist_trainer.py:770}] <INFO> [  99/ 200] connecting edge count: 2
[2022-11-04 20:20:07,989 {dist_trainer.py:821}] <INFO> [  99/ 200] loss: (train=1.267, val=1.116, test=1.182, l2=8717.583), acc: (train=0.581, val=0.608, test=0.585), diff=0.00000088, proc(train=23.595sec, eval=11.672sec)
[2022-11-04 20:20:33,627 {dist_trainer.py:770}] <INFO> [ 100/ 200] connecting edge count: 2
[2022-11-04 20:20:47,966 {dist_trainer.py:821}] <INFO> [ 100/ 200] loss: (train=1.269, val=1.080, test=1.145, l2=8693.151), acc: (train=0.571, val=0.617, test=0.600), diff=0.00000120, proc(train=25.637sec, eval=11.991sec)
[2022-11-04 20:21:10,568 {dist_trainer.py:770}] <INFO> [ 101/ 200] connecting edge count: 2
[2022-11-04 20:21:23,660 {dist_trainer.py:821}] <INFO> [ 101/ 200] loss: (train=1.292, val=1.145, test=1.220, l2=8670.893), acc: (train=0.576, val=0.599, test=0.580), diff=0.00000098, proc(train=22.601sec, eval=11.603sec)
[2022-11-04 20:21:48,868 {dist_trainer.py:770}] <INFO> [ 102/ 200] connecting edge count: 2
[2022-11-04 20:22:02,761 {dist_trainer.py:821}] <INFO> [ 102/ 200] loss: (train=1.277, val=1.154, test=1.217, l2=8648.935), acc: (train=0.582, val=0.594, test=0.571), diff=0.00000128, proc(train=25.207sec, eval=11.967sec)
[2022-11-04 20:22:25,941 {dist_trainer.py:770}] <INFO> [ 103/ 200] connecting edge count: 2
[2022-11-04 20:22:38,826 {dist_trainer.py:821}] <INFO> [ 103/ 200] loss: (train=1.200, val=1.181, test=1.246, l2=8624.898), acc: (train=0.541, val=0.583, test=0.561), diff=0.00000100, proc(train=23.179sec, eval=11.610sec)
[2022-11-04 20:23:02,496 {dist_trainer.py:770}] <INFO> [ 104/ 200] connecting edge count: 2
[2022-11-04 20:23:15,332 {dist_trainer.py:821}] <INFO> [ 104/ 200] loss: (train=1.215, val=1.064, test=1.130, l2=8622.783), acc: (train=0.611, val=0.625, test=0.606), diff=0.00000105, proc(train=23.669sec, eval=11.820sec)
[2022-11-04 20:23:40,834 {dist_trainer.py:770}] <INFO> [ 105/ 200] connecting edge count: 2
[2022-11-04 20:23:53,758 {dist_trainer.py:821}] <INFO> [ 105/ 200] loss: (train=1.233, val=1.196, test=1.264, l2=8580.263), acc: (train=0.589, val=0.574, test=0.563), diff=0.00000131, proc(train=25.502sec, eval=11.625sec)
[2022-11-04 20:24:17,723 {dist_trainer.py:770}] <INFO> [ 106/ 200] connecting edge count: 2
[2022-11-04 20:24:30,765 {dist_trainer.py:821}] <INFO> [ 106/ 200] loss: (train=1.270, val=1.344, test=1.390, l2=8571.012), acc: (train=0.560, val=0.541, test=0.524), diff=0.00000126, proc(train=23.964sec, eval=11.659sec)
[2022-11-04 20:24:55,019 {dist_trainer.py:770}] <INFO> [ 107/ 200] connecting edge count: 2
[2022-11-04 20:25:09,441 {dist_trainer.py:821}] <INFO> [ 107/ 200] loss: (train=1.240, val=1.086, test=1.166, l2=8543.318), acc: (train=0.587, val=0.622, test=0.599), diff=0.00000136, proc(train=24.254sec, eval=11.899sec)
[2022-11-04 20:25:31,762 {dist_trainer.py:770}] <INFO> [ 108/ 200] connecting edge count: 2
[2022-11-04 20:25:45,118 {dist_trainer.py:821}] <INFO> [ 108/ 200] loss: (train=1.195, val=1.052, test=1.124, l2=8519.071), acc: (train=0.626, val=0.631, test=0.609), diff=0.00000110, proc(train=22.321sec, eval=11.634sec)
[2022-11-04 20:26:07,862 {dist_trainer.py:770}] <INFO> [ 109/ 200] connecting edge count: 2
[2022-11-04 20:26:20,830 {dist_trainer.py:821}] <INFO> [ 109/ 200] loss: (train=1.202, val=1.007, test=1.079, l2=8499.667), acc: (train=0.631, val=0.648, test=0.624), diff=0.00000119, proc(train=22.744sec, eval=11.863sec)
[2022-11-04 20:26:44,538 {dist_trainer.py:770}] <INFO> [ 110/ 200] connecting edge count: 2
[2022-11-04 20:26:57,467 {dist_trainer.py:821}] <INFO> [ 110/ 200] loss: (train=1.197, val=1.170, test=1.238, l2=8465.112), acc: (train=0.610, val=0.587, test=0.567), diff=0.00000099, proc(train=23.708sec, eval=11.716sec)
[2022-11-04 20:27:21,203 {dist_trainer.py:770}] <INFO> [ 111/ 200] connecting edge count: 2
[2022-11-04 20:27:34,037 {dist_trainer.py:821}] <INFO> [ 111/ 200] loss: (train=1.201, val=1.154, test=1.216, l2=8460.741), acc: (train=0.607, val=0.599, test=0.579), diff=0.00000112, proc(train=23.735sec, eval=11.790sec)
[2022-11-04 20:27:56,679 {dist_trainer.py:770}] <INFO> [ 112/ 200] connecting edge count: 2
[2022-11-04 20:28:09,666 {dist_trainer.py:821}] <INFO> [ 112/ 200] loss: (train=1.222, val=1.122, test=1.214, l2=8423.552), acc: (train=0.585, val=0.602, test=0.574), diff=0.00000131, proc(train=22.641sec, eval=11.838sec)
[2022-11-04 20:28:32,742 {dist_trainer.py:770}] <INFO> [ 113/ 200] connecting edge count: 2
[2022-11-04 20:28:45,980 {dist_trainer.py:821}] <INFO> [ 113/ 200] loss: (train=1.204, val=1.099, test=1.176, l2=8403.779), acc: (train=0.603, val=0.622, test=0.598), diff=0.00000100, proc(train=23.076sec, eval=11.654sec)
[2022-11-04 20:29:12,051 {dist_trainer.py:770}] <INFO> [ 114/ 200] connecting edge count: 2
[2022-11-04 20:29:25,442 {dist_trainer.py:821}] <INFO> [ 114/ 200] loss: (train=1.164, val=1.121, test=1.202, l2=8381.847), acc: (train=0.661, val=0.605, test=0.578), diff=0.00000126, proc(train=26.070sec, eval=11.892sec)
[2022-11-04 20:29:48,479 {dist_trainer.py:770}] <INFO> [ 115/ 200] connecting edge count: 2
[2022-11-04 20:30:01,707 {dist_trainer.py:821}] <INFO> [ 115/ 200] loss: (train=1.160, val=1.121, test=1.195, l2=8360.451), acc: (train=0.642, val=0.599, test=0.576), diff=0.00000109, proc(train=23.037sec, eval=11.671sec)
[2022-11-04 20:30:26,345 {dist_trainer.py:770}] <INFO> [ 116/ 200] connecting edge count: 2
[2022-11-04 20:30:39,714 {dist_trainer.py:821}] <INFO> [ 116/ 200] loss: (train=1.202, val=1.046, test=1.133, l2=8357.154), acc: (train=0.635, val=0.631, test=0.606), diff=0.00000132, proc(train=24.638sec, eval=11.845sec)
[2022-11-04 20:31:05,406 {dist_trainer.py:770}] <INFO> [ 117/ 200] connecting edge count: 2
[2022-11-04 20:31:18,282 {dist_trainer.py:821}] <INFO> [ 117/ 200] loss: (train=1.201, val=1.067, test=1.138, l2=8319.348), acc: (train=0.647, val=0.624, test=0.598), diff=0.00000122, proc(train=25.691sec, eval=11.693sec)
[2022-11-04 20:31:42,856 {dist_trainer.py:770}] <INFO> [ 118/ 200] connecting edge count: 2
[2022-11-04 20:31:55,845 {dist_trainer.py:821}] <INFO> [ 118/ 200] loss: (train=1.204, val=1.372, test=1.420, l2=8319.936), acc: (train=0.543, val=0.530, test=0.514), diff=0.00000123, proc(train=24.574sec, eval=11.732sec)
[2022-11-04 20:32:17,766 {dist_trainer.py:770}] <INFO> [ 119/ 200] connecting edge count: 2
[2022-11-04 20:32:31,183 {dist_trainer.py:821}] <INFO> [ 119/ 200] loss: (train=1.181, val=1.009, test=1.097, l2=8288.204), acc: (train=0.627, val=0.648, test=0.627), diff=0.00000109, proc(train=21.921sec, eval=11.818sec)
[2022-11-04 20:32:53,489 {dist_trainer.py:770}] <INFO> [ 120/ 200] connecting edge count: 2
[2022-11-04 20:33:06,899 {dist_trainer.py:821}] <INFO> [ 120/ 200] loss: (train=1.198, val=1.159, test=1.247, l2=8269.195), acc: (train=0.631, val=0.592, test=0.569), diff=0.00000099, proc(train=22.306sec, eval=11.653sec)
[2022-11-04 20:33:32,322 {dist_trainer.py:770}] <INFO> [ 121/ 200] connecting edge count: 2
[2022-11-04 20:33:46,322 {dist_trainer.py:821}] <INFO> [ 121/ 200] loss: (train=1.200, val=1.031, test=1.116, l2=8249.842), acc: (train=0.612, val=0.632, test=0.606), diff=0.00000131, proc(train=25.422sec, eval=11.922sec)
[2022-11-04 20:34:08,915 {dist_trainer.py:770}] <INFO> [ 122/ 200] connecting edge count: 2
[2022-11-04 20:34:22,982 {dist_trainer.py:821}] <INFO> [ 122/ 200] loss: (train=1.195, val=1.009, test=1.100, l2=8219.906), acc: (train=0.642, val=0.650, test=0.620), diff=0.00000095, proc(train=22.593sec, eval=11.710sec)
[2022-11-04 20:34:47,103 {dist_trainer.py:770}] <INFO> [ 123/ 200] connecting edge count: 2
[2022-11-04 20:35:00,190 {dist_trainer.py:821}] <INFO> [ 123/ 200] loss: (train=1.219, val=0.992, test=1.074, l2=8217.562), acc: (train=0.608, val=0.651, test=0.629), diff=0.00000105, proc(train=24.120sec, eval=11.835sec)
[2022-11-04 20:35:26,877 {dist_trainer.py:770}] <INFO> [ 124/ 200] connecting edge count: 2
[2022-11-04 20:35:39,667 {dist_trainer.py:821}] <INFO> [ 124/ 200] loss: (train=1.169, val=1.037, test=1.130, l2=8174.825), acc: (train=0.625, val=0.641, test=0.619), diff=0.00000196, proc(train=26.687sec, eval=11.617sec)
[2022-11-04 20:36:03,718 {dist_trainer.py:770}] <INFO> [ 125/ 200] connecting edge count: 2
[2022-11-04 20:36:16,670 {dist_trainer.py:821}] <INFO> [ 125/ 200] loss: (train=1.206, val=1.140, test=1.225, l2=8165.173), acc: (train=0.545, val=0.608, test=0.588), diff=0.00000112, proc(train=24.050sec, eval=11.652sec)
[2022-11-04 20:36:41,977 {dist_trainer.py:770}] <INFO> [ 126/ 200] connecting edge count: 2
[2022-11-04 20:36:55,260 {dist_trainer.py:821}] <INFO> [ 126/ 200] loss: (train=1.157, val=1.005, test=1.103, l2=8132.647), acc: (train=0.617, val=0.652, test=0.619), diff=0.00000116, proc(train=25.306sec, eval=11.853sec)
[2022-11-04 20:37:17,245 {dist_trainer.py:770}] <INFO> [ 127/ 200] connecting edge count: 2
[2022-11-04 20:37:30,296 {dist_trainer.py:821}] <INFO> [ 127/ 200] loss: (train=1.145, val=1.053, test=1.144, l2=8112.489), acc: (train=0.642, val=0.635, test=0.606), diff=0.00000106, proc(train=21.984sec, eval=11.584sec)
[2022-11-04 20:37:53,564 {dist_trainer.py:770}] <INFO> [ 128/ 200] connecting edge count: 2
[2022-11-04 20:38:06,982 {dist_trainer.py:821}] <INFO> [ 128/ 200] loss: (train=1.162, val=0.971, test=1.073, l2=8095.663), acc: (train=0.616, val=0.663, test=0.636), diff=0.00000111, proc(train=23.268sec, eval=11.788sec)
[2022-11-04 20:38:30,413 {dist_trainer.py:770}] <INFO> [ 129/ 200] connecting edge count: 2
[2022-11-04 20:38:43,330 {dist_trainer.py:821}] <INFO> [ 129/ 200] loss: (train=1.127, val=0.976, test=1.076, l2=8067.253), acc: (train=0.661, val=0.656, test=0.627), diff=0.00000113, proc(train=23.431sec, eval=11.576sec)
[2022-11-04 20:39:07,285 {dist_trainer.py:770}] <INFO> [ 130/ 200] connecting edge count: 2
[2022-11-04 20:39:20,389 {dist_trainer.py:821}] <INFO> [ 130/ 200] loss: (train=1.142, val=1.048, test=1.141, l2=8063.694), acc: (train=0.598, val=0.636, test=0.610), diff=0.00000125, proc(train=23.955sec, eval=11.869sec)
[2022-11-04 20:39:45,334 {dist_trainer.py:770}] <INFO> [ 131/ 200] connecting edge count: 2
[2022-11-04 20:39:58,122 {dist_trainer.py:821}] <INFO> [ 131/ 200] loss: (train=1.138, val=0.992, test=1.102, l2=8030.710), acc: (train=0.646, val=0.658, test=0.626), diff=0.00000116, proc(train=24.945sec, eval=11.616sec)
[2022-11-04 20:40:20,075 {dist_trainer.py:770}] <INFO> [ 132/ 200] connecting edge count: 2
[2022-11-04 20:40:32,882 {dist_trainer.py:821}] <INFO> [ 132/ 200] loss: (train=1.156, val=1.003, test=1.106, l2=8013.293), acc: (train=0.624, val=0.649, test=0.618), diff=0.00000125, proc(train=21.953sec, eval=11.594sec)
[2022-11-04 20:40:58,815 {dist_trainer.py:770}] <INFO> [ 133/ 200] connecting edge count: 2
[2022-11-04 20:41:11,953 {dist_trainer.py:821}] <INFO> [ 133/ 200] loss: (train=1.126, val=1.116, test=1.220, l2=7988.648), acc: (train=0.629, val=0.624, test=0.594), diff=0.00000114, proc(train=25.933sec, eval=11.885sec)
[2022-11-04 20:41:34,599 {dist_trainer.py:770}] <INFO> [ 134/ 200] connecting edge count: 2
[2022-11-04 20:41:47,673 {dist_trainer.py:821}] <INFO> [ 134/ 200] loss: (train=1.132, val=0.994, test=1.092, l2=7971.711), acc: (train=0.608, val=0.651, test=0.626), diff=0.00000112, proc(train=22.646sec, eval=11.569sec)
[2022-11-04 20:42:11,395 {dist_trainer.py:770}] <INFO> [ 135/ 200] connecting edge count: 2
[2022-11-04 20:42:24,540 {dist_trainer.py:821}] <INFO> [ 135/ 200] loss: (train=1.152, val=0.997, test=1.104, l2=7970.598), acc: (train=0.622, val=0.650, test=0.622), diff=0.00000143, proc(train=23.722sec, eval=11.770sec)
[2022-11-04 20:42:50,392 {dist_trainer.py:770}] <INFO> [ 136/ 200] connecting edge count: 2
[2022-11-04 20:43:03,177 {dist_trainer.py:821}] <INFO> [ 136/ 200] loss: (train=1.095, val=0.995, test=1.097, l2=7929.102), acc: (train=0.640, val=0.649, test=0.623), diff=0.00000108, proc(train=25.852sec, eval=11.644sec)
[2022-11-04 20:43:27,312 {dist_trainer.py:770}] <INFO> [ 137/ 200] connecting edge count: 2
[2022-11-04 20:43:40,466 {dist_trainer.py:821}] <INFO> [ 137/ 200] loss: (train=1.137, val=0.953, test=1.058, l2=7918.801), acc: (train=0.640, val=0.665, test=0.632), diff=0.00000108, proc(train=24.135sec, eval=11.730sec)
[2022-11-04 20:44:04,385 {dist_trainer.py:770}] <INFO> [ 138/ 200] connecting edge count: 2
[2022-11-04 20:44:17,732 {dist_trainer.py:821}] <INFO> [ 138/ 200] loss: (train=1.107, val=0.947, test=1.068, l2=7888.305), acc: (train=0.637, val=0.671, test=0.638), diff=0.00000124, proc(train=23.919sec, eval=11.783sec)
[2022-11-04 20:44:39,325 {dist_trainer.py:770}] <INFO> [ 139/ 200] connecting edge count: 2
[2022-11-04 20:44:52,356 {dist_trainer.py:821}] <INFO> [ 139/ 200] loss: (train=1.085, val=0.960, test=1.065, l2=7867.767), acc: (train=0.653, val=0.667, test=0.634), diff=0.00000104, proc(train=21.593sec, eval=11.576sec)
[2022-11-04 20:45:15,714 {dist_trainer.py:770}] <INFO> [ 140/ 200] connecting edge count: 2
[2022-11-04 20:45:29,186 {dist_trainer.py:821}] <INFO> [ 140/ 200] loss: (train=1.121, val=0.975, test=1.095, l2=7850.882), acc: (train=0.667, val=0.655, test=0.618), diff=0.00000127, proc(train=23.357sec, eval=11.803sec)
[2022-11-04 20:45:53,249 {dist_trainer.py:770}] <INFO> [ 141/ 200] connecting edge count: 2
[2022-11-04 20:46:05,999 {dist_trainer.py:821}] <INFO> [ 141/ 200] loss: (train=1.090, val=1.005, test=1.109, l2=7824.181), acc: (train=0.630, val=0.654, test=0.622), diff=0.00000134, proc(train=24.063sec, eval=11.627sec)
[2022-11-04 20:46:29,867 {dist_trainer.py:770}] <INFO> [ 142/ 200] connecting edge count: 2
[2022-11-04 20:46:43,216 {dist_trainer.py:821}] <INFO> [ 142/ 200] loss: (train=1.182, val=1.054, test=1.159, l2=7820.124), acc: (train=0.607, val=0.637, test=0.599), diff=0.00000127, proc(train=23.867sec, eval=11.765sec)
[2022-11-04 20:47:07,567 {dist_trainer.py:770}] <INFO> [ 143/ 200] connecting edge count: 2
[2022-11-04 20:47:20,418 {dist_trainer.py:821}] <INFO> [ 143/ 200] loss: (train=1.103, val=0.938, test=1.068, l2=7790.881), acc: (train=0.668, val=0.675, test=0.635), diff=0.00000120, proc(train=24.351sec, eval=11.694sec)
[2022-11-04 20:47:41,791 {dist_trainer.py:770}] <INFO> [ 144/ 200] connecting edge count: 2
[2022-11-04 20:47:55,018 {dist_trainer.py:821}] <INFO> [ 144/ 200] loss: (train=1.058, val=0.921, test=1.041, l2=7771.865), acc: (train=0.655, val=0.679, test=0.641), diff=0.00000122, proc(train=21.373sec, eval=11.630sec)
[2022-11-04 20:48:19,127 {dist_trainer.py:770}] <INFO> [ 145/ 200] connecting edge count: 2
[2022-11-04 20:48:33,637 {dist_trainer.py:821}] <INFO> [ 145/ 200] loss: (train=1.071, val=0.898, test=1.020, l2=7750.940), acc: (train=0.657, val=0.685, test=0.651), diff=0.00000122, proc(train=24.109sec, eval=11.787sec)
[2022-11-04 20:48:56,010 {dist_trainer.py:770}] <INFO> [ 146/ 200] connecting edge count: 2
[2022-11-04 20:49:09,027 {dist_trainer.py:821}] <INFO> [ 146/ 200] loss: (train=1.056, val=0.964, test=1.087, l2=7731.002), acc: (train=0.652, val=0.667, test=0.632), diff=0.00000117, proc(train=22.372sec, eval=11.608sec)
[2022-11-04 20:49:32,084 {dist_trainer.py:770}] <INFO> [ 147/ 200] connecting edge count: 2
[2022-11-04 20:49:45,370 {dist_trainer.py:821}] <INFO> [ 147/ 200] loss: (train=1.053, val=0.951, test=1.069, l2=7730.267), acc: (train=0.616, val=0.670, test=0.637), diff=0.00000106, proc(train=23.057sec, eval=11.816sec)
[2022-11-04 20:50:09,849 {dist_trainer.py:770}] <INFO> [ 148/ 200] connecting edge count: 2
[2022-11-04 20:50:22,833 {dist_trainer.py:821}] <INFO> [ 148/ 200] loss: (train=1.049, val=0.927, test=1.034, l2=7692.261), acc: (train=0.639, val=0.672, test=0.641), diff=0.00000150, proc(train=24.479sec, eval=11.669sec)
[2022-11-04 20:50:45,337 {dist_trainer.py:770}] <INFO> [ 149/ 200] connecting edge count: 2
[2022-11-04 20:50:59,002 {dist_trainer.py:821}] <INFO> [ 149/ 200] loss: (train=1.097, val=1.084, test=1.185, l2=7676.008), acc: (train=0.603, val=0.621, test=0.593), diff=0.00000148, proc(train=22.504sec, eval=11.631sec)
[2022-11-04 20:51:24,166 {dist_trainer.py:770}] <INFO> [ 150/ 200] connecting edge count: 2
[2022-11-04 20:51:37,403 {dist_trainer.py:821}] <INFO> [ 150/ 200] loss: (train=1.098, val=0.912, test=1.044, l2=7649.224), acc: (train=0.688, val=0.682, test=0.640), diff=0.00000132, proc(train=25.164sec, eval=11.905sec)
[2022-11-04 20:51:58,953 {dist_trainer.py:770}] <INFO> [ 151/ 200] connecting edge count: 2
[2022-11-04 20:52:12,193 {dist_trainer.py:821}] <INFO> [ 151/ 200] loss: (train=1.068, val=0.991, test=1.123, l2=7627.943), acc: (train=0.643, val=0.659, test=0.625), diff=0.00000133, proc(train=21.550sec, eval=11.666sec)
[2022-11-04 20:52:36,613 {dist_trainer.py:770}] <INFO> [ 152/ 200] connecting edge count: 2
[2022-11-04 20:52:50,141 {dist_trainer.py:821}] <INFO> [ 152/ 200] loss: (train=1.065, val=0.910, test=1.050, l2=7613.791), acc: (train=0.661, val=0.686, test=0.646), diff=0.00000140, proc(train=24.420sec, eval=11.755sec)
[2022-11-04 20:53:13,569 {dist_trainer.py:770}] <INFO> [ 153/ 200] connecting edge count: 2
[2022-11-04 20:53:26,392 {dist_trainer.py:821}] <INFO> [ 153/ 200] loss: (train=1.055, val=0.903, test=1.035, l2=7584.413), acc: (train=0.654, val=0.685, test=0.647), diff=0.00000109, proc(train=23.427sec, eval=11.648sec)
[2022-11-04 20:53:49,970 {dist_trainer.py:770}] <INFO> [ 154/ 200] connecting edge count: 2
[2022-11-04 20:54:03,485 {dist_trainer.py:821}] <INFO> [ 154/ 200] loss: (train=1.081, val=0.908, test=1.025, l2=7580.931), acc: (train=0.655, val=0.685, test=0.651), diff=0.00000108, proc(train=23.578sec, eval=11.766sec)
[2022-11-04 20:54:28,971 {dist_trainer.py:770}] <INFO> [ 155/ 200] connecting edge count: 2
[2022-11-04 20:54:41,906 {dist_trainer.py:821}] <INFO> [ 155/ 200] loss: (train=1.060, val=1.036, test=1.168, l2=7551.643), acc: (train=0.600, val=0.648, test=0.617), diff=0.00000142, proc(train=25.486sec, eval=11.751sec)
[2022-11-04 20:55:04,629 {dist_trainer.py:770}] <INFO> [ 156/ 200] connecting edge count: 2
[2022-11-04 20:55:17,878 {dist_trainer.py:821}] <INFO> [ 156/ 200] loss: (train=1.023, val=0.859, test=0.999, l2=7531.210), acc: (train=0.682, val=0.704, test=0.663), diff=0.00000113, proc(train=22.723sec, eval=11.637sec)
[2022-11-04 20:55:43,943 {dist_trainer.py:770}] <INFO> [ 157/ 200] connecting edge count: 2
[2022-11-04 20:55:56,898 {dist_trainer.py:821}] <INFO> [ 157/ 200] loss: (train=1.023, val=0.872, test=1.006, l2=7510.041), acc: (train=0.666, val=0.699, test=0.660), diff=0.00000104, proc(train=26.064sec, eval=11.842sec)
[2022-11-04 20:56:19,203 {dist_trainer.py:770}] <INFO> [ 158/ 200] connecting edge count: 2
[2022-11-04 20:56:32,339 {dist_trainer.py:821}] <INFO> [ 158/ 200] loss: (train=1.067, val=0.904, test=1.032, l2=7493.723), acc: (train=0.687, val=0.690, test=0.652), diff=0.00000132, proc(train=22.304sec, eval=11.588sec)
[2022-11-04 20:56:55,582 {dist_trainer.py:770}] <INFO> [ 159/ 200] connecting edge count: 2
[2022-11-04 20:57:08,736 {dist_trainer.py:821}] <INFO> [ 159/ 200] loss: (train=1.112, val=0.990, test=1.108, l2=7492.771), acc: (train=0.635, val=0.656, test=0.621), diff=0.00000126, proc(train=23.243sec, eval=11.825sec)
[2022-11-04 20:57:33,863 {dist_trainer.py:770}] <INFO> [ 160/ 200] connecting edge count: 2
[2022-11-04 20:57:46,653 {dist_trainer.py:821}] <INFO> [ 160/ 200] loss: (train=0.990, val=0.877, test=1.010, l2=7457.260), acc: (train=0.696, val=0.695, test=0.656), diff=0.00000115, proc(train=25.126sec, eval=11.576sec)
[2022-11-04 20:58:10,643 {dist_trainer.py:770}] <INFO> [ 161/ 200] connecting edge count: 2
[2022-11-04 20:58:24,226 {dist_trainer.py:821}] <INFO> [ 161/ 200] loss: (train=1.019, val=0.897, test=1.035, l2=7449.877), acc: (train=0.671, val=0.685, test=0.643), diff=0.00000115, proc(train=23.990sec, eval=11.697sec)
[2022-11-04 20:58:47,404 {dist_trainer.py:770}] <INFO> [ 162/ 200] connecting edge count: 2
[2022-11-04 20:59:00,778 {dist_trainer.py:821}] <INFO> [ 162/ 200] loss: (train=1.008, val=0.874, test=1.012, l2=7424.039), acc: (train=0.667, val=0.698, test=0.660), diff=0.00000132, proc(train=23.177sec, eval=11.805sec)
[2022-11-04 20:59:22,668 {dist_trainer.py:770}] <INFO> [ 163/ 200] connecting edge count: 2
[2022-11-04 20:59:35,791 {dist_trainer.py:821}] <INFO> [ 163/ 200] loss: (train=1.039, val=0.876, test=1.026, l2=7403.200), acc: (train=0.667, val=0.697, test=0.648), diff=0.00000119, proc(train=21.890sec, eval=11.655sec)
[2022-11-04 21:00:02,570 {dist_trainer.py:770}] <INFO> [ 164/ 200] connecting edge count: 2
[2022-11-04 21:00:15,824 {dist_trainer.py:821}] <INFO> [ 164/ 200] loss: (train=1.018, val=0.853, test=1.004, l2=7386.990), acc: (train=0.682, val=0.704, test=0.661), diff=0.00000132, proc(train=26.778sec, eval=11.938sec)
[2022-11-04 21:00:38,672 {dist_trainer.py:770}] <INFO> [ 165/ 200] connecting edge count: 2
[2022-11-04 21:00:51,601 {dist_trainer.py:821}] <INFO> [ 165/ 200] loss: (train=1.026, val=0.794, test=0.945, l2=7360.128), acc: (train=0.693, val=0.725, test=0.679), diff=0.00000105, proc(train=22.847sec, eval=11.593sec)
[2022-11-04 21:01:14,490 {dist_trainer.py:770}] <INFO> [ 166/ 200] connecting edge count: 2
[2022-11-04 21:01:27,941 {dist_trainer.py:821}] <INFO> [ 166/ 200] loss: (train=1.004, val=0.844, test=0.987, l2=7357.333), acc: (train=0.696, val=0.709, test=0.666), diff=0.00000112, proc(train=22.888sec, eval=11.875sec)
[2022-11-04 21:01:51,192 {dist_trainer.py:770}] <INFO> [ 167/ 200] connecting edge count: 2
[2022-11-04 21:02:04,177 {dist_trainer.py:821}] <INFO> [ 167/ 200] loss: (train=0.978, val=0.882, test=1.034, l2=7328.374), acc: (train=0.675, val=0.693, test=0.650), diff=0.00000155, proc(train=23.250sec, eval=11.784sec)
[2022-11-04 21:02:25,550 {dist_trainer.py:770}] <INFO> [ 168/ 200] connecting edge count: 2
[2022-11-04 21:02:38,498 {dist_trainer.py:821}] <INFO> [ 168/ 200] loss: (train=1.007, val=0.842, test=0.980, l2=7312.759), acc: (train=0.704, val=0.711, test=0.671), diff=0.00000137, proc(train=21.373sec, eval=11.606sec)
[2022-11-04 21:03:02,670 {dist_trainer.py:770}] <INFO> [ 169/ 200] connecting edge count: 2
[2022-11-04 21:03:15,603 {dist_trainer.py:821}] <INFO> [ 169/ 200] loss: (train=1.014, val=0.856, test=1.002, l2=7294.509), acc: (train=0.676, val=0.701, test=0.662), diff=0.00000136, proc(train=24.171sec, eval=11.907sec)
[2022-11-04 21:03:37,663 {dist_trainer.py:770}] <INFO> [ 170/ 200] connecting edge count: 2
[2022-11-04 21:03:50,503 {dist_trainer.py:821}] <INFO> [ 170/ 200] loss: (train=0.995, val=0.842, test=0.996, l2=7276.134), acc: (train=0.697, val=0.706, test=0.661), diff=0.00000135, proc(train=22.059sec, eval=11.653sec)
[2022-11-04 21:04:14,750 {dist_trainer.py:770}] <INFO> [ 171/ 200] connecting edge count: 2
[2022-11-04 21:04:28,280 {dist_trainer.py:821}] <INFO> [ 171/ 200] loss: (train=1.033, val=0.851, test=0.995, l2=7273.262), acc: (train=0.682, val=0.705, test=0.657), diff=0.00000165, proc(train=24.247sec, eval=11.934sec)
[2022-11-04 21:04:53,921 {dist_trainer.py:770}] <INFO> [ 172/ 200] connecting edge count: 2
[2022-11-04 21:05:06,790 {dist_trainer.py:821}] <INFO> [ 172/ 200] loss: (train=1.000, val=0.858, test=1.013, l2=7242.839), acc: (train=0.696, val=0.704, test=0.659), diff=0.00000131, proc(train=25.640sec, eval=11.666sec)
[2022-11-04 21:05:30,714 {dist_trainer.py:770}] <INFO> [ 173/ 200] connecting edge count: 2
[2022-11-04 21:05:43,629 {dist_trainer.py:821}] <INFO> [ 173/ 200] loss: (train=1.015, val=0.920, test=1.063, l2=7235.410), acc: (train=0.651, val=0.683, test=0.640), diff=0.00000141, proc(train=23.923sec, eval=11.738sec)
[2022-11-04 21:06:08,287 {dist_trainer.py:770}] <INFO> [ 174/ 200] connecting edge count: 2
[2022-11-04 21:06:22,473 {dist_trainer.py:821}] <INFO> [ 174/ 200] loss: (train=1.007, val=0.868, test=1.028, l2=7212.366), acc: (train=0.696, val=0.696, test=0.648), diff=0.00000136, proc(train=24.658sec, eval=11.895sec)
[2022-11-04 21:06:45,348 {dist_trainer.py:770}] <INFO> [ 175/ 200] connecting edge count: 2
[2022-11-04 21:06:58,601 {dist_trainer.py:821}] <INFO> [ 175/ 200] loss: (train=0.980, val=0.869, test=1.008, l2=7190.512), acc: (train=0.693, val=0.701, test=0.657), diff=0.00000136, proc(train=22.875sec, eval=11.618sec)
[2022-11-04 21:07:23,036 {dist_trainer.py:770}] <INFO> [ 176/ 200] connecting edge count: 2
[2022-11-04 21:07:37,017 {dist_trainer.py:821}] <INFO> [ 176/ 200] loss: (train=1.026, val=0.824, test=0.974, l2=7172.906), acc: (train=0.693, val=0.716, test=0.663), diff=0.00000136, proc(train=24.435sec, eval=11.808sec)
[2022-11-04 21:07:59,371 {dist_trainer.py:770}] <INFO> [ 177/ 200] connecting edge count: 2
[2022-11-04 21:08:12,251 {dist_trainer.py:821}] <INFO> [ 177/ 200] loss: (train=0.962, val=0.833, test=0.987, l2=7146.017), acc: (train=0.709, val=0.716, test=0.672), diff=0.00000117, proc(train=22.355sec, eval=11.606sec)
[2022-11-04 21:08:35,354 {dist_trainer.py:770}] <INFO> [ 178/ 200] connecting edge count: 2
[2022-11-04 21:08:48,744 {dist_trainer.py:821}] <INFO> [ 178/ 200] loss: (train=0.986, val=0.835, test=0.992, l2=7143.311), acc: (train=0.691, val=0.710, test=0.666), diff=0.00000118, proc(train=23.102sec, eval=11.883sec)
[2022-11-04 21:09:13,362 {dist_trainer.py:770}] <INFO> [ 179/ 200] connecting edge count: 2
[2022-11-04 21:09:26,341 {dist_trainer.py:821}] <INFO> [ 179/ 200] loss: (train=0.978, val=0.785, test=0.955, l2=7110.761), acc: (train=0.715, val=0.732, test=0.681), diff=0.00000151, proc(train=24.617sec, eval=11.769sec)
[2022-11-04 21:09:47,840 {dist_trainer.py:770}] <INFO> [ 180/ 200] connecting edge count: 2
[2022-11-04 21:10:01,121 {dist_trainer.py:821}] <INFO> [ 180/ 200] loss: (train=0.968, val=0.823, test=0.983, l2=7096.797), acc: (train=0.691, val=0.716, test=0.668), diff=0.00000147, proc(train=21.499sec, eval=11.651sec)
[2022-11-04 21:10:24,584 {dist_trainer.py:770}] <INFO> [ 181/ 200] connecting edge count: 2
[2022-11-04 21:10:38,062 {dist_trainer.py:821}] <INFO> [ 181/ 200] loss: (train=0.986, val=0.774, test=0.950, l2=7077.772), acc: (train=0.726, val=0.737, test=0.681), diff=0.00000148, proc(train=23.462sec, eval=11.870sec)
[2022-11-04 21:11:01,029 {dist_trainer.py:770}] <INFO> [ 182/ 200] connecting edge count: 2
[2022-11-04 21:11:15,379 {dist_trainer.py:821}] <INFO> [ 182/ 200] loss: (train=0.952, val=0.804, test=0.946, l2=7059.538), acc: (train=0.718, val=0.724, test=0.677), diff=0.00000128, proc(train=22.966sec, eval=11.694sec)
[2022-11-04 21:11:37,986 {dist_trainer.py:770}] <INFO> [ 183/ 200] connecting edge count: 2
[2022-11-04 21:11:51,757 {dist_trainer.py:821}] <INFO> [ 183/ 200] loss: (train=0.986, val=0.825, test=0.985, l2=7059.042), acc: (train=0.691, val=0.717, test=0.671), diff=0.00000160, proc(train=22.607sec, eval=11.869sec)
[2022-11-04 21:12:15,045 {dist_trainer.py:770}] <INFO> [ 184/ 200] connecting edge count: 2
[2022-11-04 21:12:28,051 {dist_trainer.py:821}] <INFO> [ 184/ 200] loss: (train=0.952, val=0.753, test=0.935, l2=7023.450), acc: (train=0.734, val=0.742, test=0.682), diff=0.00000239, proc(train=23.288sec, eval=11.678sec)
[2022-11-04 21:12:52,298 {dist_trainer.py:770}] <INFO> [ 185/ 200] connecting edge count: 2
[2022-11-04 21:13:05,256 {dist_trainer.py:821}] <INFO> [ 185/ 200] loss: (train=0.994, val=0.846, test=0.996, l2=7011.400), acc: (train=0.702, val=0.704, test=0.662), diff=0.00000144, proc(train=24.246sec, eval=11.632sec)
[2022-11-04 21:13:27,516 {dist_trainer.py:770}] <INFO> [ 186/ 200] connecting edge count: 2
[2022-11-04 21:13:41,014 {dist_trainer.py:821}] <INFO> [ 186/ 200] loss: (train=0.975, val=0.822, test=0.990, l2=6988.374), acc: (train=0.696, val=0.721, test=0.672), diff=0.00000155, proc(train=22.260sec, eval=11.898sec)
[2022-11-04 21:14:03,980 {dist_trainer.py:770}] <INFO> [ 187/ 200] connecting edge count: 2
[2022-11-04 21:14:17,286 {dist_trainer.py:821}] <INFO> [ 187/ 200] loss: (train=0.947, val=0.792, test=0.958, l2=6967.883), acc: (train=0.682, val=0.725, test=0.675), diff=0.00000124, proc(train=22.965sec, eval=11.639sec)
[2022-11-04 21:14:41,995 {dist_trainer.py:770}] <INFO> [ 188/ 200] connecting edge count: 2
[2022-11-04 21:14:55,376 {dist_trainer.py:821}] <INFO> [ 188/ 200] loss: (train=0.941, val=0.919, test=1.073, l2=6951.377), acc: (train=0.642, val=0.686, test=0.637), diff=0.00000150, proc(train=24.709sec, eval=11.882sec)
[2022-11-04 21:15:18,685 {dist_trainer.py:770}] <INFO> [ 189/ 200] connecting edge count: 2
[2022-11-04 21:15:31,654 {dist_trainer.py:821}] <INFO> [ 189/ 200] loss: (train=0.941, val=0.757, test=0.929, l2=6923.876), acc: (train=0.732, val=0.737, test=0.682), diff=0.00000127, proc(train=23.309sec, eval=11.595sec)
[2022-11-04 21:15:55,221 {dist_trainer.py:770}] <INFO> [ 190/ 200] connecting edge count: 2
[2022-11-04 21:16:08,258 {dist_trainer.py:821}] <INFO> [ 190/ 200] loss: (train=0.956, val=0.880, test=1.036, l2=6921.002), acc: (train=0.664, val=0.699, test=0.650), diff=0.00000141, proc(train=23.567sec, eval=11.905sec)
[2022-11-04 21:16:32,525 {dist_trainer.py:770}] <INFO> [ 191/ 200] connecting edge count: 2
[2022-11-04 21:16:45,537 {dist_trainer.py:821}] <INFO> [ 191/ 200] loss: (train=0.922, val=0.739, test=0.918, l2=6894.854), acc: (train=0.733, val=0.748, test=0.690), diff=0.00000149, proc(train=24.266sec, eval=11.765sec)
[2022-11-04 21:17:08,832 {dist_trainer.py:770}] <INFO> [ 192/ 200] connecting edge count: 2
[2022-11-04 21:17:21,867 {dist_trainer.py:821}] <INFO> [ 192/ 200] loss: (train=0.929, val=0.754, test=0.943, l2=6876.112), acc: (train=0.713, val=0.742, test=0.689), diff=0.00000128, proc(train=23.294sec, eval=11.563sec)
[2022-11-04 21:17:46,475 {dist_trainer.py:770}] <INFO> [ 193/ 200] connecting edge count: 2
[2022-11-04 21:17:59,508 {dist_trainer.py:821}] <INFO> [ 193/ 200] loss: (train=0.941, val=0.887, test=1.075, l2=6856.590), acc: (train=0.679, val=0.697, test=0.647), diff=0.00000152, proc(train=24.608sec, eval=11.758sec)
[2022-11-04 21:18:22,383 {dist_trainer.py:770}] <INFO> [ 194/ 200] connecting edge count: 2
[2022-11-04 21:18:36,373 {dist_trainer.py:821}] <INFO> [ 194/ 200] loss: (train=0.957, val=0.827, test=0.988, l2=6842.103), acc: (train=0.704, val=0.718, test=0.666), diff=0.00000147, proc(train=22.875sec, eval=11.729sec)
[2022-11-04 21:19:00,074 {dist_trainer.py:770}] <INFO> [ 195/ 200] connecting edge count: 2
[2022-11-04 21:19:14,120 {dist_trainer.py:821}] <INFO> [ 195/ 200] loss: (train=0.980, val=0.754, test=0.938, l2=6836.214), acc: (train=0.739, val=0.743, test=0.683), diff=0.00000147, proc(train=23.700sec, eval=11.897sec)
[2022-11-04 21:19:38,431 {dist_trainer.py:770}] <INFO> [ 196/ 200] connecting edge count: 2
[2022-11-04 21:19:51,381 {dist_trainer.py:821}] <INFO> [ 196/ 200] loss: (train=0.920, val=0.822, test=1.004, l2=6808.548), acc: (train=0.718, val=0.718, test=0.665), diff=0.00000130, proc(train=24.311sec, eval=11.629sec)
[2022-11-04 21:20:14,977 {dist_trainer.py:770}] <INFO> [ 197/ 200] connecting edge count: 2
[2022-11-04 21:20:28,700 {dist_trainer.py:821}] <INFO> [ 197/ 200] loss: (train=0.939, val=0.803, test=0.970, l2=6806.423), acc: (train=0.727, val=0.721, test=0.673), diff=0.00000135, proc(train=23.596sec, eval=11.738sec)
[2022-11-04 21:20:50,737 {dist_trainer.py:770}] <INFO> [ 198/ 200] connecting edge count: 2
[2022-11-04 21:21:04,342 {dist_trainer.py:821}] <INFO> [ 198/ 200] loss: (train=0.923, val=0.852, test=1.025, l2=6781.473), acc: (train=0.675, val=0.708, test=0.661), diff=0.00000135, proc(train=22.037sec, eval=11.836sec)
[2022-11-04 21:21:27,047 {dist_trainer.py:770}] <INFO> [ 199/ 200] connecting edge count: 2
[2022-11-04 21:21:40,406 {dist_trainer.py:821}] <INFO> [ 199/ 200] loss: (train=0.927, val=0.774, test=0.948, l2=6763.844), acc: (train=0.712, val=0.733, test=0.676), diff=0.00000133, proc(train=22.704sec, eval=11.615sec)
[2022-11-04 21:22:03,447 {dist_trainer.py:770}] <INFO> [ 200/ 200] connecting edge count: 2
[2022-11-04 21:22:25,619 {dist_trainer.py:821}] <INFO> [ 200/ 200] loss: (train=0.931, val=0.777, test=0.962, l2=6752.577), acc: (train=0.710, val=0.735, test=0.674), diff=0.00000105, proc(train=23.041sec, eval=11.585sec)
[2022-11-04 21:22:38,668 {dist_trainer.py:899}] <INFO> [EVAL] loss: (train=0.842, val=0.777, test=0.962, l2=6752.562), acc: (train=0.704, val=0.735, test=0.674), proc=13.048sec
[2022-11-04 21:22:38,771 {dist_trainer.py:380}] <INFO> GC: check garbage []
[2022-11-04 21:22:39,129 {main.py:285}] <INFO> GC: check garbage []
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
