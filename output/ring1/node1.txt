[2022-11-02 16:28:57,767 {main.py:127}] <INFO> Namespace(datadir='./data', outdir='./output/ring1', epochs=200, batch_size=100, seed=569, data_init_seed=11, model_init_seed=13, l2_lambda=0.01, model_name='resnet50', dataset_name='cifar10', train_data_length=10000, group_channels=32, drop_rate=0.1, last_drop_rate=0.5, cuda=True, cuda_device_no=1, plot=False, scheduler='StepLR', step_size=410, gamma=0.9, sleep_factor=0.0, loglevel=<LogLevel.INFO: 20>, logfile=None, optimizer='PdmmISVR', nodename='node0', conf='./conf/node_list.json', host='./conf/hosts.json', lr=0.002, use_gcoef=False, piw=1.0, round_step=False, swap_timeout=10)
[2022-11-02 16:28:57,767 {main.py:193}] <INFO> {'nodes': {'node0': {'device': 'cuda', 'round': 10, 'edges': {'node2': 0, 'node1': 4}}, 'node1': {'device': 'cuda', 'round': 10, 'edges': {'node0': 1, 'node2': 5}}, 'node2': {'device': 'cuda', 'round': 10, 'edges': {'node1': 2, 'node0': 6}}}}
[2022-11-02 16:28:57,890 {dist_trainer.py:186}] <INFO> : <class 'model.resnet.ResNet'>
[2022-11-02 16:28:57,890 {dist_trainer.py:186}] <INFO> conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,890 {dist_trainer.py:183}] <INFO> bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-02 16:28:57,890 {dist_trainer.py:186}] <INFO> relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,890 {dist_trainer.py:186}] <INFO> maxpool: <class 'torch.nn.modules.pooling.MaxPool2d'>
[2022-11-02 16:28:57,890 {dist_trainer.py:186}] <INFO> dropout1: <class 'torch.nn.modules.dropout.Dropout2d'>
[2022-11-02 16:28:57,890 {dist_trainer.py:186}] <INFO> layer1: <class 'torch.nn.modules.container.Sequential'>
[2022-11-02 16:28:57,890 {dist_trainer.py:186}] <INFO> layer1.0: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,890 {dist_trainer.py:186}] <INFO> layer1.0.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,890 {dist_trainer.py:183}] <INFO> layer1.0.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-02 16:28:57,890 {dist_trainer.py:186}] <INFO> layer1.0.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,890 {dist_trainer.py:183}] <INFO> layer1.0.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-02 16:28:57,890 {dist_trainer.py:186}] <INFO> layer1.0.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,890 {dist_trainer.py:183}] <INFO> layer1.0.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,890 {dist_trainer.py:186}] <INFO> layer1.0.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,890 {dist_trainer.py:186}] <INFO> layer1.0.downsample: <class 'torch.nn.modules.container.Sequential'>
[2022-11-02 16:28:57,890 {dist_trainer.py:186}] <INFO> layer1.0.downsample.0: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,890 {dist_trainer.py:183}] <INFO> layer1.0.downsample.1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,891 {dist_trainer.py:186}] <INFO> layer1.1: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,891 {dist_trainer.py:186}] <INFO> layer1.1.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,891 {dist_trainer.py:183}] <INFO> layer1.1.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-02 16:28:57,891 {dist_trainer.py:186}] <INFO> layer1.1.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,891 {dist_trainer.py:183}] <INFO> layer1.1.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-02 16:28:57,891 {dist_trainer.py:186}] <INFO> layer1.1.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,891 {dist_trainer.py:183}] <INFO> layer1.1.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,891 {dist_trainer.py:186}] <INFO> layer1.1.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,891 {dist_trainer.py:186}] <INFO> layer1.2: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,891 {dist_trainer.py:186}] <INFO> layer1.2.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,891 {dist_trainer.py:183}] <INFO> layer1.2.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-02 16:28:57,891 {dist_trainer.py:186}] <INFO> layer1.2.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,891 {dist_trainer.py:183}] <INFO> layer1.2.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 2, channels: 64, eps: 0.000010, affine: True
[2022-11-02 16:28:57,891 {dist_trainer.py:186}] <INFO> layer1.2.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,891 {dist_trainer.py:183}] <INFO> layer1.2.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,891 {dist_trainer.py:186}] <INFO> layer1.2.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,891 {dist_trainer.py:186}] <INFO> layer1.3: <class 'torch.nn.modules.dropout.Dropout2d'>
[2022-11-02 16:28:57,891 {dist_trainer.py:186}] <INFO> layer2: <class 'torch.nn.modules.container.Sequential'>
[2022-11-02 16:28:57,891 {dist_trainer.py:186}] <INFO> layer2.0: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,891 {dist_trainer.py:186}] <INFO> layer2.0.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,891 {dist_trainer.py:183}] <INFO> layer2.0.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-02 16:28:57,891 {dist_trainer.py:186}] <INFO> layer2.0.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,891 {dist_trainer.py:183}] <INFO> layer2.0.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-02 16:28:57,891 {dist_trainer.py:186}] <INFO> layer2.0.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,891 {dist_trainer.py:183}] <INFO> layer2.0.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 16:28:57,891 {dist_trainer.py:186}] <INFO> layer2.0.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,891 {dist_trainer.py:186}] <INFO> layer2.0.downsample: <class 'torch.nn.modules.container.Sequential'>
[2022-11-02 16:28:57,891 {dist_trainer.py:186}] <INFO> layer2.0.downsample.0: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,891 {dist_trainer.py:183}] <INFO> layer2.0.downsample.1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 16:28:57,891 {dist_trainer.py:186}] <INFO> layer2.1: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,891 {dist_trainer.py:186}] <INFO> layer2.1.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,891 {dist_trainer.py:183}] <INFO> layer2.1.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-02 16:28:57,891 {dist_trainer.py:186}] <INFO> layer2.1.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,891 {dist_trainer.py:183}] <INFO> layer2.1.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-02 16:28:57,892 {dist_trainer.py:186}] <INFO> layer2.1.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,892 {dist_trainer.py:183}] <INFO> layer2.1.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 16:28:57,892 {dist_trainer.py:186}] <INFO> layer2.1.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,892 {dist_trainer.py:186}] <INFO> layer2.2: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,892 {dist_trainer.py:186}] <INFO> layer2.2.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,892 {dist_trainer.py:183}] <INFO> layer2.2.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-02 16:28:57,892 {dist_trainer.py:186}] <INFO> layer2.2.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,892 {dist_trainer.py:183}] <INFO> layer2.2.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-02 16:28:57,892 {dist_trainer.py:186}] <INFO> layer2.2.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,892 {dist_trainer.py:183}] <INFO> layer2.2.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 16:28:57,892 {dist_trainer.py:186}] <INFO> layer2.2.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,892 {dist_trainer.py:186}] <INFO> layer2.3: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,892 {dist_trainer.py:186}] <INFO> layer2.3.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,892 {dist_trainer.py:183}] <INFO> layer2.3.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-02 16:28:57,892 {dist_trainer.py:186}] <INFO> layer2.3.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,892 {dist_trainer.py:183}] <INFO> layer2.3.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 4, channels: 128, eps: 0.000010, affine: True
[2022-11-02 16:28:57,892 {dist_trainer.py:186}] <INFO> layer2.3.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,892 {dist_trainer.py:183}] <INFO> layer2.3.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 16:28:57,892 {dist_trainer.py:186}] <INFO> layer2.3.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,892 {dist_trainer.py:186}] <INFO> layer2.4: <class 'torch.nn.modules.dropout.Dropout2d'>
[2022-11-02 16:28:57,892 {dist_trainer.py:186}] <INFO> layer3: <class 'torch.nn.modules.container.Sequential'>
[2022-11-02 16:28:57,892 {dist_trainer.py:186}] <INFO> layer3.0: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,892 {dist_trainer.py:186}] <INFO> layer3.0.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,892 {dist_trainer.py:183}] <INFO> layer3.0.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,892 {dist_trainer.py:186}] <INFO> layer3.0.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,892 {dist_trainer.py:183}] <INFO> layer3.0.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,892 {dist_trainer.py:186}] <INFO> layer3.0.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,892 {dist_trainer.py:183}] <INFO> layer3.0.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-02 16:28:57,892 {dist_trainer.py:186}] <INFO> layer3.0.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,892 {dist_trainer.py:186}] <INFO> layer3.0.downsample: <class 'torch.nn.modules.container.Sequential'>
[2022-11-02 16:28:57,892 {dist_trainer.py:186}] <INFO> layer3.0.downsample.0: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,892 {dist_trainer.py:183}] <INFO> layer3.0.downsample.1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-02 16:28:57,892 {dist_trainer.py:186}] <INFO> layer3.1: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,892 {dist_trainer.py:186}] <INFO> layer3.1.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,892 {dist_trainer.py:183}] <INFO> layer3.1.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,893 {dist_trainer.py:186}] <INFO> layer3.1.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,893 {dist_trainer.py:183}] <INFO> layer3.1.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,893 {dist_trainer.py:186}] <INFO> layer3.1.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,893 {dist_trainer.py:183}] <INFO> layer3.1.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-02 16:28:57,893 {dist_trainer.py:186}] <INFO> layer3.1.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,893 {dist_trainer.py:186}] <INFO> layer3.2: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,893 {dist_trainer.py:186}] <INFO> layer3.2.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,893 {dist_trainer.py:183}] <INFO> layer3.2.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,893 {dist_trainer.py:186}] <INFO> layer3.2.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,893 {dist_trainer.py:183}] <INFO> layer3.2.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,893 {dist_trainer.py:186}] <INFO> layer3.2.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,893 {dist_trainer.py:183}] <INFO> layer3.2.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-02 16:28:57,893 {dist_trainer.py:186}] <INFO> layer3.2.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,893 {dist_trainer.py:186}] <INFO> layer3.3: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,893 {dist_trainer.py:186}] <INFO> layer3.3.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,893 {dist_trainer.py:183}] <INFO> layer3.3.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,893 {dist_trainer.py:186}] <INFO> layer3.3.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,893 {dist_trainer.py:183}] <INFO> layer3.3.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,893 {dist_trainer.py:186}] <INFO> layer3.3.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,893 {dist_trainer.py:183}] <INFO> layer3.3.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-02 16:28:57,893 {dist_trainer.py:186}] <INFO> layer3.3.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,893 {dist_trainer.py:186}] <INFO> layer3.4: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,893 {dist_trainer.py:186}] <INFO> layer3.4.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,893 {dist_trainer.py:183}] <INFO> layer3.4.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,893 {dist_trainer.py:186}] <INFO> layer3.4.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,893 {dist_trainer.py:183}] <INFO> layer3.4.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,893 {dist_trainer.py:186}] <INFO> layer3.4.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,893 {dist_trainer.py:183}] <INFO> layer3.4.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-02 16:28:57,893 {dist_trainer.py:186}] <INFO> layer3.4.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,893 {dist_trainer.py:186}] <INFO> layer3.5: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,893 {dist_trainer.py:186}] <INFO> layer3.5.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,893 {dist_trainer.py:183}] <INFO> layer3.5.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,893 {dist_trainer.py:186}] <INFO> layer3.5.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,893 {dist_trainer.py:183}] <INFO> layer3.5.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 8, channels: 256, eps: 0.000010, affine: True
[2022-11-02 16:28:57,894 {dist_trainer.py:186}] <INFO> layer3.5.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,894 {dist_trainer.py:183}] <INFO> layer3.5.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 32, channels: 1024, eps: 0.000010, affine: True
[2022-11-02 16:28:57,894 {dist_trainer.py:186}] <INFO> layer3.5.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,894 {dist_trainer.py:186}] <INFO> layer3.6: <class 'torch.nn.modules.dropout.Dropout2d'>
[2022-11-02 16:28:57,894 {dist_trainer.py:186}] <INFO> layer4: <class 'torch.nn.modules.container.Sequential'>
[2022-11-02 16:28:57,894 {dist_trainer.py:186}] <INFO> layer4.0: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,894 {dist_trainer.py:186}] <INFO> layer4.0.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,894 {dist_trainer.py:183}] <INFO> layer4.0.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 16:28:57,894 {dist_trainer.py:186}] <INFO> layer4.0.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,894 {dist_trainer.py:183}] <INFO> layer4.0.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 16:28:57,894 {dist_trainer.py:186}] <INFO> layer4.0.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,894 {dist_trainer.py:183}] <INFO> layer4.0.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 64, channels: 2048, eps: 0.000010, affine: True
[2022-11-02 16:28:57,894 {dist_trainer.py:186}] <INFO> layer4.0.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,894 {dist_trainer.py:186}] <INFO> layer4.0.downsample: <class 'torch.nn.modules.container.Sequential'>
[2022-11-02 16:28:57,894 {dist_trainer.py:186}] <INFO> layer4.0.downsample.0: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,894 {dist_trainer.py:183}] <INFO> layer4.0.downsample.1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 64, channels: 2048, eps: 0.000010, affine: True
[2022-11-02 16:28:57,894 {dist_trainer.py:186}] <INFO> layer4.1: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,894 {dist_trainer.py:186}] <INFO> layer4.1.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,894 {dist_trainer.py:183}] <INFO> layer4.1.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 16:28:57,894 {dist_trainer.py:186}] <INFO> layer4.1.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,894 {dist_trainer.py:183}] <INFO> layer4.1.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 16:28:57,894 {dist_trainer.py:186}] <INFO> layer4.1.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,894 {dist_trainer.py:183}] <INFO> layer4.1.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 64, channels: 2048, eps: 0.000010, affine: True
[2022-11-02 16:28:57,894 {dist_trainer.py:186}] <INFO> layer4.1.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,894 {dist_trainer.py:186}] <INFO> layer4.2: <class 'model.resnet.Bottleneck'>
[2022-11-02 16:28:57,894 {dist_trainer.py:186}] <INFO> layer4.2.conv1: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,894 {dist_trainer.py:183}] <INFO> layer4.2.bn1: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 16:28:57,894 {dist_trainer.py:186}] <INFO> layer4.2.conv2: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,894 {dist_trainer.py:183}] <INFO> layer4.2.bn2: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 16, channels: 512, eps: 0.000010, affine: True
[2022-11-02 16:28:57,894 {dist_trainer.py:186}] <INFO> layer4.2.conv3: <class 'torch.nn.modules.conv.Conv2d'>
[2022-11-02 16:28:57,894 {dist_trainer.py:183}] <INFO> layer4.2.bn3: <class 'torch.nn.modules.normalization.GroupNorm'>, groups: 64, channels: 2048, eps: 0.000010, affine: True
[2022-11-02 16:28:57,894 {dist_trainer.py:186}] <INFO> layer4.2.relu: <class 'torch.nn.modules.activation.ReLU'>
[2022-11-02 16:28:57,894 {dist_trainer.py:186}] <INFO> avgpool: <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>
[2022-11-02 16:28:57,894 {dist_trainer.py:186}] <INFO> dropout_fc: <class 'torch.nn.modules.dropout.Dropout'>
[2022-11-02 16:28:57,894 {dist_trainer.py:186}] <INFO> fc: <class 'torch.nn.modules.linear.Linear'>
[2022-11-02 16:28:57,895 {dist_trainer.py:192}] <INFO> parameter size: conv1.weight 37632B
[2022-11-02 16:28:57,895 {dist_trainer.py:192}] <INFO> parameter size: bn1.weight 256B
[2022-11-02 16:28:57,895 {dist_trainer.py:192}] <INFO> parameter size: bn1.bias 256B
[2022-11-02 16:28:57,895 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.conv1.weight 16384B
[2022-11-02 16:28:57,895 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.bn1.weight 256B
[2022-11-02 16:28:57,895 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.bn1.bias 256B
[2022-11-02 16:28:57,895 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.conv2.weight 147456B
[2022-11-02 16:28:57,895 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.bn2.weight 256B
[2022-11-02 16:28:57,895 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.bn2.bias 256B
[2022-11-02 16:28:57,895 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.conv3.weight 65536B
[2022-11-02 16:28:57,895 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.bn3.weight 1024B
[2022-11-02 16:28:57,895 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.bn3.bias 1024B
[2022-11-02 16:28:57,895 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.downsample.0.weight 65536B
[2022-11-02 16:28:57,895 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.downsample.1.weight 1024B
[2022-11-02 16:28:57,895 {dist_trainer.py:192}] <INFO> parameter size: layer1.0.downsample.1.bias 1024B
[2022-11-02 16:28:57,895 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.conv1.weight 65536B
[2022-11-02 16:28:57,895 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.bn1.weight 256B
[2022-11-02 16:28:57,895 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.bn1.bias 256B
[2022-11-02 16:28:57,896 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.conv2.weight 147456B
[2022-11-02 16:28:57,896 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.bn2.weight 256B
[2022-11-02 16:28:57,896 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.bn2.bias 256B
[2022-11-02 16:28:57,896 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.conv3.weight 65536B
[2022-11-02 16:28:57,896 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.bn3.weight 1024B
[2022-11-02 16:28:57,896 {dist_trainer.py:192}] <INFO> parameter size: layer1.1.bn3.bias 1024B
[2022-11-02 16:28:57,896 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.conv1.weight 65536B
[2022-11-02 16:28:57,896 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.bn1.weight 256B
[2022-11-02 16:28:57,896 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.bn1.bias 256B
[2022-11-02 16:28:57,896 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.conv2.weight 147456B
[2022-11-02 16:28:57,896 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.bn2.weight 256B
[2022-11-02 16:28:57,896 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.bn2.bias 256B
[2022-11-02 16:28:57,896 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.conv3.weight 65536B
[2022-11-02 16:28:57,896 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.bn3.weight 1024B
[2022-11-02 16:28:57,896 {dist_trainer.py:192}] <INFO> parameter size: layer1.2.bn3.bias 1024B
[2022-11-02 16:28:57,896 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.conv1.weight 131072B
[2022-11-02 16:28:57,896 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.bn1.weight 512B
[2022-11-02 16:28:57,896 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.bn1.bias 512B
[2022-11-02 16:28:57,896 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.conv2.weight 589824B
[2022-11-02 16:28:57,896 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.bn2.weight 512B
[2022-11-02 16:28:57,897 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.bn2.bias 512B
[2022-11-02 16:28:57,897 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.conv3.weight 262144B
[2022-11-02 16:28:57,897 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.bn3.weight 2048B
[2022-11-02 16:28:57,897 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.bn3.bias 2048B
[2022-11-02 16:28:57,897 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.downsample.0.weight 524288B
[2022-11-02 16:28:57,897 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.downsample.1.weight 2048B
[2022-11-02 16:28:57,897 {dist_trainer.py:192}] <INFO> parameter size: layer2.0.downsample.1.bias 2048B
[2022-11-02 16:28:57,897 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.conv1.weight 262144B
[2022-11-02 16:28:57,897 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.bn1.weight 512B
[2022-11-02 16:28:57,897 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.bn1.bias 512B
[2022-11-02 16:28:57,897 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.conv2.weight 589824B
[2022-11-02 16:28:57,897 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.bn2.weight 512B
[2022-11-02 16:28:57,897 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.bn2.bias 512B
[2022-11-02 16:28:57,897 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.conv3.weight 262144B
[2022-11-02 16:28:57,897 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.bn3.weight 2048B
[2022-11-02 16:28:57,897 {dist_trainer.py:192}] <INFO> parameter size: layer2.1.bn3.bias 2048B
[2022-11-02 16:28:57,897 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.conv1.weight 262144B
[2022-11-02 16:28:57,897 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.bn1.weight 512B
[2022-11-02 16:28:57,897 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.bn1.bias 512B
[2022-11-02 16:28:57,897 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.conv2.weight 589824B
[2022-11-02 16:28:57,897 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.bn2.weight 512B
[2022-11-02 16:28:57,898 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.bn2.bias 512B
[2022-11-02 16:28:57,898 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.conv3.weight 262144B
[2022-11-02 16:28:57,898 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.bn3.weight 2048B
[2022-11-02 16:28:57,898 {dist_trainer.py:192}] <INFO> parameter size: layer2.2.bn3.bias 2048B
[2022-11-02 16:28:57,898 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.conv1.weight 262144B
[2022-11-02 16:28:57,898 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.bn1.weight 512B
[2022-11-02 16:28:57,898 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.bn1.bias 512B
[2022-11-02 16:28:57,898 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.conv2.weight 589824B
[2022-11-02 16:28:57,898 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.bn2.weight 512B
[2022-11-02 16:28:57,898 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.bn2.bias 512B
[2022-11-02 16:28:57,898 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.conv3.weight 262144B
[2022-11-02 16:28:57,898 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.bn3.weight 2048B
[2022-11-02 16:28:57,898 {dist_trainer.py:192}] <INFO> parameter size: layer2.3.bn3.bias 2048B
[2022-11-02 16:28:57,898 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.conv1.weight 524288B
[2022-11-02 16:28:57,898 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.bn1.weight 1024B
[2022-11-02 16:28:57,898 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.bn1.bias 1024B
[2022-11-02 16:28:57,898 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.conv2.weight 2359296B
[2022-11-02 16:28:57,898 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.bn2.weight 1024B
[2022-11-02 16:28:57,898 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.bn2.bias 1024B
[2022-11-02 16:28:57,898 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.conv3.weight 1048576B
[2022-11-02 16:28:57,899 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.bn3.weight 4096B
[2022-11-02 16:28:57,899 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.bn3.bias 4096B
[2022-11-02 16:28:57,899 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.downsample.0.weight 2097152B
[2022-11-02 16:28:57,899 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.downsample.1.weight 4096B
[2022-11-02 16:28:57,899 {dist_trainer.py:192}] <INFO> parameter size: layer3.0.downsample.1.bias 4096B
[2022-11-02 16:28:57,899 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.conv1.weight 1048576B
[2022-11-02 16:28:57,899 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.bn1.weight 1024B
[2022-11-02 16:28:57,899 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.bn1.bias 1024B
[2022-11-02 16:28:57,899 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.conv2.weight 2359296B
[2022-11-02 16:28:57,899 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.bn2.weight 1024B
[2022-11-02 16:28:57,899 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.bn2.bias 1024B
[2022-11-02 16:28:57,899 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.conv3.weight 1048576B
[2022-11-02 16:28:57,899 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.bn3.weight 4096B
[2022-11-02 16:28:57,899 {dist_trainer.py:192}] <INFO> parameter size: layer3.1.bn3.bias 4096B
[2022-11-02 16:28:57,899 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.conv1.weight 1048576B
[2022-11-02 16:28:57,899 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.bn1.weight 1024B
[2022-11-02 16:28:57,899 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.bn1.bias 1024B
[2022-11-02 16:28:57,899 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.conv2.weight 2359296B
[2022-11-02 16:28:57,899 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.bn2.weight 1024B
[2022-11-02 16:28:57,899 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.bn2.bias 1024B
[2022-11-02 16:28:57,899 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.conv3.weight 1048576B
[2022-11-02 16:28:57,900 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.bn3.weight 4096B
[2022-11-02 16:28:57,900 {dist_trainer.py:192}] <INFO> parameter size: layer3.2.bn3.bias 4096B
[2022-11-02 16:28:57,900 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.conv1.weight 1048576B
[2022-11-02 16:28:57,900 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.bn1.weight 1024B
[2022-11-02 16:28:57,900 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.bn1.bias 1024B
[2022-11-02 16:28:57,900 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.conv2.weight 2359296B
[2022-11-02 16:28:57,900 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.bn2.weight 1024B
[2022-11-02 16:28:57,900 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.bn2.bias 1024B
[2022-11-02 16:28:57,900 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.conv3.weight 1048576B
[2022-11-02 16:28:57,900 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.bn3.weight 4096B
[2022-11-02 16:28:57,900 {dist_trainer.py:192}] <INFO> parameter size: layer3.3.bn3.bias 4096B
[2022-11-02 16:28:57,900 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.conv1.weight 1048576B
[2022-11-02 16:28:57,900 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.bn1.weight 1024B
[2022-11-02 16:28:57,900 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.bn1.bias 1024B
[2022-11-02 16:28:57,900 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.conv2.weight 2359296B
[2022-11-02 16:28:57,900 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.bn2.weight 1024B
[2022-11-02 16:28:57,900 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.bn2.bias 1024B
[2022-11-02 16:28:57,900 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.conv3.weight 1048576B
[2022-11-02 16:28:57,900 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.bn3.weight 4096B
[2022-11-02 16:28:57,900 {dist_trainer.py:192}] <INFO> parameter size: layer3.4.bn3.bias 4096B
[2022-11-02 16:28:57,900 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.conv1.weight 1048576B
[2022-11-02 16:28:57,901 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.bn1.weight 1024B
[2022-11-02 16:28:57,901 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.bn1.bias 1024B
[2022-11-02 16:28:57,901 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.conv2.weight 2359296B
[2022-11-02 16:28:57,901 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.bn2.weight 1024B
[2022-11-02 16:28:57,901 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.bn2.bias 1024B
[2022-11-02 16:28:57,901 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.conv3.weight 1048576B
[2022-11-02 16:28:57,901 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.bn3.weight 4096B
[2022-11-02 16:28:57,901 {dist_trainer.py:192}] <INFO> parameter size: layer3.5.bn3.bias 4096B
[2022-11-02 16:28:57,901 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.conv1.weight 2097152B
[2022-11-02 16:28:57,901 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.bn1.weight 2048B
[2022-11-02 16:28:57,901 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.bn1.bias 2048B
[2022-11-02 16:28:57,901 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.conv2.weight 9437184B
[2022-11-02 16:28:57,901 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.bn2.weight 2048B
[2022-11-02 16:28:57,901 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.bn2.bias 2048B
[2022-11-02 16:28:57,901 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.conv3.weight 4194304B
[2022-11-02 16:28:57,901 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.bn3.weight 8192B
[2022-11-02 16:28:57,901 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.bn3.bias 8192B
[2022-11-02 16:28:57,901 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.downsample.0.weight 8388608B
[2022-11-02 16:28:57,901 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.downsample.1.weight 8192B
[2022-11-02 16:28:57,901 {dist_trainer.py:192}] <INFO> parameter size: layer4.0.downsample.1.bias 8192B
[2022-11-02 16:28:57,901 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.conv1.weight 4194304B
[2022-11-02 16:28:57,902 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.bn1.weight 2048B
[2022-11-02 16:28:57,902 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.bn1.bias 2048B
[2022-11-02 16:28:57,902 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.conv2.weight 9437184B
[2022-11-02 16:28:57,902 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.bn2.weight 2048B
[2022-11-02 16:28:57,902 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.bn2.bias 2048B
[2022-11-02 16:28:57,902 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.conv3.weight 4194304B
[2022-11-02 16:28:57,902 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.bn3.weight 8192B
[2022-11-02 16:28:57,902 {dist_trainer.py:192}] <INFO> parameter size: layer4.1.bn3.bias 8192B
[2022-11-02 16:28:57,902 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.conv1.weight 4194304B
[2022-11-02 16:28:57,902 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.bn1.weight 2048B
[2022-11-02 16:28:57,902 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.bn1.bias 2048B
[2022-11-02 16:28:57,902 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.conv2.weight 9437184B
[2022-11-02 16:28:57,902 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.bn2.weight 2048B
[2022-11-02 16:28:57,902 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.bn2.bias 2048B
[2022-11-02 16:28:57,902 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.conv3.weight 4194304B
[2022-11-02 16:28:57,902 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.bn3.weight 8192B
[2022-11-02 16:28:57,902 {dist_trainer.py:192}] <INFO> parameter size: layer4.2.bn3.bias 8192B
[2022-11-02 16:28:57,902 {dist_trainer.py:192}] <INFO> parameter size: fc.weight 81920B
[2022-11-02 16:28:57,902 {dist_trainer.py:192}] <INFO> parameter size: fc.bias 40B
[2022-11-02 16:28:57,902 {dist_trainer.py:194}] <INFO> Model: resnet50 size: 89.754MiB
[2022-11-02 16:28:59,845 {dist_trainer.py:78}] <INFO> device: cuda:1 0/4, NVIDIA TITAN RTX
[2022-11-02 16:29:01,161 {dist_trainer.py:494}] <INFO> node0: [7,8,2,6,4,5,1,3]
[2022-11-02 16:29:01,161 {dist_trainer.py:494}] <INFO> node1: [4,5,1,3,0,9,7,8]
[2022-11-02 16:29:01,161 {dist_trainer.py:494}] <INFO> node2: [0,9,7,8,2,6,4,5]
[2022-11-02 16:29:01,161 {dist_trainer.py:497}] <INFO> class 0, [node1:0.472,node2:0.528]
[2022-11-02 16:29:01,161 {dist_trainer.py:497}] <INFO> class 1, [node0:0.505,node1:0.495]
[2022-11-02 16:29:01,161 {dist_trainer.py:497}] <INFO> class 2, [node0:0.535,node2:0.465]
[2022-11-02 16:29:01,161 {dist_trainer.py:497}] <INFO> class 3, [node0:0.502,node1:0.498]
[2022-11-02 16:29:01,161 {dist_trainer.py:497}] <INFO> class 4, [node0:0.325,node1:0.361,node2:0.314]
[2022-11-02 16:29:01,161 {dist_trainer.py:497}] <INFO> class 5, [node0:0.327,node1:0.343,node2:0.330]
[2022-11-02 16:29:01,161 {dist_trainer.py:497}] <INFO> class 6, [node0:0.497,node2:0.503]
[2022-11-02 16:29:01,161 {dist_trainer.py:497}] <INFO> class 7, [node0:0.340,node1:0.338,node2:0.322]
[2022-11-02 16:29:01,161 {dist_trainer.py:497}] <INFO> class 8, [node0:0.305,node1:0.352,node2:0.343]
[2022-11-02 16:29:01,161 {dist_trainer.py:497}] <INFO> class 9, [node1:0.475,node2:0.525]
[2022-11-02 16:29:01,163 {dist_trainer.py:527}] <INFO> train data node0: 1:2523,2:2675,3:2509,4:1624,5:1634,6:2484,7:1700,8:1524
[2022-11-02 16:29:01,163 {dist_trainer.py:527}] <INFO> train data node1: 0:2360,1:2477,3:2491,4:1806,5:1714,7:1690,8:1758,9:2375
[2022-11-02 16:29:01,163 {dist_trainer.py:527}] <INFO> train data node2: 0:2640,2:2325,4:1570,5:1652,6:2516,7:1610,8:1718,9:2625
[2022-11-02 16:29:14,184 {dist_trainer.py:531}] <INFO> split_load_datas(END)
[2022-11-02 16:29:14,185 {dist_trainer.py:114}] <INFO> datasets(END)
[2022-11-02 16:29:14,186 {dist_trainer.py:713}] <INFO> build_criterion(1)
[2022-11-02 16:29:14,186 {dist_trainer.py:721}] <INFO> build_criterion(2)
[2022-11-02 16:29:14,196 {contract.py:21}] <INFO> 0
[2022-11-02 16:29:14,197 {contract.py:21}] <INFO> 1
[2022-11-02 16:29:14,197 {contract.py:21}] <INFO> 2
[2022-11-02 16:29:14,198 {gateway.py:80}] <INFO> Gateway(1)
[2022-11-02 16:29:16,995 {distributed_c10d.py:228}] <INFO> Added key: store_based_barrier_key:1 to store for rank: 0
[2022-11-02 16:29:17,006 {distributed_c10d.py:262}] <INFO> Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 3 nodes.
[2022-11-02 16:29:17,006 {gateway.py:87}] <INFO> Gateway(2)
[2022-11-02 16:29:17,168 {gateway.py:25}] <INFO> ServerHandler(1)
[2022-11-02 16:29:17,168 {gateway.py:34}] <INFO> ServerHandler(2)
[2022-11-02 16:29:17,178 {contract.py:36}] <INFO> contract(1)
[2022-11-02 16:29:17,279 {contract.py:44}] <INFO> <CLI> node0 : edge setup.
[2022-11-02 16:29:17,300 {gateway.py:62}] <INFO> <SRV> node0 : edge setup.
[2022-11-02 16:29:18,044 {contract.py:44}] <INFO> <CLI> node0 : edge setup.
[2022-11-02 16:29:18,044 {contract.py:59}] <INFO> contract(2)
[2022-11-02 16:29:18,044 {pdmm_isvr.py:22}] <INFO> Optimizer <class 'optimizer.pdmm_isvr.PdmmISVR'> params: {'lr': 0.002, 'round': 10, 'initial_lr': 0.002, 'piw': 1.0, 'use_gcoef': False}
[2022-11-02 16:29:18,044 {dist_trainer.py:725}] <INFO> build_optimizer()
[2022-11-02 16:29:18,045 {dist_trainer.py:736}] <INFO> Setup scheduler: <torch.optim.lr_scheduler.StepLR object at 0x7f0b2ed50310>
[2022-11-02 16:29:44,397 {dist_trainer.py:770}] <INFO> [   1/ 200] connecting edge count: 2
[2022-11-02 16:29:57,709 {dist_trainer.py:821}] <INFO> [   1/ 200] loss: (train=2.590, val=2.459, test=2.456, l2=15787.447), acc: (train=0.166, val=0.114, test=0.117), diff=0.00190174, proc(train=26.351sec, eval=11.653sec)
[2022-11-02 16:30:19,901 {dist_trainer.py:770}] <INFO> [   2/ 200] connecting edge count: 2
[2022-11-02 16:30:32,844 {dist_trainer.py:821}] <INFO> [   2/ 200] loss: (train=2.321, val=2.510, test=2.512, l2=15547.230), acc: (train=0.167, val=0.137, test=0.138), diff=0.00001975, proc(train=22.191sec, eval=11.357sec)
[2022-11-02 16:30:57,558 {dist_trainer.py:770}] <INFO> [   3/ 200] connecting edge count: 2
[2022-11-02 16:31:10,922 {dist_trainer.py:821}] <INFO> [   3/ 200] loss: (train=2.290, val=2.283, test=2.275, l2=15555.793), acc: (train=0.142, val=0.147, test=0.151), diff=0.00000654, proc(train=24.713sec, eval=11.637sec)
[2022-11-02 16:31:36,573 {dist_trainer.py:770}] <INFO> [   4/ 200] connecting edge count: 2
[2022-11-02 16:31:49,068 {dist_trainer.py:821}] <INFO> [   4/ 200] loss: (train=2.230, val=2.135, test=2.131, l2=15527.996), acc: (train=0.270, val=0.208, test=0.214), diff=0.00000083, proc(train=25.651sec, eval=11.388sec)
[2022-11-02 16:32:13,755 {dist_trainer.py:770}] <INFO> [   5/ 200] connecting edge count: 2
[2022-11-02 16:32:27,086 {dist_trainer.py:821}] <INFO> [   5/ 200] loss: (train=2.259, val=2.154, test=2.152, l2=15525.737), acc: (train=0.210, val=0.183, test=0.182), diff=0.00000048, proc(train=24.687sec, eval=11.556sec)
[2022-11-02 16:32:53,750 {dist_trainer.py:770}] <INFO> [   6/ 200] connecting edge count: 2
[2022-11-02 16:33:06,305 {dist_trainer.py:821}] <INFO> [   6/ 200] loss: (train=2.198, val=1.989, test=1.980, l2=15467.721), acc: (train=0.298, val=0.263, test=0.267), diff=0.00000027, proc(train=26.663sec, eval=11.443sec)
[2022-11-02 16:33:29,131 {dist_trainer.py:770}] <INFO> [   7/ 200] connecting edge count: 2
[2022-11-02 16:33:41,775 {dist_trainer.py:821}] <INFO> [   7/ 200] loss: (train=2.146, val=2.185, test=2.175, l2=15453.574), acc: (train=0.221, val=0.217, test=0.220), diff=0.00000053, proc(train=22.826sec, eval=11.470sec)
[2022-11-02 16:34:06,206 {dist_trainer.py:770}] <INFO> [   8/ 200] connecting edge count: 2
[2022-11-02 16:34:19,192 {dist_trainer.py:821}] <INFO> [   8/ 200] loss: (train=2.123, val=1.956, test=1.953, l2=15405.742), acc: (train=0.341, val=0.267, test=0.265), diff=0.00000071, proc(train=24.430sec, eval=11.687sec)
[2022-11-02 16:34:41,255 {dist_trainer.py:770}] <INFO> [   9/ 200] connecting edge count: 2
[2022-11-02 16:34:54,270 {dist_trainer.py:821}] <INFO> [   9/ 200] loss: (train=2.031, val=1.846, test=1.842, l2=15372.162), acc: (train=0.302, val=0.320, test=0.327), diff=0.00000062, proc(train=22.063sec, eval=11.348sec)
[2022-11-02 16:35:19,653 {dist_trainer.py:770}] <INFO> [  10/ 200] connecting edge count: 2
[2022-11-02 16:35:33,493 {dist_trainer.py:821}] <INFO> [  10/ 200] loss: (train=2.050, val=2.007, test=2.004, l2=15375.153), acc: (train=0.290, val=0.264, test=0.267), diff=0.00000071, proc(train=25.383sec, eval=11.642sec)
[2022-11-02 16:35:59,863 {dist_trainer.py:770}] <INFO> [  11/ 200] connecting edge count: 2
[2022-11-02 16:36:12,534 {dist_trainer.py:821}] <INFO> [  11/ 200] loss: (train=2.003, val=1.883, test=1.871, l2=15326.357), acc: (train=0.355, val=0.303, test=0.299), diff=0.00000068, proc(train=26.370sec, eval=11.460sec)
[2022-11-02 16:36:36,871 {dist_trainer.py:770}] <INFO> [  12/ 200] connecting edge count: 2
[2022-11-02 16:36:50,232 {dist_trainer.py:821}] <INFO> [  12/ 200] loss: (train=2.021, val=1.921, test=1.917, l2=15319.287), acc: (train=0.337, val=0.287, test=0.285), diff=0.00000057, proc(train=24.337sec, eval=11.806sec)
[2022-11-02 16:37:16,757 {dist_trainer.py:770}] <INFO> [  13/ 200] connecting edge count: 2
[2022-11-02 16:37:29,370 {dist_trainer.py:821}] <INFO> [  13/ 200] loss: (train=1.965, val=1.770, test=1.762, l2=15263.198), acc: (train=0.394, val=0.349, test=0.348), diff=0.00000048, proc(train=26.524sec, eval=11.508sec)
[2022-11-02 16:37:52,489 {dist_trainer.py:770}] <INFO> [  14/ 200] connecting edge count: 2
[2022-11-02 16:38:05,133 {dist_trainer.py:821}] <INFO> [  14/ 200] loss: (train=1.943, val=1.807, test=1.799, l2=15249.184), acc: (train=0.366, val=0.330, test=0.325), diff=0.00000058, proc(train=23.118sec, eval=11.619sec)
[2022-11-02 16:38:29,491 {dist_trainer.py:770}] <INFO> [  15/ 200] connecting edge count: 2
[2022-11-02 16:38:42,724 {dist_trainer.py:821}] <INFO> [  15/ 200] loss: (train=1.911, val=1.798, test=1.795, l2=15202.026), acc: (train=0.377, val=0.343, test=0.341), diff=0.00000076, proc(train=24.358sec, eval=11.698sec)
